From 020a14f055cc7cb984970012cbe8bb2e7cecde97 Mon Sep 17 00:00:00 2001
From: Rokis <ghost1988102@gmail.com>
Date: Sun, 24 May 2020 12:05:41 +0800
Subject: [PATCH 032/122] cfe: add missing files needed by compile from
 src-rt-7.x.main.      change path in order not to mess up main compiler.

Signed-off-by: Rokis <ghost1988102@gmail.com>
---
 .../cfe/arch/arm/board/bcm947xx/src/Makefile  |   14 +-
 .../src/et/cfe/include/bcmenet47xx.h          |  235 ++
 .../src/et/cfe/include/bcmenetmib.h           |   87 +
 .../src/et/cfe/include/bcmenetphy.h           |   85 +
 .../src/et/cfe/include/bcmenetrxh.h           |   49 +
 .../src/et/cfe/include/bcmgmacmib.h           |  116 +
 .../src/et/cfe/include/bcmgmacrxh.h           |   51 +
 .../src/et/cfe/include/fa_core.h              |  261 ++
 .../src/et/cfe/include/gmac_common.h          |  559 +++
 .../src/et/cfe/include/gmac_core.h            |  279 ++
 .../src/et/cfe/sys/.gitignore                 |    2 +
 .../src-rt-7.14.114.x/src/et/cfe/sys/et_cfe.c |  660 ++++
 .../src-rt-7.14.114.x/src/et/cfe/sys/et_cfe.h |   35 +
 .../src-rt-7.14.114.x/src/et/cfe/sys/et_cfg.h |   25 +
 .../src-rt-7.14.114.x/src/et/cfe/sys/et_dbg.h |   71 +
 .../src/et/cfe/sys/et_export.h                |   58 +
 .../src/et/cfe/sys/et_linux.c                 | 3367 +++++++++++++++++
 .../src/et/cfe/sys/et_linux.h                 |  117 +
 .../src-rt-7.14.114.x/src/et/cfe/sys/etc.c    | 1273 +++++++
 .../src-rt-7.14.114.x/src/et/cfe/sys/etc.h    |  366 ++
 .../src/et/cfe/sys/etc47xx.c                  | 1350 +++++++
 .../src/et/cfe/sys/etc_adm.c                  |  548 +++
 .../src/et/cfe/sys/etc_adm.h                  |   36 +
 .../src-rt-7.14.114.x/src/et/cfe/sys/etc_fa.c | 1990 ++++++++++
 .../src-rt-7.14.114.x/src/et/cfe/sys/etc_fa.h |  113 +
 .../src/et/cfe/sys/etcgmac.c                  | 2264 +++++++++++
 .../src/et/cfe/sys/etcgmac.h                  |   72 +
 27 files changed, 14076 insertions(+), 7 deletions(-)
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/include/bcmenet47xx.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetmib.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetphy.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetrxh.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/include/bcmgmacmib.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/include/bcmgmacrxh.h
 create mode 100755 release/src-rt-7.14.114.x/src/et/cfe/include/fa_core.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/include/gmac_common.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/include/gmac_core.h
 create mode 100755 release/src-rt-7.14.114.x/src/et/cfe/sys/.gitignore
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfe.c
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfe.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfg.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/et_dbg.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/et_export.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/et_linux.c
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/et_linux.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/etc.c
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/etc.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/etc47xx.c
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/etc_adm.c
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/etc_adm.h
 create mode 100755 release/src-rt-7.14.114.x/src/et/cfe/sys/etc_fa.c
 create mode 100755 release/src-rt-7.14.114.x/src/et/cfe/sys/etc_fa.h
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/etcgmac.c
 create mode 100644 release/src-rt-7.14.114.x/src/et/cfe/sys/etcgmac.h

diff --git a/release/src-rt-7.14.114.x/src/cfe/cfe/arch/arm/board/bcm947xx/src/Makefile b/release/src-rt-7.14.114.x/src/cfe/cfe/arch/arm/board/bcm947xx/src/Makefile
index fd09798241..4e2297fc8d 100644
--- a/release/src-rt-7.14.114.x/src/cfe/cfe/arch/arm/board/bcm947xx/src/Makefile
+++ b/release/src-rt-7.14.114.x/src/cfe/cfe/arch/arm/board/bcm947xx/src/Makefile
@@ -2,11 +2,11 @@
 # Makefile for Broadcom BCM947XX (ARM) boards
 #
 # Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
-# 
+#
 # Permission to use, copy, modify, and/or distribute this software for any
 # purpose with or without fee is hereby granted, provided that the above
 # copyright notice and this permission notice appear in all copies.
-# 
+#
 # THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 # WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 # MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
@@ -101,7 +101,7 @@ endif
 ifeq ($(strip $(CFG_ET)),1)
 
 ETOBJS := etc.o et_cfe.o bcmrobo.o
-CFLAGS += -DCFG_ET=1 -I$(SRCBASE)/et/sys -I$(SRCBASE)/et/include -DETROBO -DDMA -DROBO_SRAB
+CFLAGS += -DCFG_ET=1 -I$(SRCBASE)/et/cfe/sys -I$(SRCBASE)/et/cfe/include -DETROBO -DDMA -DROBO_SRAB
 
 ifeq ($(strip $(CFG_GMAC)),1)
 ETOBJS += etcgmac.o
@@ -121,8 +121,8 @@ endif
 HNDDMA := 1
 
 # Search for sources under src/et/sys or objects under src/et/cfe
-ifneq ($(wildcard $(SRCBASE)/et/sys),)
-vpath %.c $(SRCBASE)/et/sys
+ifneq ($(wildcard $(SRCBASE)/et/cfe/sys),)
+vpath %.c $(SRCBASE)/et/cfe/sys
 ALLOBJS += $(ETOBJS)
 else
 ALLOBJS += $(foreach obj,$(ETOBJS),$(SRCBASE)/et/cfe/$(obj))
@@ -132,7 +132,7 @@ endif
 ifeq ($(strip $(CFG_WL)),1)
 CFLAGS += -DCFG_WL=1 -DBCMDMA64
 
-# get wl driver source files and flags, 
+# get wl driver source files and flags,
 # macros are defined in build/broadcom/bcm947xx/Makefile
 # WLCFE is to pick wl_cfe.c from wl.mk
 WLCFE=1
@@ -153,7 +153,7 @@ endif
 
 # add these path for WLOBJS only
 $(WLOBJS): WL_CFLAGS := -I$(SRCBASE)/wl/sys -I$(SRCBASE)/wl/phy -I$(SRCBASE)/wl/exe $(WL_DFLAGS)
-CFLAGS += $(WL_CFLAGS) 
+CFLAGS += $(WL_CFLAGS)
 
 # Search for sources under src/wl/sys or objects under src/wl/cfe
 ifneq ($(wildcard $(SRCBASE)/wl/sys/wlc.h),)
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenet47xx.h b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenet47xx.h
new file mode 100644
index 0000000000..1ab01ad13b
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenet47xx.h
@@ -0,0 +1,235 @@
+/*
+ * Hardware-specific definitions for
+ * Broadcom BCM47XX 10/100 Mbps Ethernet cores.
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: bcmenet47xx.h 376342 2012-12-24 21:02:49Z $
+ */
+
+#ifndef	_bcmenet_47xx_h_
+#define	_bcmenet_47xx_h_
+
+#include <bcmenetmib.h>
+#include <bcmenetrxh.h>
+#include <bcmenetphy.h>
+
+#define	BCMENET_NFILTERS	64		/* # ethernet address filter entries */
+#define	BCMENET_MCHASHBASE	0x200		/* multicast hash filter base address */
+#define	BCMENET_MCHASHSIZE	256		/* multicast hash filter size in bytes */
+#define	BCMENET_MAX_DMA		4096		/* chip has 12 bits of DMA addressing */
+
+/* power management event wakeup pattern constants */
+#define	BCMENET_NPMP		4		/* chip supports 4 wakeup patterns */
+#define	BCMENET_PMPBASE		0x400		/* wakeup pattern base address */
+#define	BCMENET_PMPSIZE		0x80		/* 128bytes each pattern */
+#define	BCMENET_PMMBASE		0x600		/* wakeup mask base address */
+#define	BCMENET_PMMSIZE		0x10		/* 128bits each mask */
+
+/* cpp contortions to concatenate w/arg prescan */
+#ifndef PAD
+#define	_PADLINE(line)	pad ## line
+#define	_XSTR(line)	_PADLINE(line)
+#define	PAD		_XSTR(__LINE__)
+#endif	/* PAD */
+
+/*
+ * Host Interface Registers
+ */
+typedef volatile struct _bcmenettregs {
+	/* Device and Power Control */
+	uint32	devcontrol;
+	uint32	PAD[2];
+	uint32	biststatus;
+	uint32	wakeuplength;
+	uint32	PAD[3];
+
+	/* Interrupt Control */
+	uint32	intstatus;
+	uint32	intmask;
+	uint32	gptimer;
+	uint32	PAD[23];
+
+	/* Ethernet MAC Address Filtering Control */
+	uint32	PAD[2];
+	uint32	enetftaddr;
+	uint32	enetftdata;
+	uint32	PAD[2];
+
+	/* Ethernet MAC Control */
+	uint32	emactxmaxburstlen;
+	uint32	emacrxmaxburstlen;
+	uint32	emaccontrol;
+	uint32	emacflowcontrol;
+
+	uint32	PAD[20];
+
+	/* DMA Lazy Interrupt Control */
+	uint32	intrecvlazy;
+	uint32	PAD[63];
+
+	/* DMA engine */
+	dma32regp_t	dmaregs;
+	dma32diag_t	dmafifo;
+	uint32	PAD[116];
+
+	/* EMAC Registers */
+	uint32 rxconfig;
+	uint32 rxmaxlength;
+	uint32 txmaxlength;
+	uint32 PAD;
+	uint32 mdiocontrol;
+	uint32 mdiodata;
+	uint32 emacintmask;
+	uint32 emacintstatus;
+	uint32 camdatalo;
+	uint32 camdatahi;
+	uint32 camcontrol;
+	uint32 enetcontrol;
+	uint32 txcontrol;
+	uint32 txwatermark;
+	uint32 mibcontrol;
+	uint32 PAD[49];
+
+	/* EMAC MIB counters */
+	bcmenetmib_t	mib;
+
+	uint32	PAD[585];
+
+	/* Sonics SiliconBackplane config registers */
+	sbconfig_t	sbconfig;
+} bcmenetregs_t;
+
+/* device control */
+#define	DC_PM		((uint32)1 << 7)	/* pattern filtering enable */
+#define	DC_IP		((uint32)1 << 10)	/* internal ephy present (rev >= 1) */
+#define	DC_ER		((uint32)1 << 15)	/* ephy reset */
+#define	DC_MP		((uint32)1 << 16)	/* mii phy mode enable */
+#define	DC_CO		((uint32)1 << 17)	/* mii phy mode: enable clocks */
+#define	DC_PA_MASK	0x7c0000		/* mii phy mode: mdc/mdio phy address */
+#define	DC_PA_SHIFT	18
+#define	DC_FS_MASK	0x03800000		/* fifo size (rev >= 8) */
+#define	DC_FS_SHIFT	23
+#define	DC_FS_4K	0			/* 4Kbytes */
+#define	DC_FS_512	1			/* 512bytes */
+
+/* wakeup length */
+#define	WL_P0_MASK	0x7f			/* pattern 0 */
+#define	WL_D0		((uint32)1 << 7)
+#define	WL_P1_MASK	0x7f00			/* pattern 1 */
+#define	WL_P1_SHIFT	8
+#define	WL_D1		((uint32)1 << 15)
+#define	WL_P2_MASK	0x7f0000		/* pattern 2 */
+#define	WL_P2_SHIFT	16
+#define	WL_D2		((uint32)1 << 23)
+#define	WL_P3_MASK	0x7f000000		/* pattern 3 */
+#define	WL_P3_SHIFT	24
+#define	WL_D3		((uint32)1 << 31)
+
+/* intstatus and intmask */
+#define	I_PME		((uint32)1 << 6)	/* power management event */
+#define	I_TO		((uint32)1 << 7)	/* general purpose timeout */
+#define	I_PC		((uint32)1 << 10)	/* descriptor error */
+#define	I_PD		((uint32)1 << 11)	/* data error */
+#define	I_DE		((uint32)1 << 12)	/* descriptor protocol error */
+#define	I_RU		((uint32)1 << 13)	/* receive descriptor underflow */
+#define	I_RO		((uint32)1 << 14)	/* receive fifo overflow */
+#define	I_XU		((uint32)1 << 15)	/* transmit fifo underflow */
+#define	I_RI		((uint32)1 << 16)	/* receive interrupt */
+#define	I_XI		((uint32)1 << 24)	/* transmit interrupt */
+#define	I_EM		((uint32)1 << 26)	/* emac interrupt */
+#define	I_MW		((uint32)1 << 27)	/* mii write */
+#define	I_MR		((uint32)1 << 28)	/* mii read */
+
+/* emaccontrol */
+#define	EMC_CG		((uint32)1 << 0)	/* crc32 generation enable */
+#define	EMC_EP		((uint32)1 << 2)	/* onchip ephy: powerdown (rev >= 1) */
+#define	EMC_ED		((uint32)1 << 3)	/* onchip ephy: energy detected (rev >= 1) */
+#define	EMC_LC_MASK	0xe0			/* onchip ephy: led control (rev >= 1) */
+#define	EMC_LC_SHIFT	5
+
+/* emacflowcontrol */
+#define	EMF_RFH_MASK	0xff			/* rx fifo hi water mark */
+#define	EMF_PG		((uint32)1 << 15)	/* enable pause frame generation */
+
+/* interrupt receive lazy */
+#define	IRL_TO_MASK	0x00ffffff		/* timeout */
+#define	IRL_FC_MASK	0xff000000		/* frame count */
+#define	IRL_FC_SHIFT	24			/* frame count */
+
+/* emac receive config */
+#define	ERC_DB		((uint32)1 << 0)	/* disable broadcast */
+#define	ERC_AM		((uint32)1 << 1)	/* accept all multicast */
+#define	ERC_RDT		((uint32)1 << 2)	/* receive disable while transmitting */
+#define	ERC_PE		((uint32)1 << 3)	/* promiscuous enable */
+#define	ERC_LE		((uint32)1 << 4)	/* loopback enable */
+#define	ERC_FE		((uint32)1 << 5)	/* enable flow control */
+#define	ERC_UF		((uint32)1 << 6)	/* accept unicast flow control frame */
+#define	ERC_RF		((uint32)1 << 7)	/* reject filter */
+#define	ERC_CA		((uint32)1 << 8)	/* cam absent */
+
+/* emac mdio control */
+#define	MC_MF_MASK	0x7f			/* mdc frequency */
+#define	MC_PE		((uint32)1 << 7)	/* mii preamble enable */
+
+/* emac mdio data */
+#define	MD_DATA_MASK	0xffff			/* r/w data */
+#define	MD_TA_MASK	0x30000			/* turnaround value */
+#define	MD_TA_SHIFT	16
+#define	MD_TA_VALID	(2 << MD_TA_SHIFT)	/* valid ta */
+#define	MD_RA_MASK	0x7c0000		/* register address */
+#define	MD_RA_SHIFT	18
+#define	MD_PMD_MASK	0xf800000		/* physical media device */
+#define	MD_PMD_SHIFT	23
+#define	MD_OP_MASK	0x30000000		/* opcode */
+#define	MD_OP_SHIFT	28
+#define	MD_OP_WRITE	(1 << MD_OP_SHIFT)	/* write op */
+#define	MD_OP_READ	(2 << MD_OP_SHIFT)	/* read op */
+#define	MD_SB_MASK	0xc0000000		/* start bits */
+#define	MD_SB_SHIFT	30
+#define	MD_SB_START	(0x1 << MD_SB_SHIFT)	/* start of frame */
+
+/* emac intstatus and intmask */
+#define	EI_MII		((uint32)1 << 0)	/* mii mdio interrupt */
+#define	EI_MIB		((uint32)1 << 1)	/* mib interrupt */
+#define	EI_FLOW		((uint32)1 << 2)	/* flow control interrupt */
+
+/* emac cam data high */
+#define	CD_V		((uint32)1 << 16)	/* valid bit */
+
+/* emac cam control */
+#define	CC_CE		((uint32)1 << 0)	/* cam enable */
+#define	CC_MS		((uint32)1 << 1)	/* mask select */
+#define	CC_RD		((uint32)1 << 2)	/* read */
+#define	CC_WR		((uint32)1 << 3)	/* write */
+#define	CC_INDEX_MASK	0x3f0000		/* index */
+#define	CC_INDEX_SHIFT	16
+#define	CC_CB		((uint32)1 << 31)	/* cam busy */
+
+/* emac ethernet control */
+#define	EC_EE		((uint32)1 << 0)	/* emac enable */
+#define	EC_ED		((uint32)1 << 1)	/* emac disable */
+#define	EC_ES		((uint32)1 << 2)	/* emac soft reset */
+#define	EC_EP		((uint32)1 << 3)	/* external phy select */
+
+/* emac transmit control */
+#define	EXC_FD		((uint32)1 << 0)	/* full duplex */
+#define	EXC_FM		((uint32)1 << 1)	/* flowmode */
+#define	EXC_SB		((uint32)1 << 2)	/* single backoff enable */
+#define	EXC_SS		((uint32)1 << 3)	/* small slottime */
+
+/* emac mib control */
+#define	EMC_RZ		((uint32)1 << 0)	/* autoclear on read */
+
+#endif	/* _bcmenet_47xx_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetmib.h b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetmib.h
new file mode 100644
index 0000000000..ec7baa3271
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetmib.h
@@ -0,0 +1,87 @@
+/*
+ * Hardware-specific MIB definition for
+ * Broadcom Home Networking Division
+ * BCM44XX and BCM47XX 10/100 Mbps Ethernet cores.
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: bcmenetmib.h 376342 2012-12-24 21:02:49Z $
+ */
+
+#ifndef _bcmenetmib_h_
+#define _bcmenetmib_h_
+
+/* cpp contortions to concatenate w/arg prescan */
+#ifndef PAD
+#define	_PADLINE(line)	pad ## line
+#define	_XSTR(line)	_PADLINE(line)
+#define	PAD		_XSTR(__LINE__)
+#endif	/* PAD */
+
+/*
+ * EMAC MIB Registers
+ */
+typedef volatile struct {
+	uint32 tx_good_octets;
+	uint32 tx_good_pkts;
+	uint32 tx_octets;
+	uint32 tx_pkts;
+	uint32 tx_broadcast_pkts;
+	uint32 tx_multicast_pkts;
+	uint32 tx_len_64;
+	uint32 tx_len_65_to_127;
+	uint32 tx_len_128_to_255;
+	uint32 tx_len_256_to_511;
+	uint32 tx_len_512_to_1023;
+	uint32 tx_len_1024_to_max;
+	uint32 tx_jabber_pkts;
+	uint32 tx_oversize_pkts;
+	uint32 tx_fragment_pkts;
+	uint32 tx_underruns;
+	uint32 tx_total_cols;
+	uint32 tx_single_cols;
+	uint32 tx_multiple_cols;
+	uint32 tx_excessive_cols;
+	uint32 tx_late_cols;
+	uint32 tx_defered;
+	uint32 tx_carrier_lost;
+	uint32 tx_pause_pkts;
+	uint32 PAD[8];
+
+	uint32 rx_good_octets;
+	uint32 rx_good_pkts;
+	uint32 rx_octets;
+	uint32 rx_pkts;
+	uint32 rx_broadcast_pkts;
+	uint32 rx_multicast_pkts;
+	uint32 rx_len_64;
+	uint32 rx_len_65_to_127;
+	uint32 rx_len_128_to_255;
+	uint32 rx_len_256_to_511;
+	uint32 rx_len_512_to_1023;
+	uint32 rx_len_1024_to_max;
+	uint32 rx_jabber_pkts;
+	uint32 rx_oversize_pkts;
+	uint32 rx_fragment_pkts;
+	uint32 rx_missed_pkts;
+	uint32 rx_crc_align_errs;
+	uint32 rx_undersize;
+	uint32 rx_crc_errs;
+	uint32 rx_align_errs;
+	uint32 rx_symbol_errs;
+	uint32 rx_pause_pkts;
+	uint32 rx_nonpause_pkts;
+} bcmenetmib_t;
+
+#endif	/* _bcmenetmib_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetphy.h b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetphy.h
new file mode 100644
index 0000000000..e9adf12292
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetphy.h
@@ -0,0 +1,85 @@
+/*
+ * Misc Broadcom BCM47XX MDC/MDIO enet phy definitions.
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: bcmenetphy.h 376342 2012-12-24 21:02:49Z $
+ */
+
+#ifndef	_bcmenetphy_h_
+#define	_bcmenetphy_h_
+
+/* phy address */
+#define	MAXEPHY		32			/* mdio phy addresses are 5bit quantities */
+#define	EPHY_MASK	0x1f			/* phy mask */
+#define	EPHY_NONE	31			/* nvram: no phy present at all */
+#define	EPHY_NOREG	30			/* nvram: no local phy regs */
+
+#define	MAXPHYREG	32			/* max 32 registers per phy */
+
+/* just a few phy registers */
+#define	CTL_RESET	(1 << 15)		/* reset */
+#define	CTL_LOOP	(1 << 14)		/* loopback */
+#define	CTL_SPEED	(1 << 13)		/* speed selection lsb 0=10, 1=100 */
+#define	CTL_ANENAB	(1 << 12)		/* autonegotiation enable */
+#define	CTL_RESTART	(1 << 9)		/* restart autonegotiation */
+#define	CTL_DUPLEX	(1 << 8)		/* duplex mode 0=half, 1=full */
+#define	CTL_SPEED_MSB	(1 << 6)		/* speed selection msb */
+
+#define	CTL_SPEED_10	((0 << 6) | (0 << 13))	/* speed selection CTL.6=0, CTL.13=0 */
+#define	CTL_SPEED_100	((0 << 6) | (1 << 13))	/* speed selection CTL.6=0, CTL.13=1 */
+#define	CTL_SPEED_1000	((1 << 6) | (0 << 13))	/* speed selection CTL.6=1, CTL.13=0 */
+
+#define	ADV_10FULL	(1 << 6)		/* autonegotiate advertise 10full */
+#define	ADV_10HALF	(1 << 5)		/* autonegotiate advertise 10half */
+#define	ADV_100FULL	(1 << 8)		/* autonegotiate advertise 100full */
+#define	ADV_100HALF	(1 << 7)		/* autonegotiate advertise 100half */
+
+/* link partner ability register */
+#define LPA_SLCT	0x001f			/* same as advertise selector */
+#define LPA_10HALF	0x0020			/* can do 10mbps half-duplex */
+#define LPA_10FULL	0x0040			/* can do 10mbps full-duplex */
+#define LPA_100HALF	0x0080			/* can do 100mbps half-duplex */
+#define LPA_100FULL	0x0100			/* can do 100mbps full-duplex */
+#define LPA_100BASE4	0x0200			/* can do 100mbps 4k packets */
+#define LPA_RESV	0x1c00			/* unused */
+#define LPA_RFAULT	0x2000			/* link partner faulted */
+#define LPA_LPACK	0x4000			/* link partner acked us */
+#define LPA_NPAGE	0x8000			/* next page bit */
+
+#define LPA_DUPLEX	(LPA_10FULL | LPA_100FULL)
+#define LPA_100		(LPA_100FULL | LPA_100HALF | LPA_100BASE4)
+
+/* 1000BASE-T control register */
+#define	ADV_1000HALF	0x0100			/* advertise 1000BASE-T half duplex */
+#define	ADV_1000FULL	0x0200			/* advertise 1000BASE-T full duplex */
+
+/* 1000BASE-T status register */
+#define	LPA_1000HALF	0x0400			/* link partner 1000BASE-T half duplex */
+#define	LPA_1000FULL	0x0800			/* link partner 1000BASE-T full duplex */
+
+/* 1000BASE-T extended status register */
+#define	EST_1000THALF	0x1000			/* 1000BASE-T half duplex capable */
+#define	EST_1000TFULL	0x2000			/* 1000BASE-T full duplex capable */
+#define	EST_1000XHALF	0x4000			/* 1000BASE-X half duplex capable */
+#define	EST_1000XFULL	0x8000			/* 1000BASE-X full duplex capable */
+
+#define	STAT_REMFAULT	(1 << 4)		/* remote fault */
+#define	STAT_LINK	(1 << 2)		/* link status */
+#define	STAT_JAB	(1 << 1)		/* jabber detected */
+#define	AUX_FORCED	(1 << 2)		/* forced 10/100 */
+#define	AUX_SPEED	(1 << 1)		/* speed 0=10mbps 1=100mbps */
+#define	AUX_DUPLEX	(1 << 0)		/* duplex 0=half 1=full */
+
+#endif	/* _bcmenetphy_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetrxh.h b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetrxh.h
new file mode 100644
index 0000000000..7f7bdbb189
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmenetrxh.h
@@ -0,0 +1,49 @@
+/*
+ * Hardware-specific Receive Data Header for the
+ * Broadcom Home Networking Division
+ * BCM44XX and BCM47XX 10/100 Mbps Ethernet cores.
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: bcmenetrxh.h 376342 2012-12-24 21:02:49Z $
+ */
+
+#ifndef _bcmenetrxh_h_
+#define	_bcmenetrxh_h_
+
+/*
+ * The Ethernet MAC core returns an 8-byte Receive Frame Data Header
+ * with every frame consisting of
+ * 16bits of frame length, followed by
+ * 16bits of EMAC rx descriptor info, followed by 32bits of undefined.
+ */
+typedef volatile struct {
+	uint16	len;
+	uint16	flags;
+	uint16	pad[12];
+} bcmenetrxh_t;
+
+#define	RXHDR_LEN	28	/* Header length */
+
+#define	RXF_L		((uint16)1 << 11)	/* last buffer in a frame */
+#define	RXF_MISS	((uint16)1 << 7)	/* received due to promisc mode */
+#define	RXF_BRDCAST	((uint16)1 << 6)	/* dest is broadcast address */
+#define	RXF_MULT	((uint16)1 << 5)	/* dest is multicast address */
+#define	RXF_LG		((uint16)1 << 4)	/* frame length > rxmaxlength */
+#define	RXF_NO		((uint16)1 << 3)	/* odd number of nibbles */
+#define	RXF_RXER	((uint16)1 << 2)	/* receive symbol error */
+#define	RXF_CRC		((uint16)1 << 1)	/* crc error */
+#define	RXF_OV		((uint16)1 << 0)	/* fifo overflow */
+
+#endif	/* _bcmenetrxh_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/include/bcmgmacmib.h b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmgmacmib.h
new file mode 100644
index 0000000000..a319d6308d
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmgmacmib.h
@@ -0,0 +1,116 @@
+/*
+ * Hardware-specific MIB definition for
+ * Broadcom Home Networking Division
+ * GbE Unimac core
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: bcmgmacmib.h 376342 2012-12-24 21:02:49Z $
+ */
+
+#ifndef	_bcmgmacmib_h_
+#define	_bcmgmacmib_h_
+
+
+/* cpp contortions to concatenate w/arg prescan */
+#ifndef PAD
+#define	_PADLINE(line)	pad ## line
+#define	_XSTR(line)	_PADLINE(line)
+#define	PAD		_XSTR(__LINE__)
+#endif	/* PAD */
+
+/* GMAC MIB structure */
+
+typedef struct _gmacmib {
+	uint32	tx_good_octets;		/* 0x300 */
+	uint32	tx_good_octets_high;	/* 0x304 */
+	uint32	tx_good_pkts;		/* 0x308 */
+	uint32	tx_octets;		/* 0x30c */
+	uint32	tx_octets_high;		/* 0x310 */
+	uint32	tx_pkts;		/* 0x314 */
+	uint32	tx_broadcast_pkts;	/* 0x318 */
+	uint32	tx_multicast_pkts;	/* 0x31c */
+	uint32	tx_len_64;		/* 0x320 */
+	uint32	tx_len_65_to_127;	/* 0x324 */
+	uint32	tx_len_128_to_255;	/* 0x328 */
+	uint32	tx_len_256_to_511;	/* 0x32c */
+	uint32	tx_len_512_to_1023;	/* 0x330 */
+	uint32	tx_len_1024_to_1522;	/* 0x334 */
+	uint32	tx_len_1523_to_2047;	/* 0x338 */
+	uint32	tx_len_2048_to_4095;	/* 0x33c */
+	uint32	tx_len_4095_to_8191;	/* 0x340 */
+	uint32	tx_len_8192_to_max;	/* 0x344 */
+	uint32	tx_jabber_pkts;		/* 0x348 */
+	uint32	tx_oversize_pkts;	/* 0x34c */
+	uint32	tx_fragment_pkts;	/* 0x350 */
+	uint32	tx_underruns;		/* 0x354 */
+	uint32	tx_total_cols;		/* 0x358 */
+	uint32	tx_single_cols;		/* 0x35c */
+	uint32	tx_multiple_cols;	/* 0x360 */
+	uint32	tx_excessive_cols;	/* 0x364 */
+	uint32	tx_late_cols;		/* 0x368 */
+	uint32	tx_defered;		/* 0x36c */
+	uint32	tx_carrier_lost;	/* 0x370 */
+	uint32	tx_pause_pkts;		/* 0x374 */
+	uint32	tx_uni_pkts;		/* 0x378 */
+	uint32	tx_q0_pkts;		/* 0x37c */
+	uint32	tx_q0_octets;		/* 0x380 */
+	uint32	tx_q0_octets_high;	/* 0x384 */
+	uint32	tx_q1_pkts;		/* 0x388 */
+	uint32	tx_q1_octets;		/* 0x38c */
+	uint32	tx_q1_octets_high;	/* 0x390 */
+	uint32	tx_q2_pkts;		/* 0x394 */
+	uint32	tx_q2_octets;		/* 0x398 */
+	uint32	tx_q2_octets_high;	/* 0x39c */
+	uint32	tx_q3_pkts;		/* 0x3a0 */
+	uint32	tx_q3_octets;		/* 0x3a4 */
+	uint32	tx_q3_octets_high;	/* 0x3a8 */
+	uint32	PAD;
+	uint32	rx_good_octets;		/* 0x3b0 */
+	uint32	rx_good_octets_high;	/* 0x3b4 */
+	uint32	rx_good_pkts;		/* 0x3b8 */
+	uint32	rx_octets;		/* 0x3bc */
+	uint32	rx_octets_high;		/* 0x3c0 */
+	uint32	rx_pkts;		/* 0x3c4 */
+	uint32	rx_broadcast_pkts;	/* 0x3c8 */
+	uint32	rx_multicast_pkts;	/* 0x3cc */
+	uint32	rx_len_64;		/* 0x3d0 */
+	uint32	rx_len_65_to_127;	/* 0x3d4 */
+	uint32	rx_len_128_to_255;	/* 0x3d8 */
+	uint32	rx_len_256_to_511;	/* 0x3dc */
+	uint32	rx_len_512_to_1023;	/* 0x3e0 */
+	uint32	rx_len_1024_to_1522;	/* 0x3e4 */
+	uint32	rx_len_1523_to_2047;	/* 0x3e8 */
+	uint32	rx_len_2048_to_4095;	/* 0x3ec */
+	uint32	rx_len_4095_to_8191;	/* 0x3f0 */
+	uint32	rx_len_8192_to_max;	/* 0x3f4 */
+	uint32	rx_jabber_pkts;		/* 0x3f8 */
+	uint32	rx_oversize_pkts;	/* 0x3fc */
+	uint32	rx_fragment_pkts;	/* 0x400 */
+	uint32	rx_missed_pkts;		/* 0x404 */
+	uint32	rx_crc_align_errs;	/* 0x408 */
+	uint32	rx_undersize;		/* 0x40c */
+	uint32	rx_crc_errs;		/* 0x410 */
+	uint32	rx_align_errs;		/* 0x414 */
+	uint32	rx_symbol_errs;		/* 0x418 */
+	uint32	rx_pause_pkts;		/* 0x41c */
+	uint32	rx_nonpause_pkts;	/* 0x420 */
+	uint32	rx_sachanges;		/* 0x424 */
+	uint32	rx_uni_pkts;		/* 0x428 */
+} gmacmib_t;
+
+#define	GM_MIB_BASE		0x300
+#define	GM_MIB_LIMIT		0x800
+
+#endif	/* _bcmgmacmib_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/include/bcmgmacrxh.h b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmgmacrxh.h
new file mode 100644
index 0000000000..364596172b
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/include/bcmgmacrxh.h
@@ -0,0 +1,51 @@
+/*
+ * Hardware-specific Receive Data Header for the
+ * Broadcom Home Networking Division
+ * BCM47XX GbE cores.
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: bcmgmacrxh.h 376342 2012-12-24 21:02:49Z $
+ */
+
+#ifndef _bcmgmacrxh_h_
+#define	_bcmgmacrxh_h_
+
+/*
+ * The Ethernet GMAC core returns an 8-byte Receive Frame Data Header
+ * with every frame consisting of
+ * 16 bits of frame length, followed by
+ * 16 bits of GMAC rx descriptor info, followed by 32bits of undefined.
+ */
+typedef volatile struct {
+	uint16	len;
+	uint16	flags;
+	uint16	pad[12];
+} bcmgmacrxh_t;
+
+#define	RXHDR_LEN	28	/* Header length */
+
+#define	GRXF_DT_MASK	((uint16)0xf)		/* data type */
+#define	GRXF_DT_SHIFT	12
+#define	GRXF_DC_MASK	((uint16)0xf)		/* (num descr to xfer the frame) - 1 */
+#define	GRXF_DC_SHIFT	8
+#define	GRXF_OVF	((uint16)1 << 7)	/* overflow error occured */
+#define	GRXF_OVERSIZE	((uint16)1 << 4)	/* frame size > rxmaxlength */
+#define	GRXF_CRC	((uint16)1 << 3)	/* crc error */
+#define	GRXF_VLAN	((uint16)1 << 2)	/* vlan tag detected */
+#define	GRXF_PT_MASK	((uint16)3)		/* packet type 0 - Unicast,
+						 * 1 - Multicast, 2 - Broadcast
+						 */
+
+#endif	/* _bcmgmacrxh_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/include/fa_core.h b/release/src-rt-7.14.114.x/src/et/cfe/include/fa_core.h
new file mode 100755
index 0000000000..80fa651698
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/include/fa_core.h
@@ -0,0 +1,261 @@
+/*
+ * Broadcom SiliconBackplane FA (Flow accelerator) definitions
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: $
+ */
+
+#ifndef	_FA_CORE_H_
+#define	_FA_CORE_H_
+
+#define FA_BASE_OFFSET		0xc00
+
+/* FA counter stats offsets */
+#define FASTAT_HIT		0	/* NAPT lookup hits count */
+#define FASTAT_MISS		1	/* NAPT lookup miss count */
+#define FASTAT_SNAP_FAIL	2	/* SNAP failures */
+#define FASTAT_TYPE_FAIL	3	/* Ethernet type failures */
+#define FASTAT_VER_FAIL		4	/* Version failures */
+#define FASTAT_FRAG_FAIL	5	/* Fragmentation Failures */
+#define FASTAT_PROT_FAIL	6	/* UDP/TCP protocol failures */
+#define FASTAT_V4CS_FAIL	7	/* IPV4 checksum failures */
+#define FASTAT_V4OP_FAIL	8	/* IPV4 option failures */
+#define FASTAT_V4HL_FAIL	9	/* IPV4 hdr len failures */
+#define FASTAT_MAX		10
+
+/* Capture address of ECC error */
+#define FAECC_NPTFL_STAT	0
+#define FAECC_NHOP_STAT		1
+#define FAECC_HWQ_STAT		2
+#define FAECC_LAB_STAT		3
+#define FAECC_HB_STAT		4
+#define FAECC_STAT_MAX		5
+
+#define FA_MAXDATA		8	/* 0:255 bits */
+
+/* Flow-Accelerator Config registers */
+typedef volatile struct _faregs {
+	uint32	control;		/* 0x0 */
+	uint32	mem_acc_ctl;		/* 0x4 */
+	uint32	bcm_hdr_ctl;		/* 0x8 */
+	uint32	l2_skip_ctl;		/* 0xc */
+	uint32	l2_tag;			/* 0x10 */
+	uint32	l2_llc_max_len;		/* 0x14 */
+	uint32	l2_snap_typelo;		/* 0x18 */
+	uint32	l2_snap_typehi;		/* 0x1c */
+	uint32	l2_ethtype;		/* 0x20 */
+	uint32	l3_ipv6_type;		/* 0x24 */
+	uint32	l3_ipv4_type;		/* 0x28 */
+	uint32	l3_napt_ctl;		/* 0x2c */
+	uint32	status;			/* 0x30 */
+	uint32	status_mask;		/* 0x34 */
+	uint32	rcv_status_en;		/* 0x38 */
+	uint32	stats[FASTAT_MAX];	/* 0x3c ... 0x60 */
+	uint32	error;			/* 0x64 */
+	uint32	error_mask;		/* 0x68 */
+	uint32	dbg_ctl;		/* 0x6c */
+	uint32	dbg_status;		/* 0x70 */
+	uint32	mem_dbg;		/* 0x74 */
+	uint32	ecc_dbg;		/* 0x78 */
+	uint32	ecc_error;		/* 0x7c */
+	uint32	ecc_error_mask;		/* 0x80 */
+	uint32	eccst[FAECC_STAT_MAX];	/* 0x84 ... 0x94 */
+	uint32	hwq_max_depth;		/* 0x98 */
+	uint32	lab_max_depth;		/* 0x9c */
+	uint32	m_accdata[FA_MAXDATA];	/* 0xa0 ... 0xa7 */
+} faregs_t;
+
+/* FA CTF Control Register(0x0) */
+#define CTF_CTL_SW_ACC_MODE			(1 << 0)
+#define CTF_CTL_BYPASS_CTF			(1 << 1)
+#define CTF_CTL_CRC_FWD				(1 << 2)
+#define CTF_CTL_CRC_OWRT			(1 << 3)
+#define CTF_CTL_HWQ_THRESHLD_MASK		(0x1FF << 4)
+#define CTF_CTL_NAPT_FLOW_INIT			(1 << 13)
+#define CTF_CTL_NEXT_HOP_INIT			(1 << 14)
+#define CTF_CTL_HWQ_INIT			(1 << 15)
+#define CTF_CTL_LAB_INIT			(1 << 16)
+#define CTF_CTL_HB_INIT				(1 << 17)
+#define CTF_CTL_DSBL_MAC_DA_CHECK		(1 << 18)
+
+#define CTF_CTL_HWQ_DEF_THRESHLD		0x140
+
+/* FA CTF Memory Access Control Register(0x4) */
+#define CTF_MEMACC_TAB_INDEX_MASK		(0x3FF << 0)
+#define CTF_MEMACC_TAB_SEL_MASK			(0x3 << 10)
+#define CTF_MEMACC_NAPT_FLOW_TAB		(~(3 << 10))
+#define CTF_MEMACC_NAPT_POOL_TAB		(1 << 10)
+#define CTF_MEMACC_NEXT_HOP_TAB			(2 << 10)
+#define CTF_MEMACC_RD_WR_N			(1 << 12)
+#define CTF_MEMACC_CUR_TBL_INDEX_MASK		(0x3FF << 13)
+
+#define CTF_MEMACC_TBL_NF			0
+#define CTF_MEMACC_TBL_NP			1
+#define CTF_MEMACC_TBL_NH			2
+#define CTF_MEMACC_RD_TABLE(t, i)		(CTF_MEMACC_RD_WR_N | (t << 10) | \
+						 (i & CTF_MEMACC_TAB_INDEX_MASK))
+#define CTF_MEMACC_WR_TABLE(t, i)		((t << 10) | (i & CTF_MEMACC_TAB_INDEX_MASK))
+
+/* FA CTF BRCM Header Control Register(0x8) */
+#define CTF_BRCM_HDR_HW_EN			(1 << 0)
+#define CTF_BRCM_HDR_SW_RX_EN			(1 << 1)
+#define CTF_BRCM_HDR_SW_TX_EN			(1 << 2)
+#define CTF_BRCM_HDR_PARSE_IGN_EN		(1 << 3)
+#define CTF_BRCM_HDR_TE				(0x3 << 4)
+#define CTF_BRCM_HDR_TC				(0x7 << 6)
+
+/* FA CTF L2 Skip Control Register(0xc) */
+#define CTF_L2SKIP_ET_SKIP_TYPE_MASK		(0xFFFF << 0)
+#define CTF_L2SKIP_ET_SKIP_BYTES_MASK		(0x7 << 16)
+#define CTF_L2SKIP_ET_SKIP_ENABLE		(1 << 19)
+#define CTF_L2SKIP_ET_TO_SNAP_CONV		(1 << 20)
+
+/* FA CTF L2 Tag Type Register(0x10) */
+#define CTF_L2TAG_ET_TAG_TYPE0_MASK		(0xFFFF << 0)
+#define CTF_L2TAG_ET_TAG_TYPE1_MASK		(0xFFFF << 16)
+
+/* FA CTF L2 LLC Max Length Register(0x14) */
+#define CTF_L2LLC_MAX_LENGTH_MASK		(0xFFFF << 0)
+#define CTF_LLC_MAX_LENGTH_DEF			0x5DC
+
+/* FA CTF L2 Ether Type Register(0x20) */
+#define CTF_L2ET_IPV6				(0xFFFF << 16)
+#define CTF_L2ET_IPV4				(0xFFFF << 0)
+
+/* FA CTF L3 IPv6 Type Register(0x24) */
+#define CTF_L3_IPV6_NEXT_HDR_TCP		(0xFF << 0)
+#define CTF_L3_IPV6_HDR_DEF_TCP			0x6
+#define CTF_L3_IPV6_NEXT_HDR_UDP		(0xFF << 8)
+#define CTF_L3_IPV6_HDR_DEF_UDP 		0x11
+
+/* FA CTF L3 IPv4 Type Register(0x28) */
+#define CTF_L3_IPV4_NEXT_HDR_TCP		(0xFF << 0)
+#define CTF_L3_IPV4_HDR_DEF_TCP			0x6
+#define CTF_L3_IPV4_NEXT_HDR_UDP		(0xFF << 8)
+#define CTF_L3_IPV4_HDR_DEF_UDP			0x11
+#define CTF_L3_IPV4_CKSUM_EN			(1 << 16)
+
+/* FA CTF L3 NAPT Control Register(0x2c) */
+#define CTFCTL_L3NAPT_HDR_DEC_TTL		(1 << 21)
+#define CTFCTL_L3NAPT_HASH_SEL			(1 << 20)
+#define CTFCTL_L3NAPT_HITS_CLR_ON_RD_EN		(1 << 19)
+#define CTFCTL_L3NAPT_TS_SHIFT			(16)
+#define CTFCTL_L3NAPT_TIMESTAMP			(0x7 << CTFCTL_L3NAPT_TS_SHIFT)
+#define CTFCTL_L3NAPT_HASH_SEED			(0xFFFF << 0)
+
+#define CTFCTL_L3NAPT_TS_NBITS	3
+#define CTFCTL_MAX_TIMESTAMP_VAL		((1 << CTFCTL_L3NAPT_TS_NBITS) - 1)
+#define CTFCTL_TIMESTAMP_MASK			((1 << CTFCTL_L3NAPT_TS_NBITS) - 1)
+#define CTFCTL_TIMESTAMP_NUM_STATES		(1 << 3)
+
+/* FA CTF Interrupt Status Register(0x30) */
+#define CTF_INTSTAT_HB_INIT_DONE		(1 << 9)
+#define CTF_INTSTAT_LAB_INIT_DONE		(1 << 8)
+#define CTF_INTSTAT_HWQ_INIT_DONE		(1 << 7)
+#define CTF_INTSTAT_NXT_HOP_INIT_DONE		(1 << 6)
+#define CTF_INTSTAT_NAPT_FLOW_INIT_DONE		(1 << 5)
+#define CTF_INTSTAT_BRCM_HDR_INIT_DONE		(1 << 4)
+#define CTF_INTSTAT_IPV4_CKSUM_ERR		(1 << 3)
+#define CTF_INTSTAT_L3_PARSE_INCOMP		(1 << 2)
+#define CTF_INTSTAT_L2_PARSE_INCOMP		(1 << 1)
+#define CTF_INTSTAT_BRCM_HDR_PARSE_INCOMP	(1 << 0)
+#define CTF_INTSTAT_INIT_DONE			(CTF_INTSTAT_HB_INIT_DONE | \
+						 CTF_INTSTAT_LAB_INIT_DONE | \
+						 CTF_INTSTAT_HWQ_INIT_DONE | \
+						 CTF_INTSTAT_NXT_HOP_INIT_DONE | \
+						 CTF_INTSTAT_NAPT_FLOW_INIT_DONE)
+
+/* FA CTF Interrupt Status Mask Register(0x34) */
+#define CTF_INTMASK_HB_INIT_DONE		~(1 << 9)
+#define CTF_INTMASK_LAB_INIT_DONE		~(1 << 8)
+#define CTF_INTMASK_HWQ_INIT_DONE		~(1 << 7)
+#define CTF_INTMASK_NXT_HOP_INIT_DONE		~(1 << 6)
+#define CTF_INTMASK_NAPT_FLOW_INIT_DONE		~(1 << 5)
+#define CTF_INTMASK_BRCM_HDR_INIT_DONE		~(1 << 4)
+#define CTF_INTMASK_IPV4_CKSUM_ERR		~(1 << 3)
+#define CTF_INTMASK_L3_PARSE_INCOMP		~(1 << 2)
+#define CTF_INTMASK_L2_PARSE_INCOMP		~(1 << 1)
+#define CTF_INTMASK_BRCM_HDR_PARSE_INCOMP	~(1 << 0)
+
+/* FA CTF Receive Status Mask Register(0x38) */
+#define CTF_RXMASK_L3PROTO_EXT_FAIL		~(1 << 7)
+#define CTF_RXMASK_L3PROTO_IPV4_HDR_LEN_FAIL	~(1 << 6)
+#define CTF_RXMASK_L3PROTO_IPV4_OPT_FAIL	~(1 << 5)
+#define CTF_RXMASK_L3PROTO_IPV4_CKSUM_FAIL	~(1 << 4)
+#define CTF_RXMASK_L3PROTO_FRAG_FAIL		~(1 << 3)
+#define CTF_RXMASK_L3PROTO_VER_FAIL		~(1 << 2)
+#define CTF_RXMASK_L3PROTO_L2ETYPE_FAIL		~(1 << 1)
+#define CTF_RXMASK_L3PROTO_L2SNAP_FAIL		~(1 << 0)
+
+/* FA CTF Error Status Register(0x64) */
+#define CTF_ERR_HWQ_OVFLOW			(1 << 8)
+#define CTF_ERR_HB_OVFLOW			(1 << 7)
+#define CTF_ERR_RXQ_OVFLOW			(1 << 6)
+#define CTF_ERR_SOP_EOP				(1 << 5)
+#define CTF_ERR_SPB_OVFLOW			(1 << 4)
+#define CTF_ERR_LAB_OVFLOW			(1 << 3)
+#define CTF_ERR_INT_MERGE			(1 << 2)
+#define CTF_ERR_TXQ_OVFLOW			(1 << 1)
+#define CTF_ERR_RB_OVFLOW			(1 << 0)
+
+/* FA CTF Error Status Mask Register(0x68) */
+#define CTF_ERR_HWQ_OVFLOW_MASK			~(1 << 8)
+#define CTF_ERR_HB_OVFLOW_MASK			~(1 << 7)
+#define CTF_ERR_RXQ_OVFLOW_MASK			~(1 << 6)
+#define CTF_ERR_SOP_EOP_MASK			~(1 << 5)
+#define CTF_ERR_SPB_OVFLOW_MASK			~(1 << 4)
+#define CTF_ERR_LAB_OVFLOW_MASK			~(1 << 3)
+#define CTF_ERR_INT_MERGE_MASK			~(1 << 2)
+#define CTF_ERR_TXQ_OVFLOW_MASK			~(1 << 1)
+#define CTF_ERR_RB_OVFLOW_MASK			~(1 << 0)
+
+/* FA CTF Debug Control Register(0x6c) */
+#define CTF_DBG_OK_TO_SEND			(0xF << 6)
+#define CTF_DBG_FORCE_ALL_HIT			(1 << 2)
+#define CTF_DBG_FORCE_ALL_MISS			(1 << 1)
+#define CTF_DBG_REG				(1 << 0)
+
+/* FA CTF Debug Control Register(0x70) */
+#define CTF_DBG_MEM_ACC_BUSY			(1 << 0)
+
+#define CTF_DATA_SIZE				8
+#define CTF_MAX_POOL_TABLE_INDEX		4
+#define CTF_MAX_NEXTHOP_TABLE_INDEX		128
+#define CTF_MAX_BUCKET_INDEX			4
+#define CTF_MAX_FLOW_TABLE			1024
+
+/* Next hop defines */
+#define CTF_NH_L2FR_TYPE_ET			0
+#define CTF_NH_L2FR_TYPE_SNAP			1
+#define CTF_NH_OP_STAG				0
+#define CTF_NH_OP_CTAG				1
+#define CTF_NH_OP_NOTAG				2
+
+/* Pool entry defines */
+#define CTF_NP_INTERNAL				0
+#define CTF_NP_EXTERNAL				1
+
+/* NAPT entry definitions */
+#define CTF_NAPT_TSTAMP_MASK			0x7
+#define CTF_NAPT_OVRW_IP			1
+#define CTF_NAPT_OVRW_PORT			2
+#define CTF_NAPT_ACTION_MASK			0x3
+#define CTF_NAPT_DMA_UNIMAC			0
+#define CTF_NAPT_DMA_IHOST			1
+
+#define CTF_FA_MACC_DATA0_TS(d)			(d[0] & CTF_NAPT_TSTAMP_MASK)
+
+#endif	/* _FA_CORE_H_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/include/gmac_common.h b/release/src-rt-7.14.114.x/src/et/cfe/include/gmac_common.h
new file mode 100644
index 0000000000..b1a137d828
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/include/gmac_common.h
@@ -0,0 +1,559 @@
+/*
+ * gmacdefs - Broadcom gmac (Unimac) specific definitions
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: gmac_common.h 376342 2012-12-24 21:02:49Z $
+ */
+
+#ifndef _gmac_common_core_h_
+#define _gmac_common_core_h_
+
+#ifndef PAD
+#define     _PADLINE(line)    pad ## line
+#define     _XSTR(line)     _PADLINE(line)
+#define     PAD     XSTR(__LINE__)
+#endif
+
+typedef volatile struct _gmac_commonregs {
+    uint32 	stag0;
+    uint32 	stag1;
+    uint32 	stag2;
+    uint32 	stag3;
+    uint32 	PAD[4];
+    uint32 	parsercontrol;
+    uint32 	mib_max_len;
+    uint32 	PAD[54];
+    uint32 	phyaccess;
+    uint32 	phycontrol;
+    uint32 	PAD[2];
+    uint32 	gmac0_rgmii_cntl;
+    uint32 	PAD[59];
+    uint32 	cfp_access;
+    uint32 	PAD[3];
+    uint32 	cfp_tcam_data0;
+    uint32 	cfp_tcam_data1;
+    uint32 	cfp_tcam_data2;
+    uint32 	cfp_tcam_data3;
+    uint32 	cfp_tcam_data4;
+    uint32 	cfp_tcam_data5;
+    uint32 	cfp_tcam_data6;
+    uint32 	cfp_tcam_data7;
+    uint32 	cfp_tcam_mask0;
+    uint32 	cfp_tcam_mask1;
+    uint32 	cfp_tcam_mask2;
+    uint32 	cfp_tcam_mask3;
+    uint32 	cfp_tcam_mask4;
+    uint32 	cfp_tcam_mask5;
+    uint32 	cfp_tcam_mask6;
+    uint32 	cfp_tcam_mask7;
+    uint32 	cfp_action_data;
+    uint32 	PAD[19];
+    uint32 	tcam_bist_cntl;
+    uint32 	tcam_bist_status;
+    uint32 	tcam_cmp_status;
+    uint32 	tcam_disable;
+    uint32 	PAD[16];
+    uint32 	tcam_test_cntl;
+    uint32 	PAD[3];
+    uint32 	udf_0_a3_a0;
+    uint32 	udf_0_a7_a4;
+    uint32 	udf_0_a8;
+    uint32 	PAD[1];
+    uint32 	udf_1_a3_a0;
+    uint32 	udf_1_a7_a4;
+    uint32 	udf_1_a8;
+    uint32 	PAD[1];
+    uint32 	udf_2_a3_a0;
+    uint32 	udf_2_a7_a4;
+    uint32 	udf_2_a8;
+    uint32 	PAD[1];
+    uint32 	udf_0_b3_b0;
+    uint32 	udf_0_b7_b4;
+    uint32 	udf_0_b8;
+    uint32 	PAD[1];
+    uint32 	udf_1_b3_b0;
+    uint32 	udf_1_b7_b4;
+    uint32 	udf_1_b8;
+    uint32 	PAD[1];
+    uint32 	udf_2_b3_b0;
+    uint32 	udf_2_b7_b4;
+    uint32 	udf_2_b8;
+    uint32 	PAD[1];
+    uint32 	udf_0_c3_c0;
+    uint32 	udf_0_c7_c4;
+    uint32 	udf_0_c8;
+    uint32 	PAD[1];
+    uint32 	udf_1_c3_c0;
+    uint32 	udf_1_c7_c4;
+    uint32 	udf_1_c8;
+    uint32 	PAD[1];
+    uint32 	udf_2_c3_c0;
+    uint32 	udf_2_c7_c4;
+    uint32 	udf_2_c8;
+    uint32 	PAD[1];
+    uint32 	udf_0_d3_d0;
+    uint32 	udf_0_d7_d4;
+    uint32 	udf_0_d11_d8;
+} gmac_commonregs_t;
+
+/*  stag0 offset0x0  */
+#define 	STAG0_TPID_SHIFT	0
+#define 	STAG0_TPID_MASK	0xffff
+
+/*  stag1 offset0x4  */
+#define 	STAG1_TPID_SHIFT	0
+#define 	STAG1_TPID_MASK	0xffff
+
+/*  stag2 offset0x8  */
+#define 	STAG2_TPID_SHIFT	0
+#define 	STAG2_TPID_MASK	0xffff
+
+/*  stag3 offset0xc  */
+#define 	STAG3_TPID_SHIFT	0
+#define 	STAG3_TPID_MASK	0xffff
+
+/*  parsercontrol offset0x20  */
+#define 	PARSERCONTROL_MAX_PARSER_LEN_TH_SHIFT	0
+#define 	PARSERCONTROL_MAX_PARSER_LEN_TH_MASK	0x3fff
+
+/*  mib_max_len offset0x24  */
+#define 	MIB_MAX_LEN_MIB_MAX_LEN_SHIFT	0
+#define 	MIB_MAX_LEN_MIB_MAX_LEN_MASK	0x3fff
+
+/*  phyaccess offset0x100  */
+#define 	PHYACCESS_TRIGGER_SHIFT	30
+#define 	PHYACCESS_TRIGGER_MASK	0x40000000
+#define 	PHYACCESS_WR_CMD_SHIFT	29
+#define 	PHYACCESS_WR_CMD_MASK	0x20000000
+#define 	PHYACCESS_CPU_REG_ADDR_SHIFT	24
+#define 	PHYACCESS_CPU_REG_ADDR_MASK	0x1f000000
+#define 	PHYACCESS_CPU_PHY_ADDR_SHIFT	16
+#define 	PHYACCESS_CPU_PHY_ADDR_MASK	0x1f0000
+#define 	PHYACCESS_ACC_DATA_SHIFT	0
+#define 	PHYACCESS_ACC_DATA_MASK	0xffff
+
+/*  phycontrol offset0x104  */
+#define 	PHYCONTROL_SD_ACCESS_EN_SHIFT	25
+#define 	PHYCONTROL_SD_ACCESS_EN_MASK	0x2000000
+#define 	PHYCONTROL_NWAY_AUTO_POLLING_EN_SHIFT	24
+#define 	PHYCONTROL_NWAY_AUTO_POLLING_EN_MASK	0x1000000
+#define 	PHYCONTROL_MDC_TRANSITION_EN_SHIFT	23
+#define 	PHYCONTROL_MDC_TRANSITION_EN_MASK	0x800000
+#define 	PHYCONTROL_MDC_CYCLE_TH_SHIFT	16
+#define 	PHYCONTROL_MDC_CYCLE_TH_MASK	0x7f0000
+#define 	PHYCONTROL_EXT_PHY_ADDR_SHIFT	0
+#define 	PHYCONTROL_EXT_PHY_ADDR_MASK	0x1f
+
+/*  gmac0_rgmii_cntl offset0x110  */
+#define 	GMAC0_RGMII_CNTL_TIMING_SEL_SHIFT	0
+#define 	GMAC0_RGMII_CNTL_TIMING_SEL_MASK	0x1
+#define 	GMAC0_RGMII_CNTL_RGMII_DLL_RXC_BYPASS_SHIFT	1
+#define 	GMAC0_RGMII_CNTL_RGMII_DLL_RXC_BYPASS_MASK	0x2
+#define 	GMAC0_RGMII_CNTL_BYPASS_2NS_DEL_SHIFT	2
+#define 	GMAC0_RGMII_CNTL_BYPASS_2NS_DEL_MASK	0x4
+#define 	GMAC0_RGMII_CNTL_DEL_STRB_SHIFT	3
+#define 	GMAC0_RGMII_CNTL_DEL_STRB_MASK	0x8
+#define 	GMAC0_RGMII_CNTL_DEL_VALUE_SHIFT	4
+#define 	GMAC0_RGMII_CNTL_DEL_VALUE_MASK	0x70
+#define 	GMAC0_RGMII_CNTL_DEL_ADDR_SHIFT	7
+#define 	GMAC0_RGMII_CNTL_DEL_ADDR_MASK	0x780
+
+/*  cfp_access offset0x200  */
+#define 	CFP_ACCESS_OP_START_DONE_SHIFT	0
+#define 	CFP_ACCESS_OP_START_DONE_MASK	0x1
+#define 	CFP_ACCESS_OP_SEL_SHIFT	1
+#define 	CFP_ACCESS_OP_SEL_MASK	0xe
+#define 	CFP_ACCESS_CFP_RAM_CLEAR_SHIFT	4
+#define 	CFP_ACCESS_CFP_RAM_CLEAR_MASK	0x10
+#define 	CFP_ACCESS_RESERVED1_SHIFT	5
+#define 	CFP_ACCESS_RESERVED1_MASK	0x3e0
+#define 	CFP_ACCESS_RAM_SEL_SHIFT	10
+#define 	CFP_ACCESS_RAM_SEL_MASK	0x7c00
+#define 	CFP_ACCESS_TCAM_RESET_SHIFT	15
+#define 	CFP_ACCESS_TCAM_RESET_MASK	0x8000
+#define 	CFP_ACCESS_XCESS_ADDR_SHIFT	16
+#define 	CFP_ACCESS_XCESS_ADDR_MASK	0x1ff0000
+#define 	CFP_ACCESS_RESERVED0_SHIFT	25
+#define 	CFP_ACCESS_RESERVED0_MASK	0xe000000
+#define 	CFP_ACCESS_RD_STATUS_SHIFT	28
+#define 	CFP_ACCESS_RD_STATUS_MASK	0xf0000000
+
+/*  cfp_tcam_data0 offset0x210  */
+#define 	CFP_TCAM_DATA0_DATA_SHIFT	0
+#define 	CFP_TCAM_DATA0_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_data1 offset0x214  */
+#define 	CFP_TCAM_DATA1_DATA_SHIFT	0
+#define 	CFP_TCAM_DATA1_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_data2 offset0x218  */
+#define 	CFP_TCAM_DATA2_DATA_SHIFT	0
+#define 	CFP_TCAM_DATA2_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_data3 offset0x21c  */
+#define 	CFP_TCAM_DATA3_DATA_SHIFT	0
+#define 	CFP_TCAM_DATA3_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_data4 offset0x220  */
+#define 	CFP_TCAM_DATA4_DATA_SHIFT	0
+#define 	CFP_TCAM_DATA4_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_data5 offset0x224  */
+#define 	CFP_TCAM_DATA5_DATA_SHIFT	0
+#define 	CFP_TCAM_DATA5_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_data6 offset0x228  */
+#define 	CFP_TCAM_DATA6_DATA_SHIFT	0
+#define 	CFP_TCAM_DATA6_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_data7 offset0x22c  */
+#define 	CFP_TCAM_DATA7_DATA_SHIFT	0
+#define 	CFP_TCAM_DATA7_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_mask0 offset0x230  */
+#define 	CFP_TCAM_MASK0_DATA_SHIFT	0
+#define 	CFP_TCAM_MASK0_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_mask1 offset0x234  */
+#define 	CFP_TCAM_MASK1_DATA_SHIFT	0
+#define 	CFP_TCAM_MASK1_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_mask2 offset0x238  */
+#define 	CFP_TCAM_MASK2_DATA_SHIFT	0
+#define 	CFP_TCAM_MASK2_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_mask3 offset0x23c  */
+#define 	CFP_TCAM_MASK3_DATA_SHIFT	0
+#define 	CFP_TCAM_MASK3_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_mask4 offset0x240  */
+#define 	CFP_TCAM_MASK4_DATA_SHIFT	0
+#define 	CFP_TCAM_MASK4_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_mask5 offset0x244  */
+#define 	CFP_TCAM_MASK5_DATA_SHIFT	0
+#define 	CFP_TCAM_MASK5_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_mask6 offset0x248  */
+#define 	CFP_TCAM_MASK6_DATA_SHIFT	0
+#define 	CFP_TCAM_MASK6_DATA_MASK	0xffffffff
+
+/*  cfp_tcam_mask7 offset0x24c  */
+#define 	CFP_TCAM_MASK7_DATA_SHIFT	0
+#define 	CFP_TCAM_MASK7_DATA_MASK	0xffffffff
+
+/*  cfp_action_data offset0x250  */
+#define 	CFP_ACTION_DATA_CHAINID_SHIFT	0
+#define 	CFP_ACTION_DATA_CHAINID_MASK	0xff
+#define 	CFP_ACTION_DATA_CHANNELID_SHIFT	8
+#define 	CFP_ACTION_DATA_CHANNELID_MASK	0xf00
+#define 	CFP_ACTION_DATA_DROP_SHIFT	12
+#define 	CFP_ACTION_DATA_DROP_MASK	0x1000
+#define 	CFP_ACTION_DATA_RESERVED_SHIFT	13
+#define 	CFP_ACTION_DATA_RESERVED_MASK	0xffffe000
+
+/*  tcam_bist_cntl offset0x2a0  */
+#define 	TCAM_BIST_CNTL_TCAM_BIST_EN_SHIFT	0
+#define 	TCAM_BIST_CNTL_TCAM_BIST_EN_MASK	0x1
+#define 	TCAM_BIST_CNTL_TCAM_BIST_TCAM_SEL_SHIFT	1
+#define 	TCAM_BIST_CNTL_TCAM_BIST_TCAM_SEL_MASK	0x6
+#define 	TCAM_BIST_CNTL_RESERVED1_SHIFT	3
+#define 	TCAM_BIST_CNTL_RESERVED1_MASK	0x8
+#define 	TCAM_BIST_CNTL_TCAM_BIST_STATUS_SEL_SHIFT	4
+#define 	TCAM_BIST_CNTL_TCAM_BIST_STATUS_SEL_MASK	0xf0
+#define 	TCAM_BIST_CNTL_TCAM_BIST_SKIP_ERR_CNT_SHIFT	8
+#define 	TCAM_BIST_CNTL_TCAM_BIST_SKIP_ERR_CNT_MASK	0xff00
+#define 	TCAM_BIST_CNTL_TCAM_TEST_COMPARE_SHIFT	16
+#define 	TCAM_BIST_CNTL_TCAM_TEST_COMPARE_MASK	0x10000
+#define 	TCAM_BIST_CNTL_RESERVED_SHIFT	17
+#define 	TCAM_BIST_CNTL_RESERVED_MASK	0x7ffe0000
+#define 	TCAM_BIST_CNTL_TCAM_BIST_DONE_SHIFT	31
+#define 	TCAM_BIST_CNTL_TCAM_BIST_DONE_MASK	0x80000000
+
+/*  tcam_bist_status offset0x2a4  */
+#define 	TCAM_BIST_STATUS_TCAM_BIST_STATUS_SHIFT	0
+#define 	TCAM_BIST_STATUS_TCAM_BIST_STATUS_MASK	0xffff
+#define 	TCAM_BIST_STATUS_RESERVED_SHIFT	16
+#define 	TCAM_BIST_STATUS_RESERVED_MASK	0xffff0000
+
+/*  tcam_cmp_status offset0x2a8  */
+#define 	TCAM_CMP_STATUS_TCAM_HIT_ADDR_SHIFT	0
+#define 	TCAM_CMP_STATUS_TCAM_HIT_ADDR_MASK	0x1ff
+#define 	TCAM_CMP_STATUS_RESERVED2_SHIFT	9
+#define 	TCAM_CMP_STATUS_RESERVED2_MASK	0x7e00
+#define 	TCAM_CMP_STATUS_TCAM_HIT_SHIFT	15
+#define 	TCAM_CMP_STATUS_TCAM_HIT_MASK	0x8000
+#define 	TCAM_CMP_STATUS_RESERVED1_SHIFT	16
+#define 	TCAM_CMP_STATUS_RESERVED1_MASK	0xffff0000
+
+/*  tcam_disable offset0x2ac  */
+#define 	TCAM_DISABLE_TCAM_DISABLE_SHIFT	0
+#define 	TCAM_DISABLE_TCAM_DISABLE_MASK	0xf
+#define 	TCAM_DISABLE_RESERVED_SHIFT	4
+#define 	TCAM_DISABLE_RESERVED_MASK	0xfffffff0
+
+/*  tcam_test_cntl offset0x2f0  */
+#define 	TCAM_TEST_CNTL_TCAM_TEST_CNTL_SHIFT	0
+#define 	TCAM_TEST_CNTL_TCAM_TEST_CNTL_MASK	0x7ff
+#define 	TCAM_TEST_CNTL_RESERVED_SHIFT	11
+#define 	TCAM_TEST_CNTL_RESERVED_MASK	0xfffff800
+
+/*  udf_0_a3_a0 offset0x300  */
+#define 	UDF_0_A3_A0_CFG_UDF_0_A0_SHIFT	0
+#define 	UDF_0_A3_A0_CFG_UDF_0_A0_MASK	0xff
+#define 	UDF_0_A3_A0_CFG_UDF_0_A1_SHIFT	8
+#define 	UDF_0_A3_A0_CFG_UDF_0_A1_MASK	0xff00
+#define 	UDF_0_A3_A0_CFG_UDF_0_A2_SHIFT	16
+#define 	UDF_0_A3_A0_CFG_UDF_0_A2_MASK	0xff0000
+#define 	UDF_0_A3_A0_CFG_UDF_0_A3_SHIFT	24
+#define 	UDF_0_A3_A0_CFG_UDF_0_A3_MASK	0xff000000
+
+/*  udf_0_a7_a4 offset0x304  */
+#define 	UDF_0_A7_A4_CFG_UDF_0_A4_SHIFT	0
+#define 	UDF_0_A7_A4_CFG_UDF_0_A4_MASK	0xff
+#define 	UDF_0_A7_A4_CFG_UDF_0_A5_SHIFT	8
+#define 	UDF_0_A7_A4_CFG_UDF_0_A5_MASK	0xff00
+#define 	UDF_0_A7_A4_CFG_UDF_0_A6_SHIFT	16
+#define 	UDF_0_A7_A4_CFG_UDF_0_A6_MASK	0xff0000
+#define 	UDF_0_A7_A4_CFG_UDF_0_A7_SHIFT	24
+#define 	UDF_0_A7_A4_CFG_UDF_0_A7_MASK	0xff000000
+
+/*  udf_0_a8 offset0x308  */
+#define 	UDF_0_A8_CFG_UDF_0_A8_SHIFT	0
+#define 	UDF_0_A8_CFG_UDF_0_A8_MASK	0xff
+
+/*  udf_1_a3_a0 offset0x310  */
+#define 	UDF_1_A3_A0_CFG_UDF_1_A0_SHIFT	0
+#define 	UDF_1_A3_A0_CFG_UDF_1_A0_MASK	0xff
+#define 	UDF_1_A3_A0_CFG_UDF_1_A1_SHIFT	8
+#define 	UDF_1_A3_A0_CFG_UDF_1_A1_MASK	0xff00
+#define 	UDF_1_A3_A0_CFG_UDF_1_A2_SHIFT	16
+#define 	UDF_1_A3_A0_CFG_UDF_1_A2_MASK	0xff0000
+#define 	UDF_1_A3_A0_CFG_UDF_1_A3_SHIFT	24
+#define 	UDF_1_A3_A0_CFG_UDF_1_A3_MASK	0xff000000
+
+/*  udf_1_a7_a4 offset0x314  */
+#define 	UDF_1_A7_A4_CFG_UDF_1_A4_SHIFT	0
+#define 	UDF_1_A7_A4_CFG_UDF_1_A4_MASK	0xff
+#define 	UDF_1_A7_A4_CFG_UDF_1_A5_SHIFT	8
+#define 	UDF_1_A7_A4_CFG_UDF_1_A5_MASK	0xff00
+#define 	UDF_1_A7_A4_CFG_UDF_1_A6_SHIFT	16
+#define 	UDF_1_A7_A4_CFG_UDF_1_A6_MASK	0xff0000
+#define 	UDF_1_A7_A4_CFG_UDF_1_A7_SHIFT	24
+#define 	UDF_1_A7_A4_CFG_UDF_1_A7_MASK	0xff000000
+
+/*  udf_1_a8 offset0x318  */
+#define 	UDF_1_A8_CFG_UDF_1_A8_SHIFT	0
+#define 	UDF_1_A8_CFG_UDF_1_A8_MASK	0xff
+
+/*  udf_2_a3_a0 offset0x320  */
+#define 	UDF_2_A3_A0_CFG_UDF_2_A0_SHIFT	0
+#define 	UDF_2_A3_A0_CFG_UDF_2_A0_MASK	0xff
+#define 	UDF_2_A3_A0_CFG_UDF_2_A1_SHIFT	8
+#define 	UDF_2_A3_A0_CFG_UDF_2_A1_MASK	0xff00
+#define 	UDF_2_A3_A0_CFG_UDF_2_A2_SHIFT	16
+#define 	UDF_2_A3_A0_CFG_UDF_2_A2_MASK	0xff0000
+#define 	UDF_2_A3_A0_CFG_UDF_2_A3_SHIFT	24
+#define 	UDF_2_A3_A0_CFG_UDF_2_A3_MASK	0xff000000
+
+/*  udf_2_a7_a4 offset0x324  */
+#define 	UDF_2_A7_A4_CFG_UDF_2_A4_SHIFT	0
+#define 	UDF_2_A7_A4_CFG_UDF_2_A4_MASK	0xff
+#define 	UDF_2_A7_A4_CFG_UDF_2_A5_SHIFT	8
+#define 	UDF_2_A7_A4_CFG_UDF_2_A5_MASK	0xff00
+#define 	UDF_2_A7_A4_CFG_UDF_2_A6_SHIFT	16
+#define 	UDF_2_A7_A4_CFG_UDF_2_A6_MASK	0xff0000
+#define 	UDF_2_A7_A4_CFG_UDF_2_A7_SHIFT	24
+#define 	UDF_2_A7_A4_CFG_UDF_2_A7_MASK	0xff000000
+
+/*  udf_2_a8 offset0x328  */
+#define 	UDF_2_A8_CFG_UDF_2_A8_SHIFT	0
+#define 	UDF_2_A8_CFG_UDF_2_A8_MASK	0xff
+
+/*  udf_0_b3_b0 offset0x330  */
+#define 	UDF_0_B3_B0_CFG_UDF_0_B0_SHIFT	0
+#define 	UDF_0_B3_B0_CFG_UDF_0_B0_MASK	0xff
+#define 	UDF_0_B3_B0_CFG_UDF_0_B1_SHIFT	8
+#define 	UDF_0_B3_B0_CFG_UDF_0_B1_MASK	0xff00
+#define 	UDF_0_B3_B0_CFG_UDF_0_B2_SHIFT	16
+#define 	UDF_0_B3_B0_CFG_UDF_0_B2_MASK	0xff0000
+#define 	UDF_0_B3_B0_CFG_UDF_0_B3_SHIFT	24
+#define 	UDF_0_B3_B0_CFG_UDF_0_B3_MASK	0xff000000
+
+/*  udf_0_b7_b4 offset0x334  */
+#define 	UDF_0_B7_B4_CFG_UDF_0_B4_SHIFT	0
+#define 	UDF_0_B7_B4_CFG_UDF_0_B4_MASK	0xff
+#define 	UDF_0_B7_B4_CFG_UDF_0_B5_SHIFT	8
+#define 	UDF_0_B7_B4_CFG_UDF_0_B5_MASK	0xff00
+#define 	UDF_0_B7_B4_CFG_UDF_0_B6_SHIFT	16
+#define 	UDF_0_B7_B4_CFG_UDF_0_B6_MASK	0xff0000
+#define 	UDF_0_B7_B4_CFG_UDF_0_B7_SHIFT	24
+#define 	UDF_0_B7_B4_CFG_UDF_0_B7_MASK	0xff000000
+
+/*  udf_0_b8 offset0x338  */
+#define 	UDF_0_B8_CFG_UDF_0_B8_SHIFT	0
+#define 	UDF_0_B8_CFG_UDF_0_B8_MASK	0xff
+
+/*  udf_1_b3_b0 offset0x340  */
+#define 	UDF_1_B3_B0_CFG_UDF_1_B0_SHIFT	0
+#define 	UDF_1_B3_B0_CFG_UDF_1_B0_MASK	0xff
+#define 	UDF_1_B3_B0_CFG_UDF_1_B1_SHIFT	8
+#define 	UDF_1_B3_B0_CFG_UDF_1_B1_MASK	0xff00
+#define 	UDF_1_B3_B0_CFG_UDF_1_B2_SHIFT	16
+#define 	UDF_1_B3_B0_CFG_UDF_1_B2_MASK	0xff0000
+#define 	UDF_1_B3_B0_CFG_UDF_1_B3_SHIFT	24
+#define 	UDF_1_B3_B0_CFG_UDF_1_B3_MASK	0xff000000
+
+/*  udf_1_b7_b4 offset0x344  */
+#define 	UDF_1_B7_B4_CFG_UDF_1_B4_SHIFT	0
+#define 	UDF_1_B7_B4_CFG_UDF_1_B4_MASK	0xff
+#define 	UDF_1_B7_B4_CFG_UDF_1_B5_SHIFT	8
+#define 	UDF_1_B7_B4_CFG_UDF_1_B5_MASK	0xff00
+#define 	UDF_1_B7_B4_CFG_UDF_1_B6_SHIFT	16
+#define 	UDF_1_B7_B4_CFG_UDF_1_B6_MASK	0xff0000
+#define 	UDF_1_B7_B4_CFG_UDF_1_B7_SHIFT	24
+#define 	UDF_1_B7_B4_CFG_UDF_1_B7_MASK	0xff000000
+
+/*  udf_1_b8 offset0x348  */
+#define 	UDF_1_B8_CFG_UDF_1_B8_SHIFT	0
+#define 	UDF_1_B8_CFG_UDF_1_B8_MASK	0xff
+
+/*  udf_2_b3_b0 offset0x350  */
+#define 	UDF_2_B3_B0_CFG_UDF_2_B0_SHIFT	0
+#define 	UDF_2_B3_B0_CFG_UDF_2_B0_MASK	0xff
+#define 	UDF_2_B3_B0_CFG_UDF_2_B1_SHIFT	8
+#define 	UDF_2_B3_B0_CFG_UDF_2_B1_MASK	0xff00
+#define 	UDF_2_B3_B0_CFG_UDF_2_B2_SHIFT	16
+#define 	UDF_2_B3_B0_CFG_UDF_2_B2_MASK	0xff0000
+#define 	UDF_2_B3_B0_CFG_UDF_2_B3_SHIFT	24
+#define 	UDF_2_B3_B0_CFG_UDF_2_B3_MASK	0xff000000
+
+/*  udf_2_b7_b4 offset0x354  */
+#define 	UDF_2_B7_B4_CFG_UDF_2_B4_SHIFT	0
+#define 	UDF_2_B7_B4_CFG_UDF_2_B4_MASK	0xff
+#define 	UDF_2_B7_B4_CFG_UDF_2_B5_SHIFT	8
+#define 	UDF_2_B7_B4_CFG_UDF_2_B5_MASK	0xff00
+#define 	UDF_2_B7_B4_CFG_UDF_2_B6_SHIFT	16
+#define 	UDF_2_B7_B4_CFG_UDF_2_B6_MASK	0xff0000
+#define 	UDF_2_B7_B4_CFG_UDF_2_B7_SHIFT	24
+#define 	UDF_2_B7_B4_CFG_UDF_2_B7_MASK	0xff000000
+
+/*  udf_2_b8 offset0x358  */
+#define 	UDF_2_B8_CFG_UDF_2_B8_SHIFT	0
+#define 	UDF_2_B8_CFG_UDF_2_B8_MASK	0xff
+
+/*  udf_0_c3_c0 offset0x360  */
+#define 	UDF_0_C3_C0_CFG_UDF_0_C0_SHIFT	0
+#define 	UDF_0_C3_C0_CFG_UDF_0_C0_MASK	0xff
+#define 	UDF_0_C3_C0_CFG_UDF_0_C1_SHIFT	8
+#define 	UDF_0_C3_C0_CFG_UDF_0_C1_MASK	0xff00
+#define 	UDF_0_C3_C0_CFG_UDF_0_C2_SHIFT	16
+#define 	UDF_0_C3_C0_CFG_UDF_0_C2_MASK	0xff0000
+#define 	UDF_0_C3_C0_CFG_UDF_0_C3_SHIFT	24
+#define 	UDF_0_C3_C0_CFG_UDF_0_C3_MASK	0xff000000
+
+/*  udf_0_c7_c4 offset0x364  */
+#define 	UDF_0_C7_C4_CFG_UDF_0_C4_SHIFT	0
+#define 	UDF_0_C7_C4_CFG_UDF_0_C4_MASK	0xff
+#define 	UDF_0_C7_C4_CFG_UDF_0_C5_SHIFT	8
+#define 	UDF_0_C7_C4_CFG_UDF_0_C5_MASK	0xff00
+#define 	UDF_0_C7_C4_CFG_UDF_0_C6_SHIFT	16
+#define 	UDF_0_C7_C4_CFG_UDF_0_C6_MASK	0xff0000
+#define 	UDF_0_C7_C4_CFG_UDF_0_C7_SHIFT	24
+#define 	UDF_0_C7_C4_CFG_UDF_0_C7_MASK	0xff000000
+
+/*  udf_0_c8 offset0x368  */
+#define 	UDF_0_C8_CFG_UDF_0_C8_SHIFT	0
+#define 	UDF_0_C8_CFG_UDF_0_C8_MASK	0xff
+
+/*  udf_1_c3_c0 offset0x370  */
+#define 	UDF_1_C3_C0_CFG_UDF_1_C0_SHIFT	0
+#define 	UDF_1_C3_C0_CFG_UDF_1_C0_MASK	0xff
+#define 	UDF_1_C3_C0_CFG_UDF_1_C1_SHIFT	8
+#define 	UDF_1_C3_C0_CFG_UDF_1_C1_MASK	0xff00
+#define 	UDF_1_C3_C0_CFG_UDF_1_C2_SHIFT	16
+#define 	UDF_1_C3_C0_CFG_UDF_1_C2_MASK	0xff0000
+#define 	UDF_1_C3_C0_CFG_UDF_1_C3_SHIFT	24
+#define 	UDF_1_C3_C0_CFG_UDF_1_C3_MASK	0xff000000
+
+/*  udf_1_c7_c4 offset0x374  */
+#define 	UDF_1_C7_C4_CFG_UDF_1_C4_SHIFT	0
+#define 	UDF_1_C7_C4_CFG_UDF_1_C4_MASK	0xff
+#define 	UDF_1_C7_C4_CFG_UDF_1_C5_SHIFT	8
+#define 	UDF_1_C7_C4_CFG_UDF_1_C5_MASK	0xff00
+#define 	UDF_1_C7_C4_CFG_UDF_1_C6_SHIFT	16
+#define 	UDF_1_C7_C4_CFG_UDF_1_C6_MASK	0xff0000
+#define 	UDF_1_C7_C4_CFG_UDF_1_C7_SHIFT	24
+#define 	UDF_1_C7_C4_CFG_UDF_1_C7_MASK	0xff000000
+
+/*  udf_1_c8 offset0x378  */
+#define 	UDF_1_C8_CFG_UDF_1_C8_SHIFT	0
+#define 	UDF_1_C8_CFG_UDF_1_C8_MASK	0xff
+
+/*  udf_2_c3_c0 offset0x380  */
+#define 	UDF_2_C3_C0_CFG_UDF_2_C0_SHIFT	0
+#define 	UDF_2_C3_C0_CFG_UDF_2_C0_MASK	0xff
+#define 	UDF_2_C3_C0_CFG_UDF_2_C1_SHIFT	8
+#define 	UDF_2_C3_C0_CFG_UDF_2_C1_MASK	0xff00
+#define 	UDF_2_C3_C0_CFG_UDF_2_C2_SHIFT	16
+#define 	UDF_2_C3_C0_CFG_UDF_2_C2_MASK	0xff0000
+#define 	UDF_2_C3_C0_CFG_UDF_2_C3_SHIFT	24
+#define 	UDF_2_C3_C0_CFG_UDF_2_C3_MASK	0xff000000
+
+/*  udf_2_c7_c4 offset0x384  */
+#define 	UDF_2_C7_C4_CFG_UDF_2_C4_SHIFT	0
+#define 	UDF_2_C7_C4_CFG_UDF_2_C4_MASK	0xff
+#define 	UDF_2_C7_C4_CFG_UDF_2_C5_SHIFT	8
+#define 	UDF_2_C7_C4_CFG_UDF_2_C5_MASK	0xff00
+#define 	UDF_2_C7_C4_CFG_UDF_2_C6_SHIFT	16
+#define 	UDF_2_C7_C4_CFG_UDF_2_C6_MASK	0xff0000
+#define 	UDF_2_C7_C4_CFG_UDF_2_C7_SHIFT	24
+#define 	UDF_2_C7_C4_CFG_UDF_2_C7_MASK	0xff000000
+
+/*  udf_2_c8 offset0x388  */
+#define 	UDF_2_C8_CFG_UDF_2_C8_SHIFT	0
+#define 	UDF_2_C8_CFG_UDF_2_C8_MASK	0xff
+
+/*  udf_0_d3_d0 offset0x390  */
+#define 	UDF_0_D3_D0_CFG_UDF_0_D0_SHIFT	0
+#define 	UDF_0_D3_D0_CFG_UDF_0_D0_MASK	0xff
+#define 	UDF_0_D3_D0_CFG_UDF_0_D1_SHIFT	8
+#define 	UDF_0_D3_D0_CFG_UDF_0_D1_MASK	0xff00
+#define 	UDF_0_D3_D0_CFG_UDF_0_D2_SHIFT	16
+#define 	UDF_0_D3_D0_CFG_UDF_0_D2_MASK	0xff0000
+#define 	UDF_0_D3_D0_CFG_UDF_0_D3_SHIFT	24
+#define 	UDF_0_D3_D0_CFG_UDF_0_D3_MASK	0xff000000
+
+/*  udf_0_d7_d4 offset0x394  */
+#define 	UDF_0_D7_D4_CFG_UDF_0_D4_SHIFT	0
+#define 	UDF_0_D7_D4_CFG_UDF_0_D4_MASK	0xff
+#define 	UDF_0_D7_D4_CFG_UDF_0_D5_SHIFT	8
+#define 	UDF_0_D7_D4_CFG_UDF_0_D5_MASK	0xff00
+#define 	UDF_0_D7_D4_CFG_UDF_0_D6_SHIFT	16
+#define 	UDF_0_D7_D4_CFG_UDF_0_D6_MASK	0xff0000
+#define 	UDF_0_D7_D4_CFG_UDF_0_D7_SHIFT	24
+#define 	UDF_0_D7_D4_CFG_UDF_0_D7_MASK	0xff000000
+
+/*  udf_0_d11_d8 offset0x398  */
+#define 	UDF_0_D11_D8_CFG_UDF_0_D8_SHIFT	0
+#define 	UDF_0_D11_D8_CFG_UDF_0_D8_MASK	0xff
+#define 	UDF_0_D11_D8_CFG_UDF_0_D9_SHIFT	8
+#define 	UDF_0_D11_D8_CFG_UDF_0_D9_MASK	0xff00
+#define 	UDF_0_D11_D8_CFG_UDF_0_D10_SHIFT	16
+#define 	UDF_0_D11_D8_CFG_UDF_0_D10_MASK	0xff0000
+#define 	UDF_0_D11_D8_CFG_UDF_0_D11_SHIFT	24
+#define 	UDF_0_D11_D8_CFG_UDF_0_D11_MASK	0xff000000
+
+#endif /* _gmac_common_core_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/include/gmac_core.h b/release/src-rt-7.14.114.x/src/et/cfe/include/gmac_core.h
new file mode 100644
index 0000000000..789d5078ed
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/include/gmac_core.h
@@ -0,0 +1,279 @@
+/*
+ * gmacdefs - Broadcom gmac (Unimac) specific definitions
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: gmac_core.h 376342 2012-12-24 21:02:49Z $
+ */
+
+#ifndef	_gmac_core_h_
+#define	_gmac_core_h_
+
+
+/* cpp contortions to concatenate w/arg prescan */
+#ifndef PAD
+#define	_PADLINE(line)	pad ## line
+#define	_XSTR(line)	_PADLINE(line)
+#define	PAD		_XSTR(__LINE__)
+#endif	/* PAD */
+
+/* We have 4 DMA TX channels */
+#define	GMAC_NUM_DMA_TX		4
+
+typedef volatile struct {
+	dma64regs_t	dmaxmt;		/* dma tx */
+	uint32 PAD[2];
+	dma64regs_t	dmarcv;		/* dma rx */
+	uint32 PAD[2];
+} dma64_t;
+
+/*
+ * Host Interface Registers
+ */
+typedef volatile struct _gmacregs {
+	uint32	devcontrol;		/* 0x000 */
+	uint32	devstatus;		/* 0x004 */
+	uint32	PAD;
+	uint32	biststatus;		/* 0x00c */
+	uint32	PAD[4];
+	uint32	intstatus;		/* 0x020 */
+	uint32	intmask;		/* 0x024 */
+	uint32	gptimer;		/* 0x028 */
+	uint32	PAD[53];
+	uint32	intrecvlazy;		/* 0x100 */
+	uint32	flowctlthresh;		/* 0x104 */
+	uint32	wrrthresh;		/* 0x108 */
+	uint32	gmac_idle_cnt_thresh;	/* 0x10c */
+	uint32	PAD[28];
+	uint32	phyaccess;		/* 0x180 */
+	uint32	PAD;
+	uint32	phycontrol;		/* 0x188 */
+	uint32	txqctl;			/* 0x18c */
+	uint32	rxqctl;			/* 0x190 */
+	uint32	gpioselect;		/* 0x194 */
+	uint32	gpio_output_en;		/* 0x198 */
+	uint32	PAD[17];
+	uint32	clk_ctl_st;		/* 0x1e0 */
+	uint32	hw_war;			/* 0x1e4 */
+	uint32	pwrctl;			/* 0x1e8 */
+	uint32	PAD[5];
+
+	dma64_t dmaregs[GMAC_NUM_DMA_TX];
+
+	/* GAMC MIB counters */
+	gmacmib_t	mib;
+	uint32	PAD[245];
+
+	uint32	unimacversion;		/* 0x800 */
+	uint32	hdbkpctl;		/* 0x804 */
+	uint32	cmdcfg;			/* 0x808 */
+	uint32	macaddrhigh;		/* 0x80c */
+	uint32	macaddrlow;		/* 0x810 */
+	uint32	rxmaxlength;		/* 0x814 */
+	uint32	pausequanta;		/* 0x818 */
+	uint32	PAD[10];
+	uint32	macmode;		/* 0x844 */
+	uint32	outertag;		/* 0x848 */
+	uint32	innertag;		/* 0x84c */
+	uint32	PAD[3];
+	uint32	txipg;			/* 0x85c */
+	uint32	PAD[180];
+	uint32	pausectl;		/* 0xb30 */
+	uint32	txflush;		/* 0xb34 */
+	uint32	rxstatus;		/* 0xb38 */
+	uint32	txstatus;		/* 0xb3c */
+} gmacregs_t;
+
+#define	GM_MIB_BASE		0x300
+#define	GM_MIB_LIMIT		0x800
+
+/*
+ * register-specific flag definitions
+ */
+
+/* device control */
+#define	DC_TSM			0x00000002
+#define	DC_CFCO			0x00000004
+#define	DC_RLSS			0x00000008
+#define	DC_MROR			0x00000010
+#define	DC_FCM_MASK		0x00000060
+#define	DC_FCM_SHIFT		5
+#define	DC_NAE			0x00000080
+#define	DC_TF			0x00000100
+#define	DC_RDS_MASK		0x00030000
+#define	DC_RDS_SHIFT		16
+#define	DC_TDS_MASK		0x000c0000
+#define	DC_TDS_SHIFT		18
+
+/* device status */
+#define	DS_RBF			0x00000001
+#define	DS_RDF			0x00000002
+#define	DS_RIF			0x00000004
+#define	DS_TBF			0x00000008
+#define	DS_TDF			0x00000010
+#define	DS_TIF			0x00000020
+#define	DS_PO			0x00000040
+#define	DS_MM_MASK		0x00000300
+#define	DS_MM_SHIFT		8
+
+/* bist status */
+#define	BS_MTF			0x00000001
+#define	BS_MRF			0x00000002
+#define	BS_TDB			0x00000004
+#define	BS_TIB			0x00000008
+#define	BS_TBF			0x00000010
+#define	BS_RDB			0x00000020
+#define	BS_RIB			0x00000040
+#define	BS_RBF			0x00000080
+#define	BS_URTF			0x00000100
+#define	BS_UTF			0x00000200
+#define	BS_URF			0x00000400
+
+/* interrupt status and mask registers */
+#define	I_MRO			0x00000001
+#define	I_MTO			0x00000002
+#define	I_TFD			0x00000004
+#define	I_LS			0x00000008
+#define	I_MDIO			0x00000010
+#define	I_MR			0x00000020
+#define	I_MT			0x00000040
+#define	I_TO			0x00000080
+#define	I_PDEE			0x00000400
+#define	I_PDE			0x00000800
+#define	I_DE			0x00001000
+#define	I_RDU			0x00002000
+#define	I_RFO			0x00004000
+#define	I_XFU			0x00008000
+#define	I_RI			0x00010000
+#define	I_XI0			0x01000000
+#define	I_XI1			0x02000000
+#define	I_XI2			0x04000000
+#define	I_XI3			0x08000000
+#define	I_INTMASK		0x0f01fcff
+#define	I_ERRMASK		0x0000fc00
+
+/* interrupt receive lazy */
+#define	IRL_TO_MASK		0x00ffffff
+#define	IRL_FC_MASK		0xff000000
+#define	IRL_FC_SHIFT		24
+
+/* flow control thresholds */
+#define	FCT_TT_MASK		0x00000fff
+#define	FCT_RT_MASK		0x0fff0000
+#define	FCT_RT_SHIFT		16
+
+/* txq aribter wrr thresholds */
+#define	WRRT_Q0T_MASK		0x000000ff
+#define	WRRT_Q1T_MASK		0x0000ff00
+#define	WRRT_Q1T_SHIFT		8
+#define	WRRT_Q2T_MASK		0x00ff0000
+#define	WRRT_Q2T_SHIFT		16
+#define	WRRT_Q3T_MASK		0xff000000
+#define	WRRT_Q3T_SHIFT		24
+
+/* phy access */
+#define	PA_DATA_MASK		0x0000ffff
+#define	PA_ADDR_MASK		0x001f0000
+#define	PA_ADDR_SHIFT		16
+#define	PA_REG_MASK		0x1f000000
+#define	PA_REG_SHIFT		24
+#define	PA_WRITE		0x20000000
+#define	PA_START		0x40000000
+
+/* phy control */
+#define	PC_EPA_MASK		0x0000001f
+#define	PC_MCT_MASK		0x007f0000
+#define	PC_MCT_SHIFT		16
+#define	PC_MTE			0x00800000
+
+/* rxq control */
+#define	RC_DBT_MASK		0x00000fff
+#define	RC_DBT_SHIFT		0
+#define	RC_PTE			0x00001000
+#define	RC_MDP_MASK		0x3f000000
+#define	RC_MDP_SHIFT		24
+
+#define RC_MAC_DATA_PERIOD	9
+
+/* txq control */
+#define	TC_DBT_MASK		0x00000fff
+#define	TC_DBT_SHIFT		0
+
+/* gpio select */
+#define	GS_GSC_MASK		0x0000000f
+#define	GS_GSC_SHIFT		0
+
+/* gpio output enable */
+#define	GS_GOE_MASK		0x0000ffff
+#define	GS_GOE_SHIFT		0
+
+/* clk control status */
+#define CS_FA			0x00000001
+#define CS_FH			0x00000002
+#define CS_FI			0x00000004
+#define CS_AQ			0x00000008
+#define CS_HQ			0x00000010
+#define CS_FC			0x00000020
+#define CS_ER			0x00000100
+#define CS_AA			0x00010000
+#define CS_HA			0x00020000
+#define CS_BA			0x00040000
+#define CS_BH			0x00080000
+#define CS_ES			0x01000000
+
+/* command config */
+#define	CC_TE			0x00000001
+#define	CC_RE			0x00000002
+#define	CC_ES_MASK		0x0000000c
+#define	CC_ES_SHIFT		2
+#define	CC_PROM			0x00000010
+#define	CC_PAD_EN		0x00000020
+#define	CC_CF			0x00000040
+#define	CC_PF			0x00000080
+#define	CC_RPI			0x00000100
+#define	CC_TAI			0x00000200
+#define	CC_HD			0x00000400
+#define	CC_HD_SHIFT		10
+#define CC_SR(corerev)  ((corerev >= 4) ? 0x00002000 : 0x00000800)
+#define	CC_ML			0x00008000
+#define	CC_AE			0x00400000
+#define	CC_CFE			0x00800000
+#define	CC_NLC			0x01000000
+#define	CC_RL			0x02000000
+#define	CC_RED			0x04000000
+#define	CC_PE			0x08000000
+#define	CC_TPI			0x10000000
+#define	CC_AT			0x20000000
+
+/* mac addr high */
+#define	MH_HI_MASK		0xffff
+#define	MH_HI_SHIFT		16
+#define	MH_MID_MASK		0xffff
+#define	MH_MID_SHIFT		0
+
+/* mac addr low */
+#define	ML_LO_MASK		0xffff
+#define	ML_LO_SHIFT		0
+
+/* Core specific control flags */
+#define SICF_SWCLKE		0x0004
+#define SICF_SWRST		0x0008
+
+/* Core specific status flags */
+#define SISF_SW_ATTACHED	0x0800
+
+/* 4707 has 4 GMAC and need to be reset before start access */
+#define MAX_GMAC_CORES_4707	4
+
+#endif	/* _gmac_core_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/.gitignore b/release/src-rt-7.14.114.x/src/et/cfe/sys/.gitignore
new file mode 100755
index 0000000000..b69095feca
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/.gitignore
@@ -0,0 +1,2 @@
+*.o
+*.cmd
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfe.c b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfe.c
new file mode 100644
index 0000000000..2db2efa545
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfe.c
@@ -0,0 +1,660 @@
+/*
+ * CFE polled-mode device driver for
+ * Broadcom BCM47XX 10/100 Mbps Ethernet Controller
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: et_cfe.c 380255 2013-01-22 03:15:28Z $
+ */
+
+#include <et_cfg.h>
+#include "lib_types.h"
+#include "lib_malloc.h"
+#include "lib_string.h"
+#include "lib_printf.h"
+
+#include "cfe_iocb.h"
+#include "cfe_device.h"
+#include "cfe_ioctl.h"
+#include "cfe_console.h"
+#include "cfe_timer.h"
+#include "cfe_error.h"
+#include "ui_command.h"
+
+#include <typedefs.h>
+#include <osl.h>
+#include <epivers.h>
+#include <bcmendian.h>
+#include <proto/ethernet.h>
+#include <bcmdevs.h>
+#include <bcmenetmib.h>
+#include <bcmenetrxh.h>
+#include <bcmutils.h>
+#include <et_dbg.h>
+#include <hndsoc.h>
+#include <bcmgmacrxh.h>
+#include <etc.h>
+
+typedef struct et_info {
+	etc_info_t *etc;		/* pointer to common os-independent data */
+	cfe_devctx_t *ctx;		/* backpoint to device */
+	int64_t timer;			/* one second watchdog timer */
+	osl_t *osh;
+	struct et_info *next;		/* pointer to next et_info_t in chain */
+} et_info_t;
+
+static et_info_t *et_list = NULL;
+
+void et_init(et_info_t *et, uint options);
+void et_reset(et_info_t *et);
+void et_link_up(et_info_t *et);
+void et_link_down(et_info_t *et);
+int et_up(et_info_t *et);
+int et_down(et_info_t *et, int reset);
+void et_dump(et_info_t *et, struct bcmstrbuf *b);
+void et_addcmd(void);
+void et_intrson(et_info_t *et);
+
+void
+et_init(et_info_t *et, uint options)
+{
+	ET_TRACE(("et%d: et_init\n", et->etc->unit));
+
+	etc_reset(et->etc);
+	etc_init(et->etc, options);
+}
+
+void
+et_reset(et_info_t *et)
+{
+	ET_TRACE(("et%d: et_reset\n", et->etc->unit));
+
+	etc_reset(et->etc);
+}
+
+void
+et_link_up(et_info_t *et)
+{
+	ET_ERROR(("et%d: link up (%d%s)\n",
+		et->etc->unit, et->etc->speed, (et->etc->duplex? "FD" : "HD")));
+}
+
+void
+et_link_down(et_info_t *et)
+{
+	ET_ERROR(("et%d: link down\n", et->etc->unit));
+}
+
+int
+et_up(et_info_t *et)
+{
+	if (et->etc->up)
+		return 0;
+
+	ET_TRACE(("et%d: et_up\n", et->etc->unit));
+
+	etc_up(et->etc);
+
+	/* schedule one second watchdog timer */
+	TIMER_SET(et->timer, CFE_HZ / 2);
+
+	return 0;
+}
+
+int
+et_down(et_info_t *et, int reset)
+{
+	ET_TRACE(("et%d: et_down\n", et->etc->unit));
+
+	/* stop watchdog timer */
+	TIMER_CLEAR(et->timer);
+
+	etc_down(et->etc, reset);
+
+	return 0;
+}
+
+void
+et_dump(et_info_t *et, struct bcmstrbuf *b)
+{
+#ifdef BCMDBG
+	etc_dump(et->etc, b);
+#endif
+}
+
+et_info_t *et_phyfind(et_info_t *et, uint coreunit);
+uint16 et_phyrd(et_info_t *et, uint phyaddr, uint reg);
+void et_phywr(et_info_t *et, uint reg, uint phyaddr, uint16 val);
+
+/*
+ * 47XX-specific shared mdc/mdio contortion:
+ * Find the et associated with the same chip as <et>
+ * and coreunit matching <coreunit>.
+ */
+et_info_t *
+et_phyfind(et_info_t *et, uint coreunit)
+{
+	et_info_t *tmp;
+
+	/* walk the list et's */
+	for (tmp = et_list; tmp; tmp = tmp->next) {
+		if (et->etc == NULL)
+			continue;
+		if (tmp->etc->coreunit != coreunit)
+			continue;
+		break;
+	}
+	return (tmp);
+}
+
+/* shared phy read entry point */
+uint16
+et_phyrd(et_info_t *et, uint phyaddr, uint reg)
+{
+	return et->etc->chops->phyrd(et->etc->ch, phyaddr, reg);
+}
+
+/* shared phy write entry point */
+void
+et_phywr(et_info_t *et, uint phyaddr, uint reg, uint16 val)
+{
+	et->etc->chops->phywr(et->etc->ch, phyaddr, reg, val);
+}
+
+/*  *********************************************************************
+    *  ETHER_PROBE(drv,probe_a,probe_b,probe_ptr)
+    *  
+    *  Probe and install driver.
+    *  Create a context structure and attach to the
+    *  specified network device.
+    *  
+    *  Input parameters: 
+    *  	   drv - driver descriptor
+    *  	   probe_a - device ID
+    *  	   probe_b - unit number
+    *  	   probe_ptr - mapped registers
+    *  	   
+    *  Return value:
+    *  	   nothing
+    ********************************************************************* */
+
+static void
+et_probe(cfe_driver_t *drv,
+	 unsigned long probe_a, unsigned long probe_b, 
+	 void *probe_ptr)
+{
+	et_info_t *et;
+	uint16 device;
+	uint unit;
+	char name[128];
+
+	device = (uint16) probe_a;
+	unit = (uint) probe_b;
+
+	if (!(et = (et_info_t *) KMALLOC(sizeof(et_info_t), 0))) {
+		ET_ERROR(("et%d: KMALLOC failed\n", unit));
+		return;
+	}
+	bzero(et, sizeof(et_info_t));
+
+	et->osh = osl_attach(et);
+	ASSERT(et->osh);
+
+#ifdef	CFG_SIM
+	/* Make it chatty in simulation */
+	et_msg_level = 0xf;
+#endif
+
+	/* common load-time initialization */
+	if ((et->etc = etc_attach(et, VENDOR_BROADCOM, device, unit, et->osh, probe_ptr)) == NULL) {
+		ET_ERROR(("et%d: etc_attach failed\n", unit));
+		KFREE(et);
+		return;
+	}
+
+	/* this is a polling driver - the chip intmask stays zero */
+	et->etc->chops->intrsoff(et->etc->ch);
+
+	/* add us to the global linked list */
+	et->next = et_list;
+	et_list = et;
+
+	/* print hello string */
+	et->etc->chops->longname(et->etc->ch, name, sizeof (name));
+	printf("et%d: %s %s\n", unit, name, EPI_VERSION_STR);
+
+	cfe_attach(drv, et, NULL, name);
+}
+
+/*  *********************************************************************
+    *  ETHER_OPEN(ctx)
+    *  
+    *  Open the Ethernet device.  The MAC is reset, initialized, and
+    *  prepared to receive and send packets.
+    *  
+    *  Input parameters: 
+    *  	   ctx - device context (includes ptr to our softc)
+    *  	   
+    *  Return value:
+    *  	   status, 0 = ok
+    ********************************************************************* */
+
+static int
+et_open(cfe_devctx_t *ctx)
+{
+	et_info_t *et = (et_info_t *) ctx->dev_softc;
+
+	ET_TRACE(("et%d: et_open\n", et->etc->unit));
+
+	return et_up(et);
+}
+
+/*  *********************************************************************
+    *  ETHER_READ(ctx,buffer)
+    *  
+    *  Read a packet from the Ethernet device.  If no packets are
+    *  available, the read will succeed but return 0 bytes.
+    *  
+    *  Input parameters: 
+    *  	   ctx - device context (includes ptr to our softc)
+    *      buffer - pointer to buffer descriptor.  
+    *  	   
+    *  Return value:
+    *  	   status, 0 = ok
+    ********************************************************************* */
+
+static int
+et_read(cfe_devctx_t *ctx, iocb_buffer_t *buffer)
+{
+	et_info_t *et = (et_info_t *) ctx->dev_softc;
+	int events;
+	void *p;
+	bcmenetrxh_t *rxh;
+	uint16 flags;
+	char eabuf[32];
+
+	ET_TRACE(("et%d: et_read\n", et->etc->unit));
+
+	/* assume no packets */
+	buffer->buf_retlen = 0;
+
+	/* poll for packet */
+	events = et->etc->chops->getintrevents(et->etc->ch, FALSE);
+	if (events & INTR_ERROR)
+		return CFE_ERR_IOERR;
+	if ((events & INTR_RX) == 0)
+		return 0;
+
+	/* get packet */
+	if (!(p = et->etc->chops->rx(et->etc->ch)))
+		goto done;
+
+	/* packet buffer starts with rxhdr */
+	rxh = (bcmenetrxh_t *) PKTDATA(NULL, p);
+
+	/* strip off rxhdr */
+	PKTPULL(NULL, p, HWRXOFF);
+
+	/* check for reported frame errors */
+	flags = RXH_FLAGS(et->etc, rxh);
+	if (flags) {
+		bcm_ether_ntoa((struct ether_addr *)
+	                       (((struct ether_header *) PKTDATA(NULL, p))->ether_shost), eabuf);
+		if (RXH_OVERSIZE(et->etc, rxh)) {
+			ET_ERROR(("et%d: rx: over size packet from %s\n", et->etc->unit, eabuf));
+		}
+		if (RXH_CRC(et->etc, rxh)) {
+			ET_ERROR(("et%d: rx: crc error from %s\n", et->etc->unit, eabuf));
+		}
+		if (RXH_OVF(et->etc, rxh)) {
+			ET_ERROR(("et%d: rx: fifo overflow\n", et->etc->unit));
+		}
+		if (RXH_NO(et->etc, rxh)) {
+			ET_ERROR(("et%d: rx: crc error (odd nibbles) from %s\n",
+			          et->etc->unit, eabuf));
+		}
+		if (RXH_RXER(et->etc, rxh)) {
+			ET_ERROR(("et%d: rx: symbol error from %s\n", et->etc->unit, eabuf));
+		}
+	} else {
+		bcopy(PKTDATA(NULL, p), buffer->buf_ptr, PKTLEN(NULL, p));
+		buffer->buf_retlen = PKTLEN(NULL, p);
+		ET_PRHDR("rx", (struct ether_header *) buffer->buf_ptr,
+		         buffer->buf_retlen, et->etc->unit);
+		ET_PRPKT("rxpkt", buffer->buf_ptr, buffer->buf_retlen, et->etc->unit);
+	}
+
+	/* free packet */
+	PKTFREE(et->osh, p, FALSE);
+
+done:
+	/* post more rx bufs */
+	et->etc->chops->rxfill(et->etc->ch);
+
+	return 0;
+}
+
+/*  *********************************************************************
+    *  ETHER_INPSTAT(ctx,inpstat)
+    *  
+    *  Check for received packets on the Ethernet device
+    *  
+    *  Input parameters: 
+    *  	   ctx - device context (includes ptr to our softc)
+    *      inpstat - pointer to input status structure
+    *  	   
+    *  Return value:
+    *  	   status, 0 = ok
+    ********************************************************************* */
+
+static int
+et_inpstat(cfe_devctx_t *ctx, iocb_inpstat_t *inpstat)
+{
+	et_info_t *et = (et_info_t *) ctx->dev_softc;
+	int events;
+
+	events = et->etc->chops->getintrevents(et->etc->ch, FALSE);
+	inpstat->inp_status = ((events & INTR_RX) ? 1 : 0);
+
+	return 0;
+}
+
+/*  *********************************************************************
+    *  ETHER_WRITE(ctx,buffer)
+    *  
+    *  Write a packet to the Ethernet device.
+    *  
+    *  Input parameters: 
+    *  	   ctx - device context (includes ptr to our softc)
+    *      buffer - pointer to buffer descriptor.  
+    *  	   
+    *  Return value:
+    *  	   status, 0 = ok
+    ********************************************************************* */
+
+static int
+et_write(cfe_devctx_t *ctx, iocb_buffer_t *buffer)
+{
+	et_info_t *et = ctx->dev_softc;
+	int events;
+	void *p;
+
+	if (!(p = PKTGET(NULL, buffer->buf_length, TRUE))) {
+		ET_ERROR(("et%d: PKTGET failed\n", et->etc->unit));
+		return CFE_ERR_NOMEM;
+	}
+
+	bcopy(buffer->buf_ptr, PKTDATA(NULL, p), buffer->buf_length);
+
+	ET_PRHDR("tx", (struct ether_header *)PKTDATA(NULL, p), PKTLEN(NULL, p), et->etc->unit);
+	ET_PRPKT("txpkt", PKTDATA(NULL, p), PKTLEN(NULL, p), et->etc->unit);
+
+	ASSERT(*et->etc->txavail[TX_Q0] > 0);
+
+	/* transmit the frame */
+	et->etc->chops->tx(et->etc->ch, p);
+
+	while (((events = et->etc->chops->getintrevents(et->etc->ch, FALSE)) & (INTR_ERROR | INTR_TX)) == 0);
+
+	/* reclaim any completed tx frames */
+	et->etc->chops->txreclaim(et->etc->ch, FALSE);
+
+	return (events & INTR_ERROR) ? CFE_ERR_IOERR : CFE_OK;
+}
+
+/*  *********************************************************************
+    *  ETHER_IOCTL(ctx,buffer)
+    *  
+    *  Do device-specific I/O control operations for the device
+    *  
+    *  Input parameters: 
+    *  	   ctx - device context (includes ptr to our softc)
+    *      buffer - pointer to buffer descriptor.  
+    *  	   
+    *  Return value:
+    *  	   status, 0 = ok
+    ********************************************************************* */
+static int
+et_ioctl(cfe_devctx_t *ctx,iocb_buffer_t *buffer) 
+{
+	et_info_t *et = (et_info_t *) ctx->dev_softc;
+	int val;
+
+	ET_TRACE(("et%d: et_ioctl: cmd 0x%x\n", et->etc->unit, buffer->buf_ioctlcmd));
+
+	switch (buffer->buf_ioctlcmd) {
+
+	case IOCTL_ETHER_GETHWADDR:
+		bcopy(&et->etc->cur_etheraddr, buffer->buf_ptr, ETHER_ADDR_LEN);
+		break;
+
+	case IOCTL_ETHER_SETHWADDR:
+		bcopy(buffer->buf_ptr, &et->etc->cur_etheraddr, ETHER_ADDR_LEN);
+		et_init(et, ET_INIT_DEF_OPTIONS);
+		break;
+
+	case IOCTL_ETHER_GETSPEED:
+		val = ETHER_SPEED_UNKNOWN;
+		if (et->etc->linkstate) {
+			if (et->etc->speed == 10)
+				val = et->etc->duplex ? ETHER_SPEED_10FDX : ETHER_SPEED_10HDX;
+			else if (et->etc->speed == 100)
+				val = et->etc->duplex ? ETHER_SPEED_100FDX : ETHER_SPEED_100HDX;
+			else if (et->etc->speed == 1000)
+				val = ETHER_SPEED_1000FDX;
+		}
+		*((int *) buffer->buf_ptr) = val;
+		break;
+
+	case IOCTL_ETHER_SETSPEED:
+		val = *((int *) buffer->buf_ptr);
+		if (val == ETHER_SPEED_AUTO)
+			val = ET_AUTO;
+		else if (val == ETHER_SPEED_10HDX)
+			val = ET_10HALF;
+		else if (val == ETHER_SPEED_10FDX)
+			val = ET_10FULL;
+		else if (val == ETHER_SPEED_100HDX)
+			val = ET_100HALF;
+		else if (val == ETHER_SPEED_100FDX)
+			val = ET_100FULL;
+		else if (val == ETHER_SPEED_1000FDX)
+			val = ET_1000FULL;
+		else
+			return CFE_ERR_UNSUPPORTED;
+		return etc_ioctl(et->etc, ETCSPEED, &val);
+
+	case IOCTL_ETHER_GETLINK:
+		*((int *) buffer->buf_ptr) = (int) et->etc->linkstate;
+		break;
+
+	case IOCTL_ETHER_GETLOOPBACK:
+		*((int *) buffer->buf_ptr) = et->etc->loopbk;
+		break;
+
+	case IOCTL_ETHER_SETLOOPBACK:
+		val = *((int *) buffer->buf_ptr);
+		if (val == ETHER_LOOPBACK_OFF)
+			val = (int) FALSE;
+		else
+			val = (int) TRUE;
+		return etc_ioctl(et->etc, ETCLOOP, &val);
+
+	default:
+		return CFE_ERR_UNSUPPORTED;
+
+	}
+
+	return 0;
+}
+
+/*  *********************************************************************
+    *  ETHER_CLOSE(ctx)
+    *  
+    *  Close the Ethernet device.
+    *  
+    *  Input parameters: 
+    *  	   ctx - device context (includes ptr to our softc)
+    *  	   
+    *  Return value:
+    *  	   status, 0 = ok
+    ********************************************************************* */
+
+static int
+et_close(cfe_devctx_t *ctx)
+{
+	et_info_t *et = (et_info_t *) ctx->dev_softc;
+
+	ET_TRACE(("et%d: et_close\n", et->etc->unit));
+
+	return et_down(et, 1);
+}
+
+void
+et_intrson(et_info_t *et)
+{
+	/* this is a polling driver - the chip intmask stays zero */
+	ET_TRACE(("et%d: et_intrson\n", et->etc->unit));
+}
+
+/*  *********************************************************************
+    *  ETHER_POLL(ctx,ticks)
+    *  
+    *  Check for changes in the PHY, so we can track speed changes.
+    *  
+    *  Input parameters: 
+    *  	   ctx - device context (includes ptr to our softc)
+    *      ticks- current time in ticks
+    *  	   
+    *  Return value:
+    *  	   nothing
+    ********************************************************************* */
+
+static void
+et_poll(cfe_devctx_t *ctx, int64_t ticks)
+{
+	et_info_t *et = (et_info_t *) ctx->dev_softc;
+
+	if (TIMER_RUNNING(et->timer) &&
+	    TIMER_EXPIRED(et->timer)) {
+		etc_watchdog(et->etc);
+		TIMER_SET(et->timer, CFE_HZ / 2);
+	}
+}
+
+const static cfe_devdisp_t et_dispatch = {
+	et_open,
+	et_read,
+	et_inpstat,
+	et_write,
+	et_ioctl,
+	et_close,
+	et_poll,
+	NULL
+};
+
+const cfe_driver_t bcmet = {
+	"Broadcom Ethernet",
+	"eth",
+	CFE_DEV_NETWORK,
+	&et_dispatch,
+	et_probe
+};
+
+static int
+ui_cmd_et(ui_cmdline_t *cmdline, int argc, char *argv[])
+{
+	char *command, *name;
+	et_info_t *et;
+	cfe_device_t *dev;
+	int cmd, val, ret;
+	char *arg = (char *) &val;
+
+	if (!(command = cmd_getarg(cmdline, 0)))
+		return CFE_ERR_INV_PARAM;
+
+	if (!cmd_sw_value(cmdline, "-i", &name) || !name)
+		name = "eth0";
+	if (!(dev = cfe_finddev(name)) ||
+	    !dev->dev_softc)
+		return CFE_ERR_DEVNOTFOUND;
+	for (et = et_list; et; et = et->next)
+		if (et == dev->dev_softc)
+			break;
+	if (!et && !(et = et_list))
+		return CFE_ERR_DEVNOTFOUND;
+
+	if (!strcmp(command, "up"))
+		cmd = ETCUP;
+	else if (!strcmp(command, "down"))
+		cmd = ETCDOWN;
+	else if (!strcmp(command, "loop")) {
+		cmd = ETCLOOP;
+		arg = cmd_getarg(cmdline, 1);
+	}
+	else if (!strcmp(command, "dump")) {
+		char *p;
+		if (!(arg = KMALLOC(IOCBUFSZ, 0)))
+			return CFE_ERR_NOMEM;
+		bzero(arg, IOCBUFSZ);
+		if ((ret = etc_ioctl(et->etc, ETCDUMP, arg))) {
+			KFREE(arg);
+			return ret;
+		}
+		/* No puts in cfe, and printf only has a 512 byte buffer */
+		p = arg;
+		while (*p)
+			printf("%c", *p++);
+		KFREE(arg);
+		return 0;
+	}
+	else if (!strcmp(command, "msglevel")) {
+		cmd = ETCSETMSGLEVEL;
+		arg = cmd_getarg(cmdline, 1);
+	}
+	else if (!strcmp(command, "promisc")) {
+		cmd = ETCPROMISC;
+		arg = cmd_getarg(cmdline, 1);
+	}
+	else
+		return CFE_ERR_INV_PARAM;
+
+	if (!arg)
+		return CFE_ERR_INV_PARAM;
+	else if (arg != (char *) &val) {
+		val = bcm_strtoul(arg, NULL, 0);
+		arg = (char *) &val;
+	}
+
+	return etc_ioctl(et->etc, cmd, arg);
+}
+
+void
+et_addcmd(void)
+{
+	cmd_addcmd("et",
+		   ui_cmd_et,
+		   NULL,
+		   "Broadcom Ethernet utility.",
+		   "et command [args..]\n\n"
+		   "Configures the specified Broadcom Ethernet interface.",
+		   "-i=*;Specifies the interface|"
+		   "up;Activate the specified interface|"
+		   "down;Deactivate the specified interface|"
+		   "loop;Sets the loopback mode (0,1)|"
+		   "dump;Dump driver information|"
+		   "msglevel;Sets the driver message level|"
+		   "promisc;Sets promiscuous mode|");
+}
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfe.h b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfe.h
new file mode 100644
index 0000000000..7a3a8e2ee1
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfe.h
@@ -0,0 +1,35 @@
+/*
+ * CFE device driver tunables for
+ * Broadcom BCM47XX 10/100Mbps Ethernet Device Driver
+
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: et_cfe.h 267700 2011-06-19 15:41:07Z $
+ */
+
+#ifndef _et_cfe_h_
+#define _et_cfe_h_
+
+#define NTXD	        16
+#define NRXD	        16
+#define NRXBUFPOST	8   
+
+#define NBUFS		(NRXBUFPOST + 8)
+
+/* common tunables */
+#define	RXBUFSZ		LBDATASZ	/* rx packet buffer size */
+#define	MAXMULTILIST	32		/* max # multicast addresses */
+
+#endif /* _et_cfe_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfg.h b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfg.h
new file mode 100644
index 0000000000..dea6c56d7e
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_cfg.h
@@ -0,0 +1,25 @@
+/*
+ * BCM ET driver config options
+ *
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: et_cfg.h,v 1.1.4.1 2010-08-05 19:17:00 $
+ */
+
+#if defined(__NetBSD__) || defined(__FreeBSD__)
+#include <opt_bcm.h>
+#include <opt_et.h>
+#endif /* defined(__NetBSD__) || defined(__FreeBSD__) */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/et_dbg.h b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_dbg.h
new file mode 100644
index 0000000000..36e0f53f25
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_dbg.h
@@ -0,0 +1,71 @@
+/*
+ * Minimal debug/trace/assert driver definitions for
+ * Broadcom Home Networking Division 10/100 Mbit/s Ethernet
+ * Device Driver.
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: et_dbg.h 404499 2013-05-28 01:06:37Z $
+ */
+
+#ifndef _et_dbg_
+#define _et_dbg_
+
+#ifdef	BCMDBG
+struct ether_header;
+extern void etc_prhdr(char *msg, struct ether_header *eh, uint len, int unit);
+extern void etc_prhex(char *msg, uchar *buf, uint nbytes, int unit);
+/*
+ * et_msg_level is a bitvector:
+ *	0	errors
+ *	1	function-level tracing
+ *	2	one-line frame tx/rx summary
+ *	3	complex frame tx/rx in hex
+ */
+#define	ET_ERROR(args)	if (!(et_msg_level & 1)) ; else printf args
+#define	ET_TRACE(args)	if (!(et_msg_level & 2)) ; else printf args
+#define	ET_PRHDR(msg, eh, len, unit)	if (!(et_msg_level & 4)) ; else etc_prhdr(msg, eh, len, unit)
+#define	ET_PRPKT(msg, buf, len, unit)	if (!(et_msg_level & 8)) ; else etc_prhex(msg, buf, len, unit)
+#else	/* BCMDBG */
+#define	ET_ERROR(args)
+#define	ET_TRACE(args)
+#define	ET_PRHDR(msg, eh, len, unit)
+#define	ET_PRPKT(msg, buf, len, unit)
+#endif	/* BCMDBG */
+
+extern uint32 et_msg_level;
+
+#define	ET_LOG(fmt, a1, a2)
+
+/* include port-specific tunables */
+#ifdef NDIS
+#include <et_ndis.h>
+#elif defined(__ECOS)
+#include <et_ecos.h>
+#elif defined(linux)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 36)
+#include <linux/config.h>
+#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 36) */
+#include <et_linux.h>
+#elif defined(PMON)
+#include <et_pmon.h>
+#elif defined(_CFE_)
+#include <et_cfe.h>
+#elif defined(__NetBSD__)
+#include <et_bsd.h>
+#else
+#error
+#endif
+
+#endif /* _et_dbg_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/et_export.h b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_export.h
new file mode 100644
index 0000000000..a64a80e500
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_export.h
@@ -0,0 +1,58 @@
+/*
+ * Required functions exported by the port-specific (os-dependent) driver
+ * to common (os-independent) driver code.
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: et_export.h 468275 2014-04-07 05:21:13Z $
+ */
+
+#ifndef _et_export_h_
+#define _et_export_h_
+
+/* misc callbacks */
+extern void et_init(void *et, uint options);
+extern void et_reset(void *et);
+extern void et_link_up(void *et);
+extern void et_link_down(void *et);
+extern int et_up(void *et);
+extern int et_down(void *et, int reset);
+extern void et_dump(void *et, struct bcmstrbuf *b);
+extern void et_intrson(void *et);
+extern void et_discard(void *et, void *pkt);
+
+/* for BCM5222 dual-phy shared mdio contortion */
+extern void *et_phyfind(void *et, uint coreunit);
+extern uint16 et_phyrd(void *et, uint phyaddr, uint reg);
+extern void et_phywr(void *et, uint reg, uint phyaddr, uint16 val);
+#ifdef HNDCTF
+extern void et_dump_ctf(void *et, struct bcmstrbuf *b);
+#endif
+#ifdef BCMDBG_CTRACE
+extern void et_dump_ctrace(void *et, struct bcmstrbuf *b);
+#endif
+#ifdef BCM_GMAC3
+extern void et_dump_fwder(void *et, struct bcmstrbuf *b);
+#endif
+#ifdef ETFA
+extern void et_fa_lock_init(void *et);
+extern void et_fa_lock(void *et);
+extern void et_fa_unlock(void *et);
+extern void *et_fa_get_fa_dev(void *et);
+extern bool et_fa_dev_on(void *dev);
+extern void et_fa_set_dev_on(void *et);
+extern void *et_fa_fs_create(void);
+extern void et_fa_fs_clean(void);
+#endif /* ETFA */
+#endif	/* _et_export_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/et_linux.c b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_linux.c
new file mode 100644
index 0000000000..8cb25a666e
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_linux.c
@@ -0,0 +1,3367 @@
+/*
+ * Linux device driver for
+ * Broadcom BCM47XX 10/100/1000 Mbps Ethernet Controller
+ *
+ * Copyright (C) 2015, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: et_linux.c 526408 2015-01-14 06:05:30Z $
+ */
+
+#include <et_cfg.h>
+#define __UNDEF_NO_VERSION__
+
+#include <typedefs.h>
+
+#include <linux/module.h>
+#include <linuxver.h>
+#include <bcmdefs.h>
+
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/pci.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/delay.h>
+#include <linux/string.h>
+#include <linux/sockios.h>
+#ifdef SIOCETHTOOL
+#include <linux/ethtool.h>
+#endif /* SIOCETHTOOL */
+#include <linux/ip.h>
+#include <linux/if_vlan.h>
+#include <net/tcp.h>
+
+#include <asm/system.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/pgtable.h>
+#include <asm/uaccess.h>
+
+#include <osl.h>
+#include <epivers.h>
+#include <bcmendian.h>
+#include <bcmdefs.h>
+#include <proto/ethernet.h>
+#include <proto/vlan.h>
+#include <proto/bcmip.h>
+#include <bcmdevs.h>
+#include <bcmenetmib.h>
+#include <bcmgmacmib.h>
+#include <bcmenetrxh.h>
+#include <bcmenetphy.h>
+#include <etioctl.h>
+#include <bcmutils.h>
+#include <pcicfg.h>
+#include <et_dbg.h>
+#include <hndsoc.h>
+#include <bcmgmacrxh.h>
+#include <etc.h>
+#ifdef HNDCTF
+#include <ctf/hndctf.h>
+#endif /* HNDCTF */
+#include <hndfwd.h>
+#if defined(PLC) || defined(ETFA)
+#include <siutils.h>
+#endif /* PLC || ETFA */
+#ifdef ETFA
+#include <etc_fa.h>
+#endif /* ETFA */
+
+#ifdef ETFA
+#define CTF_CAPABLE_DEV(et)	FA_CTF_CAPABLE_DEV((fa_t *)(et)->etc->fa)
+#else
+#define CTF_CAPABLE_DEV(et)	(TRUE)
+#endif /* !ETFA */
+
+#ifdef ET_ALL_PASSIVE_ON
+/* When ET_ALL_PASSIVE_ON, ET_ALL_PASSIVE must be true */
+#if defined(BCM_GMAC3)
+#define ET_ALL_PASSIVE_ENAB(et)	0
+#else  /* ! BCM_GMAC3 */
+#define ET_ALL_PASSIVE_ENAB(et)	1
+#endif /* ! BCM_GMAC3 */
+#else
+#ifdef ET_ALL_PASSIVE
+#define ET_ALL_PASSIVE_ENAB(et)	(!(et)->all_dispatch_mode)
+#else /* ET_ALL_PASSIVE */
+#define ET_ALL_PASSIVE_ENAB(et)	0
+#endif /* ET_ALL_PASSIVE */
+#endif	/* ET_ALL_PASSIVE_ON */
+
+#ifdef USBAP
+#define MAX_IP_HDR_LEN			60
+#define MAX_TCP_HDR_LEN			60
+#define MAX_TCP_CTRL_PKT_LEN	(ETHERVLAN_HDR_LEN+MAX_IP_HDR_LEN+MAX_TCP_HDR_LEN+ETHER_CRC_LEN)
+#define PKT_IS_TCP_CTRL(osh, p)	(PKTLEN((osh), (p)) <= (MAX_TCP_CTRL_PKT_LEN + HWRXOFF))
+#define SKIP_TCP_CTRL_CHECK(et)	((et)->etc->speed >= 1000)
+#endif
+
+#if defined(BCM_GMAC3)
+
+/* Ensure linux_osl.h:FWDER_HWRXOFF matches etc.h:HWRXOFF */
+#if (FWDER_HWRXOFF != HWRXOFF)
+#error "FWDER_HWRXOFF mismatch with HWRXOFF"
+#endif
+
+#if defined(ETFA)
+#error "GMAC3 based forwarding not compatible with ETFA - AuX port"
+#endif /* ETFA */
+#if !defined(DMA)
+#error "GMAC3 not supported without DMA"
+#endif /* ! DMA */
+#endif /* BCM_GMAC3 */
+
+static int et_get_settings(struct net_device *dev, struct ethtool_cmd *ecmd);
+static int et_set_settings(struct net_device *dev, struct ethtool_cmd *ecmd);
+static void et_get_driver_info(struct net_device *dev, struct ethtool_drvinfo *info);
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 36)
+static const struct ethtool_ops et_ethtool_ops =
+{
+	.get_settings = et_get_settings,
+	.set_settings = et_set_settings,
+	.get_drvinfo = et_get_driver_info
+};
+#endif /* LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 36) */
+
+
+#ifdef ET_INGRESS_QOS
+#define TOSS_CAP	4
+#define PROC_CAP	4
+#endif /* ET_INGRESS_QOS */
+
+MODULE_LICENSE("Proprietary");
+
+#ifdef PLC
+typedef struct et_plc {
+	bool	hw;			/* plc hardware present */
+	int32	txvid;			/* vlan used to send to plc */
+	int32	rxvid1;			/* frames rx'd on this will be sent to br */
+	int32	rxvid2;			/* frames rx'd on this will be sent to wds */
+	int32	rxvid3;			/* frames rx'd on this will be sent to plc */
+	struct net_device *txdev;	/* plc device (vid 3) for tx */
+	struct net_device *rxdev1;	/* plc device (vid 4) for rx */
+	struct net_device *rxdev2;	/* plc device (vid 5) for tx & rx */
+	struct net_device *rxdev3;	/* plc device (vid 6) for tx & rx */
+} et_plc_t;
+#endif /* PLC */
+
+/* In 2.6.20 kernels work functions get passed a pointer to the
+ * struct work, so things will continue to work as long as the work
+ * structure is the first component of the task structure.
+ */
+typedef struct et_task {
+	struct work_struct work;
+	void *context;
+} et_task_t;
+
+typedef struct et_info {
+	etc_info_t	*etc;		/* pointer to common os-independent data */
+	struct net_device *dev;		/* backpoint to device */
+	struct pci_dev *pdev;		/* backpoint to pci_dev */
+	void		*osh;		/* pointer to os handle */
+#if defined(BCM_GMAC3)
+	bool fwder_up;			/* BCM_GMAC3: runtime forwarder state */
+	struct fwder *fwdh;		/* BCM_GMAC3: my upstream forwarder handle */
+#endif /* BCM_GMAC3 */
+#ifdef HNDCTF
+	ctf_t		*cih;		/* ctf instance handle */
+	ctf_brc_hot_t	*brc_hot;	/* hot bridge cache entry */
+#endif
+#ifdef ETFA
+	uint8       fa_bhdr_sz;
+	bool        fa_aux_dev;
+#endif /* ET_FA */
+	struct semaphore sem;		/* use semaphore to allow sleep */
+	spinlock_t	lock;		/* per-device perimeter lock */
+	spinlock_t	txq_lock;	/* lock for txq protection */
+	spinlock_t	isr_lock;	/* lock for irq reentrancy protection */
+	struct sk_buff_head txq[NUMTXQ];	/* send queue */
+	int   txq_pktcnt[NUMTXQ];	/* packets in each tx queue */
+	void *regsva;			/* opaque chip registers virtual address */
+	struct timer_list timer;	/* one second watchdog timer */
+	bool set;			/* indicate the timer is set or not */
+	struct net_device_stats stats;	/* stat counter reporting structure */
+	int events;			/* bit channel between isr and dpc */
+	struct et_info *next;		/* pointer to next et_info_t in chain */
+#ifdef	NAPI2_POLL
+	struct napi_struct napi_poll;
+#endif	/* NAPI2_POLL */
+#ifndef NAPI_POLL
+	struct tasklet_struct tasklet;	/* dpc tasklet */
+	struct tasklet_struct tx_tasklet;	/* tx tasklet */
+#endif /* NAPI_POLL */
+#ifdef ET_ALL_PASSIVE
+	et_task_t	dpc_task;	/* work queue for rx dpc */
+	et_task_t	txq_task;	/* work queue for tx frames */
+	et_task_t	wd_task;	/* work queue for watchdog */
+	bool		all_dispatch_mode;	/* dispatch mode: tasklets or passive */
+#endif /* ET_ALL_PASSIVE */
+	bool resched;			/* dpc was rescheduled */
+#ifdef PLC
+	et_plc_t	plc;		/* plc interface info */
+#endif /* PLC */
+#ifdef ETFA
+	spinlock_t	fa_lock;	/* lock for fa cache protection */
+#endif
+} et_info_t;
+
+static int et_found = 0;
+static et_info_t *et_list = NULL;
+
+#define	ET_INFO(dev)	(et_info_t *)(DEV_PRIV(dev))
+
+
+#define ET_LOCK(et) \
+do { \
+	if (ET_ALL_PASSIVE_ENAB(et)) \
+		down(&(et)->sem); \
+	else \
+		spin_lock_bh(&(et)->lock); \
+} while (0)
+
+#define ET_UNLOCK(et) \
+do { \
+	if (ET_ALL_PASSIVE_ENAB(et)) \
+		up(&(et)->sem); \
+	else \
+		spin_unlock_bh(&(et)->lock); \
+} while (0)
+
+#define ET_TXQ_LOCK(et)		spin_lock_bh(&(et)->txq_lock)
+#define ET_TXQ_UNLOCK(et)	spin_unlock_bh(&(et)->txq_lock)
+
+#define INT_LOCK(et, flags)	spin_lock_irqsave(&(et)->isr_lock, flags)
+#define INT_UNLOCK(et, flags)	spin_unlock_irqrestore(&(et)->isr_lock, flags)
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2, 4, 5)
+#error Linux version must be newer than 2.4.5
+#endif	/* LINUX_VERSION_CODE <= KERNEL_VERSION(2, 4, 5) */
+
+/* linux 2.4 doesn't have in_atomic */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 20)
+#define in_atomic() 0
+#endif
+
+/* prototypes called by etc.c */
+void et_init(et_info_t *et, uint options);
+void et_reset(et_info_t *et);
+void et_link_up(et_info_t *et);
+void et_link_down(et_info_t *et);
+void et_up(et_info_t *et);
+void et_down(et_info_t *et, int reset);
+void et_discard(et_info_t *et, void *pkt);
+void et_dump(et_info_t *et, struct bcmstrbuf *b);
+#ifdef HNDCTF
+void et_dump_ctf(et_info_t *et, struct bcmstrbuf *b);
+#endif
+#ifdef BCMDBG_CTRACE
+void et_dump_ctrace(et_info_t *et, struct bcmstrbuf *b);
+#endif
+#if defined(BCM_GMAC3)
+void et_dump_fwder(et_info_t *et, struct bcmstrbuf *b);
+#endif /* BCM_GMAC3 */
+
+/* local prototypes */
+static void et_free(et_info_t *et);
+static int et_open(struct net_device *dev);
+static int et_close(struct net_device *dev);
+#if defined(BCM_GMAC3)
+static int et_forward(struct fwder * fwder, struct sk_buff *skbs, int skb_cnt,
+                      struct net_device *rx_dev);
+static int et_dummy_start(struct sk_buff *skb, struct net_device *dev);
+#endif /* BCM_GMAC3 */
+static int et_start(struct sk_buff *skb, struct net_device *dev);
+static void et_sendnext(et_info_t *et);
+static struct net_device_stats *et_get_stats(struct net_device *dev);
+static int et_set_mac_address(struct net_device *dev, void *addr);
+static void et_set_multicast_list(struct net_device *dev);
+static void _et_watchdog(struct net_device *data);
+static void et_watchdog(ulong data);
+static int et_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd);
+#ifdef ETFA
+static int et_fa_default_cb(void *dev, ctf_ipc_t *ipc, bool v6, int cmd);
+static int et_fa_normal_cb(void *dev, ctf_ipc_t *ipc, bool v6, int cmd);
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+static irqreturn_t et_isr(int irq, void *dev_id);
+#else
+static irqreturn_t et_isr(int irq, void *dev_id, struct pt_regs *ptregs);
+#endif
+#ifdef	NAPI2_POLL
+static int et_poll(struct napi_struct *napi, int budget);
+#elif defined(NAPI_POLL)
+static int et_poll(struct net_device *dev, int *budget);
+#else /* ! NAPI_POLL */
+static void et_dpc(ulong data);
+#endif /* NAPI_POLL */
+static void et_tx_tasklet(ulong data);
+#ifdef ET_ALL_PASSIVE
+static void et_dpc_work(struct et_task *task);
+static void et_watchdog_task(et_task_t *task);
+#endif /* ET_ALL_PASSIVE */
+static void et_txq_work(struct et_task *task);
+static inline int32 et_ctf_forward(et_info_t *et, struct sk_buff *skb);
+static void et_sendup(et_info_t *et, struct sk_buff *skb, int dataoff);
+#ifdef BCMDBG
+static void et_dumpet(et_info_t *et, struct bcmstrbuf *b);
+#endif /* BCMDBG */
+static void et_error(et_info_t *et, struct sk_buff *skb, void *rxh);
+
+#ifdef HAVE_NET_DEVICE_OPS
+static const struct net_device_ops et_netdev_ops = {
+	.ndo_open = et_open,
+	.ndo_stop = et_close,
+	.ndo_start_xmit = et_start,
+	.ndo_get_stats = et_get_stats,
+	.ndo_set_mac_address = et_set_mac_address,
+	.ndo_set_multicast_list = et_set_multicast_list,
+	.ndo_do_ioctl = et_ioctl,
+};
+
+#if defined(BCM_GMAC3)
+static const struct net_device_ops et_gmac3_netdev_ops = {
+	.ndo_open = et_open,
+	.ndo_stop = et_close,
+	.ndo_start_xmit = et_dummy_start,
+	.ndo_get_stats = et_get_stats,
+	.ndo_set_mac_address = et_set_mac_address,
+	.ndo_set_multicast_list = et_set_multicast_list,
+	.ndo_do_ioctl = et_ioctl,
+};
+#endif /* BCM_GMAC3 */
+
+#endif /* HAVE_NET_DEVICE_OPS */
+
+/* recognized PCI IDs */
+static struct pci_device_id et_id_table[] __devinitdata = {
+	{ vendor: PCI_ANY_ID,
+	device: PCI_ANY_ID,
+	subvendor: PCI_ANY_ID,
+	subdevice: PCI_ANY_ID,
+	class: PCI_CLASS_NETWORK_OTHER << 8,
+	class_mask: 0xffff00,
+	driver_data: 0,
+	},
+	{ vendor: PCI_ANY_ID,
+	device: PCI_ANY_ID,
+	subvendor: PCI_ANY_ID,
+	subdevice: PCI_ANY_ID,
+	class: PCI_CLASS_NETWORK_ETHERNET << 8,
+	class_mask: 0xffff00,
+	driver_data: 0,
+	},
+	{ 0, }
+};
+MODULE_DEVICE_TABLE(pci, et_id_table);
+
+static unsigned int online_cpus = 1;
+#if defined(BCMDBG)
+static uint32 msglevel = 0xdeadbeef;
+module_param(msglevel, uint, 0644);
+#endif /* defined(BCMDBG) */
+
+#ifdef ET_ALL_PASSIVE
+/* passive mode: 1: enable, 0: disable */
+static int passivemode = 0;
+module_param(passivemode, int, 0);
+#endif /* ET_ALL_PASSIVE */
+static int txworkq = 0;
+module_param(txworkq, int, 0);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 36)
+#define ET_TXQ_THRESH_DEFAULT   1536
+#else
+#define ET_TXQ_THRESH_DEFAULT   3300
+#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 36) */
+
+static int et_txq_thresh = ET_TXQ_THRESH_DEFAULT;
+module_param(et_txq_thresh, int, 0);
+
+static uint et_rxlazy_timeout = ET_RXLAZY_TIMEOUT;
+module_param(et_rxlazy_timeout, uint, 0);
+
+static uint et_rxlazy_framecnt = ET_RXLAZY_FRAMECNT;
+module_param(et_rxlazy_framecnt, uint, 0);
+
+#ifdef PKTC
+#ifndef HNDCTF
+#error "Packet chaining feature can't work w/o CTF"
+#endif
+#define PKTC_ENAB(et)	((et)->etc->pktc)
+#define PKTCMC	2
+struct pktc_data {
+	void	*chead;		/* chain head */
+	void	*ctail;		/* chain tail */
+	uint8	*h_da;		/* pointer to da of chain head */
+	uint8	*h_sa;		/* pointer to sa of chain head */
+	uint8	h_prio;		/* prio of chain head */
+};
+typedef struct pktc_data pktc_data_t;
+
+/**
+ * Given packet fields and bridge cache, determine whether a packet is
+ * eligible to be added to current chain data entry.
+ */
+
+#if defined(BCM_GMAC3)
+
+static inline bool
+is_pkt_chainable(et_info_t *et, void * pkt, void *pkthdr, uint8 prio,
+                 pktc_data_t *cd, const bool dev_ntkif)
+{
+	struct ether_header *eh = (struct ether_header *)pkthdr;
+
+	/* RXHFLAGS is tested in the etcgmac during chip rx quota, already */
+	if ((!ETHER_ISNULLDEST(eh->ether_dhost)) &&
+	    !eacmp(eh->ether_dhost, cd->h_da) &&
+	    !eacmp(eh->ether_shost, cd->h_sa) &&
+	    (prio == cd->h_prio)) {
+
+		if (dev_ntkif) { /* NTKIF: Lookup hot bridge cache */
+
+			/* Packets are received with VLAN Tag on ntkif port#8 | GMAC#2 */
+			struct ethervlan_header *evh = (struct ethervlan_header *)pkthdr;
+
+			if (et->brc_hot &&
+			    CTF_HOTBRC_CMP(et->brc_hot, evh->ether_dhost, (void*)et->dev) &&
+			    (evh->vlan_type == HTON16(ETHER_TYPE_8021Q)) &&
+			    ((evh->ether_type == HTON16(ETHER_TYPE_IP)) ||
+			     (evh->ether_type == HTON16(ETHER_TYPE_IPV6)))) {
+
+				return TRUE;
+			}
+
+		} else {
+
+			/* Packets are received without VLAN Tag on GMAC forwarders */
+
+			if ((eh->ether_type == HTON16(ETHER_TYPE_IP)) ||
+			    (eh->ether_type == HTON16(ETHER_TYPE_IPV6))) {
+
+				return TRUE;
+			}
+		}
+	}
+
+	return FALSE; /* not eligible to be chained with h_xx entry */
+}
+
+#else /* ! BCM_GMAC3 */
+
+static inline bool
+is_pkt_chainable(et_info_t *et, void * pkt, void * pkthdr, uint8 prio,
+                 pktc_data_t *cd, const bool dev_ntkif)
+{
+	struct ethervlan_header *evh = (struct ethervlan_header *)pkthdr;
+
+	if ((!ETHER_ISNULLDEST(evh->ether_dhost)) &&
+	    !eacmp(evh->ether_dhost, cd->h_da) &&
+	    !eacmp(evh->ether_shost, cd->h_sa) &&
+	    et->brc_hot &&
+	    CTF_HOTBRC_CMP(et->brc_hot, evh, (void *)et->dev) &&
+	    (prio == cd->h_prio) &&
+	    (evh->vlan_type == HTON16(ETHER_TYPE_8021Q)) &&
+	    ((evh->ether_type == HTON16(ETHER_TYPE_IP)) ||
+	     (evh->ether_type == HTON16(ETHER_TYPE_IPV6))) &&
+	    (!RXH_FLAGS(et->etc, PKTDATA(et->osh, pkt)))) {
+
+		return TRUE;
+	}
+
+	return FALSE; /* not eligible to be chained with h_xx entry */
+}
+
+#endif /* BCM_GMAC3 */
+
+#else /* PKTC */
+#define PKTC_ENAB(et)	0
+#endif /* PKTC */
+
+
+#ifdef HNDCTF
+static void
+et_ctf_detach(ctf_t *ci, void *arg)
+{
+	et_info_t *et = (et_info_t *)arg;
+
+	et->cih = NULL;
+
+#ifdef CTFPOOL
+	/* free the buffers in fast pool */
+	osl_ctfpool_cleanup(et->osh);
+#endif /* CTFPOOL */
+
+	return;
+}
+#endif /* HNDCTF */
+
+#ifdef PLC
+static void
+et_plc_reset(void)
+{
+	si_t *sih = NULL;
+	uint reset_plc;         /* plc reset signal */
+	uint refvdd_off_plc;    /* plc 3.3V control */
+	uint en_off_plc;        /* plc 0.9V control */
+	int refvdd_off_plc_mask;
+	int en_off_plc_mask;
+	int reset_plc_mask;
+
+	sih = si_kattach(SI_OSH);
+
+	/* Reset plc and turn on plc 3.3V and 0.95V */
+	refvdd_off_plc = getgpiopin(NULL, "refvdd_off_plc", GPIO_PIN_NOTDEFINED);
+	en_off_plc = getgpiopin(NULL, "en_off_plc", GPIO_PIN_NOTDEFINED);
+	reset_plc = getgpiopin(NULL, "reset_plc", GPIO_PIN_NOTDEFINED);
+
+	if (reset_plc != GPIO_PIN_NOTDEFINED) {
+		reset_plc_mask = 1 << reset_plc;
+
+		si_gpioout(sih, reset_plc_mask, reset_plc_mask, GPIO_HI_PRIORITY);
+		si_gpioouten(sih, reset_plc_mask, reset_plc_mask, GPIO_HI_PRIORITY);
+
+		if ((refvdd_off_plc != GPIO_PIN_NOTDEFINED) &&
+		    (en_off_plc != GPIO_PIN_NOTDEFINED)) {
+			refvdd_off_plc_mask = 1 << refvdd_off_plc;
+			en_off_plc_mask = 1 << en_off_plc;
+
+			si_gpioout(sih, refvdd_off_plc_mask, 0, GPIO_HI_PRIORITY);
+			si_gpioouten(sih, refvdd_off_plc_mask, refvdd_off_plc_mask,
+				GPIO_HI_PRIORITY);
+
+			si_gpioout(sih, en_off_plc_mask, en_off_plc_mask, GPIO_HI_PRIORITY);
+			si_gpioouten(sih, en_off_plc_mask, en_off_plc_mask, GPIO_HI_PRIORITY);
+		}
+
+		/* Reset signal, 150ms at least */
+		bcm_mdelay(300);
+		si_gpioout(sih, reset_plc_mask, 0, GPIO_HI_PRIORITY);
+	}
+}
+
+#define PLC_VIDTODEV(et, vid)	\
+	(((vid) == (et)->plc.rxvid2) ? (et)->plc.rxdev2 : \
+	 ((vid) == (et)->plc.rxvid1) ? (et)->plc.rxdev1 : \
+	 ((vid) == (et)->plc.rxvid3) ? (et)->plc.rxdev3 : \
+	 ((vid) == (et)->plc.txvid)  ? (et)->plc.txdev : NULL)
+
+static int
+et_plc_netdev_event(struct notifier_block *this, unsigned long event, void *ptr)
+{
+	struct net_device *real_dev, *vl_dev;
+	et_info_t *et;
+	uint16 vid;
+
+	/* we are only interested in plc vifs */
+	vl_dev = (struct net_device *)ptr;
+	if ((vl_dev->priv_flags & IFF_802_1Q_VLAN) == 0)
+		return NOTIFY_DONE;
+
+	/* get the pointer to real device */
+	real_dev = VLAN_DEV_INFO(vl_dev)->real_dev;
+	vid = VLAN_DEV_INFO(vl_dev)->vlan_id;
+
+	et = ET_INFO(real_dev);
+	if (et == NULL) {
+		ET_ERROR(("%s: not an ethernet vlan\n", __FUNCTION__));
+		return NOTIFY_DONE;
+	}
+
+	ET_TRACE(("et%d: %s: event %ld for %s\n", et->etc->unit, __FUNCTION__,
+	          event, vl_dev->name));
+
+	switch (event) {
+	case NETDEV_REGISTER:
+	case NETDEV_UP:
+	case NETDEV_CHANGE:
+		/* save the netdev pointers of plc vifs when corresponding
+		 * interface register event is received.
+		 */
+		if (vid == et->plc.txvid)
+			et->plc.txdev = vl_dev;
+		else if (vid == et->plc.rxvid1)
+			et->plc.rxdev1 = vl_dev;
+		else if (vid == et->plc.rxvid2)
+			et->plc.rxdev2 = vl_dev;
+		else if (vid == et->plc.rxvid3)
+			et->plc.rxdev3 = vl_dev;
+		else
+			;
+		break;
+
+	case NETDEV_UNREGISTER:
+	case NETDEV_DOWN:
+		/* clear the netdev pointers of plc vifs when corresponding
+		 * interface unregister event is received.
+		 */
+		if (vid == et->plc.txvid)
+			et->plc.txdev = NULL;
+		else if (vid == et->plc.rxvid1)
+			et->plc.rxdev1 = NULL;
+		else if (vid == et->plc.rxvid2)
+			et->plc.rxdev2 = NULL;
+		else if (vid == et->plc.rxvid3)
+			et->plc.rxdev3 = NULL;
+		else
+			;
+		break;
+
+	default:
+		break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+static struct notifier_block et_plc_netdev_notifier = {
+	.notifier_call = et_plc_netdev_event
+};
+
+static inline int32
+et_plc_recv(et_info_t *et, struct sk_buff *skb)
+{
+	struct net_device *plc_dev;
+	struct ethervlan_header *evh;
+	uint8 *pkt_data;
+	static uint8 snap_const[] = {0xaa, 0xaa, 0x03, 0x00, 0x1f, 0x84, 0x89, 0x12};
+
+	pkt_data = (uint8 *)PKTDATA(et->osh, skb);
+	evh = (struct ethervlan_header *)pkt_data;
+
+	/* all incoming frames from plc are vlan tagged */
+	if (evh->vlan_type != HTON16(ETHER_TYPE_8021Q))
+		return -1;
+
+	ASSERT((NTOH16(evh->vlan_tag) & VLAN_VID_MASK) != 3);
+
+	plc_dev = PLC_VIDTODEV(et, NTOH16(evh->vlan_tag) & VLAN_VID_MASK);
+
+#ifdef ET_PLC_NO_VLAN_TAG_RX
+	/* The untagged packet from plc 60321 will be tagged with VID=7 by Robo Switch.
+	 * Check ethernet type to tell it from the packet tagged with VID=7 from 60321.
+	 */
+	if (plc_dev == NULL) {
+		int vid = NTOH16(evh->vlan_tag) & VLAN_VID_MASK;
+
+		/* Skip when is a PLC control packet or a gigle daemon packet */
+		if ((vid != 7) ||
+		    (evh->ether_type == HTON16(ETHER_TYPE_GIGLED)) ||
+			(evh->ether_type == HTON16(ETHER_TYPE_8912)))
+			return -1;
+
+		/* Skip when it is a PLC BOOT packet */
+		if (NTOH16(evh->ether_type) < ETHER_TYPE_MIN) {
+			/* Check snap field */
+			pkt_data += sizeof(struct ethervlan_header);
+			if (!memcmp(pkt_data, snap_const, sizeof(snap_const)))
+				return -1;
+		}
+
+		/* Skip in case of plc rxvid1 is NULL */
+		if (et->plc.rxdev1 == NULL)
+			return -1;
+
+		/* Change VID=7 to be plc rxvid1 to emulate it's received by plv rxdev1 */
+		plc_dev = et->plc.rxdev1;
+		evh->vlan_tag &= ~HTON16(VLAN_VID_MASK);
+		evh->vlan_tag |= HTON16(et->plc.rxvid1);
+	}
+#else
+	if (plc_dev == NULL)
+		return -1;
+#endif /* ET_PLC_NO_VLAN_TAG_RX */
+
+	/* call the master hook function to route frames to appropriate
+	 * transmit interface.
+	 */
+	if (plc_dev->master_hook != NULL) {
+		PKTSETPRIO(skb, (NTOH16(evh->vlan_tag) >> VLAN_PRI_SHIFT) & VLAN_PRI_MASK);
+		if (plc_dev->master_hook(skb, plc_dev, plc_dev->master_hook_arg) == 0) {
+			struct net_device_stats *stats;
+			stats = vlan_dev_get_stats(plc_dev);
+			stats->rx_packets++;
+			stats->rx_bytes += skb->len;
+			return 0;
+		}
+		skb->dev = plc_dev->master;
+	}
+
+	return -1;
+}
+#endif /* PLC */
+
+static int __devinit
+et_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
+{
+	struct net_device *dev = NULL;
+	et_info_t *et;
+	osl_t *osh;
+	char name[128];
+	int i, coreunit = et_found, err;
+#ifdef PLC
+	int8 *var;
+#endif /* PLC */
+	/* Scan based on core unit.
+	  * Map core unit to nvram unit for FA, otherwise, core unit is equal to nvram unit
+	  */
+	int unit = coreunit;
+
+	ET_TRACE(("et core%d: et_probe: bus %d slot %d func %d irq %d\n", coreunit,
+	          pdev->bus->number, PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn), pdev->irq));
+
+	if (!etc_chipmatch(pdev->vendor, pdev->device))
+		return -ENODEV;
+
+#ifdef ETFA
+	sprintf(name, "et%dmacaddr", unit);
+	if (getvar(NULL, name))
+		fa_set_aux_unit(si_kattach(SI_OSH), unit);
+#endif /* ETFA */
+
+	/* Map core unit to nvram unit for FA, otherwise, core unit is equal to nvram unit */
+	etc_unitmap(pdev->vendor, pdev->device, coreunit, &unit);
+
+	/* Advanced for next core unit */
+	et_found++;
+
+#ifdef ETFA
+	/* Get mac address from nvram */
+	if (fa_get_macaddr(si_kattach(SI_OSH), NULL, unit) == NULL) {
+		ET_ERROR(("et core%d: can not bind to et%d\n", coreunit, unit));
+		return -ENODEV;
+	}
+#else
+	/* pre-qualify et unit, that can save the effort to do et_detach */
+	sprintf(name, "et%dmacaddr", unit);
+	if (getvar(NULL, name) == NULL) {
+		ET_ERROR(("et%d: et%dmacaddr not found, ignore it\n", unit, unit));
+		ET_ERROR(("et core%d: can not bind to et%d\n", coreunit, unit));
+		return -ENODEV;
+	}
+#endif /* ETFA */
+
+	/* Use ET_ERROR to print core unit to nvram unit mapping always */
+	ET_ERROR(("et core%d: bind to et%d\n", coreunit, unit));
+
+	osh = osl_attach(pdev, PCI_BUS, FALSE);
+	ASSERT(osh);
+
+	/* Set ACP coherence flag */
+	if (OSL_ACP_WAR_ENAB() || OSL_ARCH_IS_COHERENT())
+		osl_flag_set(osh, OSL_ACP_COHERENCE);
+
+	pci_set_master(pdev);
+	if ((err = pci_enable_device(pdev)) != 0) {
+		ET_ERROR(("et%d: et_probe: pci_enable_device() failed\n", unit));
+		osl_detach(osh);
+		return err;
+	}
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 36)
+	if ((dev = alloc_etherdev(sizeof(et_info_t))) == NULL) {
+		ET_ERROR(("et%d: et_probe: alloc_etherdev() failed\n", unit));
+		osl_detach(osh);
+		return -ENOMEM;
+	}
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 0)
+	if ((dev = alloc_etherdev(0)) == NULL) {
+		ET_ERROR(("et%d: et_probe: alloc_etherdev() failed\n", unit));
+		osl_detach(osh);
+		return -ENOMEM;
+	}
+	/* allocate private info */
+	if ((et = (et_info_t *)MALLOC(osh, sizeof(et_info_t))) == NULL) {
+		ET_ERROR(("et%d: et_probe: out of memory, malloced %d bytes\n", unit,
+		          MALLOCED(osh)));
+		MFREE(osh, dev, sizeof(et_info_t));
+		osl_detach(osh);
+		return -ENOMEM;
+	}
+	dev->priv = (void *)et;
+#else
+	if (!(dev = (struct net_device *) MALLOC(osh, sizeof(struct net_device)))) {
+		ET_ERROR(("et%d: et_probe: out of memory, malloced %d bytes\n", unit,
+		          MALLOCED(osh)));
+		osl_detach(osh);
+		return -ENOMEM;
+	}
+	bzero(dev, sizeof(struct net_device));
+
+	if (!init_etherdev(dev, 0)) {
+		ET_ERROR(("et%d: et_probe: init_etherdev() failed\n", unit));
+		MFREE(osh, dev, sizeof(struct net_device));
+		osl_detach(osh);
+		return -ENOMEM;
+	}
+	/* allocate private info */
+	if ((et = (et_info_t *)MALLOC(osh, sizeof(et_info_t))) == NULL) {
+		ET_ERROR(("et%d: et_probe: out of memory, malloced %d bytes\n", unit,
+		          MALLOCED(osh)));
+		MFREE(osh, dev, sizeof(et_info_t));
+		osl_detach(osh);
+		return -ENOMEM;
+	}
+	dev->priv = (void *)et;
+#endif /* < 2.6.0 */
+
+	et = ET_INFO(dev);
+	bzero(et, sizeof(et_info_t));	/* Is this needed in 2.6.36 ? -LR */
+	et->dev = dev;
+	et->pdev = pdev;
+	et->osh = osh;
+	pci_set_drvdata(pdev, et);
+
+	/* map chip registers (47xx: and sprom) */
+	dev->base_addr = pci_resource_start(pdev, 0);
+	if ((et->regsva = ioremap_nocache(dev->base_addr, PCI_BAR0_WINSZ)) == NULL) {
+		ET_ERROR(("et%d: ioremap() failed\n", unit));
+		goto fail;
+	}
+
+	init_MUTEX(&et->sem);
+	spin_lock_init(&et->lock);
+	spin_lock_init(&et->txq_lock);
+	spin_lock_init(&et->isr_lock);
+
+	for (i = 0; i < NUMTXQ; i++)
+		skb_queue_head_init(&et->txq[i]);
+
+	/* common load-time initialization */
+	et->etc = etc_attach((void *)et, pdev->vendor, pdev->device, coreunit, osh, et->regsva);
+	if (et->etc == NULL) {
+		ET_ERROR(("et%d: etc_attach() failed\n", unit));
+		goto fail;
+	}
+
+#ifdef ETFA
+	if (et->etc->fa) {
+		fa_set_name(et->etc->fa, dev->name);
+	}
+	et->fa_bhdr_sz = FA_RX_BCM_HDR((fa_t *)et->etc->fa)
+	               ? sizeof(bcm_hdr_t) : 0;
+	et->fa_aux_dev = FA_IS_AUX_DEV((fa_t *)et->etc->fa)
+		           ? TRUE : FALSE;
+#endif /* ETFA */
+
+#if defined(BCM_GMAC3)
+	fwder_init(); /* initialize the fwder */
+
+	et->fwder_up = FALSE; /* et_forward() enabled/disabled on et_up/et_down */
+	et->fwdh = (struct fwder *)NULL;
+
+	if (DEV_FWDER(et->etc)) { /* Attach driver to forwarder */
+		/* Ethernet network interface uses "ethXX". Use "fwdXX" instead */
+		strncpy(dev->name, DEV_FWDER_NAME, 3);
+
+		/* Store the rx lazy configuration */
+		etc_rxlazy(et->etc, et_rxlazy_timeout, et_rxlazy_framecnt);
+
+		/*
+		 * Attach my transmit handler to UPSTREAM fwder instance on core=unit
+		 *      wl# MAC -> wl_sendup -> et_forward -> et::GMAC#
+		 * and get the DNSTREAM direction transmit handler for use in sendup.
+		 *      et_sendup/chain -> et->fwdh->bypass_fn=wl_forward -> wl_start
+		 */
+		et->fwdh = fwder_attach(FWDER_UPSTREAM, et->etc->coreunit,
+		                        FWDER_NIC_MODE, et_forward, et->dev, et->osh);
+		if (et->fwdh) {
+			et->fwdh->dataoff = HWRXOFF;
+#ifdef ETFA
+			et->fwdh->dataoff += et->fa_bhdr_sz;
+#endif
+		}
+		ET_TRACE(("et%d: unit<%d> fwder<%p>\n", unit, et->etc->coreunit, et->fwdh));
+	}
+#endif /* BCM_GMAC3 */
+
+#ifdef HNDCTF
+	/* Normally we do ctf_attach for each ethernet devices but here we have to ignore
+	 * the aux device which invoked by the FA.  Because the aux device is a FA auxiliary
+	 * device, the skb->dev for all the packets from aux will be change to FA dev later.
+	 */
+	if (CTF_CAPABLE_DEV(et)) {
+		et->cih = ctf_attach(osh, dev->name, &et_msg_level, et_ctf_detach, et);
+
+		if (DEV_NTKIF(et->etc)) {   /* Bind CTF to ethernet network interface */
+			if (ctf_dev_register(et->cih, dev, FALSE) != BCME_OK) {
+				ET_ERROR(("et%d: ctf_dev_register() failed\n", unit));
+				goto fail;
+			}
+		}
+
+#ifdef ETFA
+		if (FA_IS_FA_DEV((fa_t *)et->etc->fa)) {
+			if (getintvar(NULL, "ctf_fa_mode") == CTF_FA_NORMAL) {
+				ctf_fa_register(et->cih, et_fa_normal_cb, dev);
+			}
+			else {
+				ctf_fa_register(et->cih, et_fa_default_cb, dev);
+			}
+		}
+#endif
+
+#ifdef CTFPOOL
+		/* create ctf packet pool with specified number of buffers */
+		if (CTF_ENAB(et->cih)) {
+			uint32 poolsz;
+			/* use large ctf poolsz for platforms with more memory */
+			poolsz = ((num_physpages >= 32767) ? CTFPOOLSZ * 2 :
+			          ((num_physpages >= 8192) ? CTFPOOLSZ : 0));
+			if ((poolsz > 0) &&
+			    (osl_ctfpool_init(osh, poolsz, RXBUFSZ+BCMEXTRAHDROOM) < 0)) {
+				ET_ERROR(("et%d: chipattach: ctfpool alloc/init failed\n", unit));
+				goto fail;
+			}
+		}
+#endif /* CTFPOOL */
+	}
+#endif /* HNDCTF */
+
+	bcopy(&et->etc->cur_etheraddr, dev->dev_addr, ETHER_ADDR_LEN);
+
+	/* init 1 second watchdog timer */
+	init_timer(&et->timer);
+	et->timer.data = (ulong)dev;
+	et->timer.function = et_watchdog;
+
+#ifdef CONFIG_SMP
+	/* initialize number of online cpus */
+	online_cpus = num_online_cpus();
+#if defined(__ARM_ARCH_7A__)
+	if (online_cpus > 1) {
+		if (et_txq_thresh == 0) {
+			et_txq_thresh = ET_TXQ_THRESH_DEFAULT;
+		}
+	}
+#endif /* __ARM_ARCH_7A__ */
+#else
+	online_cpus = 1;
+#endif /* CONFIG_SMP */
+	ET_ERROR(("et%d: online cpus %d\n", unit, online_cpus));
+
+#ifdef	NAPI2_POLL
+	netif_napi_add(dev, & et->napi_poll, et_poll, 64);
+	napi_enable(&et->napi_poll);
+#endif	/* NAPI2_POLL */
+
+#if !defined(NAPI_POLL) && !defined(NAPI2_POLL)
+	/* setup the bottom half handler */
+	tasklet_init(&et->tasklet, et_dpc, (ulong)et);
+#endif /*! NAPIx_POLL */
+
+	tasklet_init(&et->tx_tasklet, et_tx_tasklet, (ulong)et);
+	tasklet_disable(&et->tx_tasklet);
+
+#ifdef ET_ALL_PASSIVE
+	if (ET_ALL_PASSIVE_ENAB(et)) {
+		MY_INIT_WORK(&et->dpc_task.work, (work_func_t)et_dpc_work);
+		et->dpc_task.context = et;
+		MY_INIT_WORK(&et->txq_task.work, (work_func_t)et_txq_work);
+		et->txq_task.context = et;
+		MY_INIT_WORK(&et->wd_task.work, (work_func_t)et_watchdog_task);
+		et->wd_task.context = et;
+	} else if (txworkq) {
+		MY_INIT_WORK(&et->txq_task.work, (work_func_t)et_txq_work);
+		et->txq_task.context = et;
+	}
+	et->all_dispatch_mode = (passivemode == 0) ? TRUE : FALSE;
+#endif  /* ET_ALL_PASSIVE */
+
+	/* register our interrupt handler */
+	if (request_irq(pdev->irq, et_isr, IRQF_SHARED, dev->name, et)) {
+		ET_ERROR(("et%d: request_irq() failed\n", unit));
+		goto fail;
+	}
+	dev->irq = pdev->irq;
+
+#if defined(BCM_GMAC3)
+	if (DEV_FWDER(et->etc)) {
+		/* Setup GMAC forwarder irq affinity by fwder unit. */
+		fwder_affinity(FWDER_DNSTREAM, et->etc->coreunit, pdev->irq);
+	}
+#endif /* BCM_GMAC3 */
+
+	/* add us to the global linked list */
+	et->next = et_list;
+	et_list = et;
+
+#ifndef HAVE_NET_DEVICE_OPS
+	/* lastly, enable our entry points */
+	dev->open = et_open;
+	dev->stop = et_close;
+#if defined(BCM_GMAC3)
+	if (DEV_FWDER(et->etc))
+		dev->hard_start_xmit = et_dummy_start;
+	else
+#endif /* BCM_GMAC3 */
+		dev->hard_start_xmit = et_start;
+	dev->get_stats = et_get_stats;
+	dev->set_mac_address = et_set_mac_address;
+	dev->set_multicast_list = et_set_multicast_list;
+	dev->do_ioctl = et_ioctl;
+#ifdef NAPI_POLL
+	dev->poll = et_poll;
+	dev->weight = (ET_GMAC(et->etc) ? 64 : 32);
+#endif /* NAPI_POLL */
+#else /* ! HAVE_NET_DEVICE_OPS */
+	/* Linux 2.6.36 and up. - LR */
+#if defined(BCM_GMAC3)
+	if (DEV_FWDER(et->etc))
+		dev->netdev_ops = &et_gmac3_netdev_ops;
+	else
+#endif /* BCM_GMAC3 */
+		dev->netdev_ops = &et_netdev_ops;
+#ifdef NAPI_POLL
+	dev->poll = et_poll;
+	dev->weight = (ET_GMAC(et->etc) ? 64 : 32);
+#endif /* NAPI_POLL */
+
+#endif /* HAVE_NET_DEVICE_OPS */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 36)
+	dev->ethtool_ops = &et_ethtool_ops;
+#endif
+
+	if (register_netdev(dev)) {
+		ET_ERROR(("et%d: register_netdev() failed\n", unit));
+		goto fail;
+	}
+
+#ifdef __ARM_ARCH_7A__
+	dev->features = (NETIF_F_SG | NETIF_F_FRAGLIST | NETIF_F_ALL_CSUM);
+#endif
+
+	/* print hello string */
+	(*et->etc->chops->longname)(et->etc->ch, name, sizeof(name));
+	printf("%s: %s %s\n", dev->name, name, EPI_VERSION_STR);
+
+#ifdef HNDCTF
+	if (DEV_NTKIF(et->etc)) {   /* Enable CTF on ethernet network interface */
+		if (et->cih &&
+			ctf_enable(et->cih, dev, TRUE, &et->brc_hot) != BCME_OK) {
+			ET_ERROR(("et%d: ctf_enable() failed\n", unit));
+			goto fail;
+		}
+	}
+#endif /* HNDCTF */
+
+	ET_TRACE(("et%d: registered dev<%p,%s> ET<%u:%s> irq<%u>\n", unit,
+	         dev, dev->name, et->etc->coreunit,
+	         DEV_NTKIF(et->etc) ? "NETWORKIF" : "FORWARDER", dev->irq));
+
+#ifdef PLC
+	/* read plc_vifs to initialize the vids to use for receiving
+	 * and forwarding the frames.
+	 */
+	var = getvar(NULL, "plc_vifs");
+
+	if (var == NULL) {
+		ET_ERROR(("et%d: %s: PLC vifs not configured\n", unit, __FUNCTION__));
+		return (0);
+	}
+
+	et_plc_reset();
+
+	et->plc.hw = TRUE;
+
+	/* initialize the vids to use for plc rx and tx */
+	sscanf(var, "vlan%d vlan%d vlan%d vlan%d",
+	       &et->plc.txvid, &et->plc.rxvid1, &et->plc.rxvid2, &et->plc.rxvid3);
+
+	ET_ERROR(("et%d: %s: PLC vifs %s\n", unit, __FUNCTION__, var));
+
+	/* register a callback to be called on plc dev create event */
+	register_netdevice_notifier(&et_plc_netdev_notifier);
+#endif /* PLC */
+
+	return (0);
+
+fail:
+	et_free(et);
+	return (-ENODEV);
+}
+
+static int
+et_suspend(struct pci_dev *pdev, DRV_SUSPEND_STATE_TYPE state)
+{
+	et_info_t *et;
+
+	if ((et = (et_info_t *) pci_get_drvdata(pdev))) {
+		netif_device_detach(et->dev);
+		ET_LOCK(et);
+		et_down(et, 1);
+		ET_UNLOCK(et);
+	}
+
+	return 0;
+}
+
+static int
+et_resume(struct pci_dev *pdev)
+{
+	et_info_t *et;
+
+	if ((et = (et_info_t *) pci_get_drvdata(pdev))) {
+		ET_LOCK(et);
+		et_up(et);
+		ET_UNLOCK(et);
+		netif_device_attach(et->dev);
+	}
+
+	return 0;
+}
+
+/* Compatibility routines */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 6)
+static void
+_et_suspend(struct pci_dev *pdev)
+{
+	et_suspend(pdev, 0);
+}
+
+static void
+_et_resume(struct pci_dev *pdev)
+{
+	et_resume(pdev);
+}
+#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 6) */
+
+static void __devexit
+et_remove(struct pci_dev *pdev)
+{
+	et_info_t *et;
+
+	if (!etc_chipmatch(pdev->vendor, pdev->device))
+		return;
+
+#if defined(BCM_GMAC3)
+	fwder_exit();
+#endif /* BCM_GMAC3 */
+
+#ifdef PLC
+	/* Un-register us from receiving netdevice events */
+	unregister_netdevice_notifier(&et_plc_netdev_notifier);
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 12)
+	et_suspend(pdev, 0);
+#else
+	et_suspend(pdev, PMSG_SUSPEND);
+#endif
+
+	if ((et = (et_info_t *) pci_get_drvdata(pdev))) {
+		et_free(et);
+		pci_set_drvdata(pdev, NULL);
+	}
+}
+
+static struct pci_driver et_pci_driver = {
+	name:		"et",
+	probe:		et_probe,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 6)
+	suspend:	_et_suspend,
+	resume:		_et_resume,
+#else
+	suspend:	et_suspend,
+	resume:		et_resume,
+#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2, 4, 6) */
+	remove:		__devexit_p(et_remove),
+	id_table:	et_id_table,
+	};
+
+static int __init
+et_module_init(void)
+{
+	char * var;
+
+#if defined(BCMDBG)
+	if (msglevel != 0xdeadbeef)
+		et_msg_level = msglevel;
+	else {
+		var = getvar(NULL, "et_msglevel");
+		if (var)
+			et_msg_level = bcm_strtoul(var, NULL, 0);
+	}
+
+	printf("%s: msglevel set to 0x%x\n", __FUNCTION__, et_msg_level);
+#endif /* defined(BCMDBG) */
+
+#ifdef ET_ALL_PASSIVE
+	{
+		var = getvar(NULL, "et_dispatch_mode");
+		if (var)
+			passivemode = bcm_strtoul(var, NULL, 0);
+		printf("%s: passivemode set to 0x%x\n", __FUNCTION__, passivemode);
+		var = getvar(NULL, "txworkq");
+		if (var)
+			txworkq = bcm_strtoul(var, NULL, 0);
+		printf("%s: txworkq set to 0x%x\n", __FUNCTION__, txworkq);
+	}
+#endif /* ET_ALL_PASSIVE */
+	var = getvar(NULL, "et_txq_thresh");
+	if (var)
+		et_txq_thresh = bcm_strtoul(var, NULL, 0);
+	printf("%s: et_txq_thresh set to 0x%x\n", __FUNCTION__, et_txq_thresh);
+
+	var = getvar(NULL, "et_rxlazy_timeout");
+	if (var)
+		et_rxlazy_timeout = bcm_strtoul(var, NULL, 0);
+	printf("%s: et_rxlazy_timeout set to 0x%x\n", __FUNCTION__, et_rxlazy_timeout);
+
+	var = getvar(NULL, "et_rxlazy_framecnt");
+	if (var)
+		et_rxlazy_framecnt = bcm_strtoul(var, NULL, 0);
+	printf("%s: et_rxlazy_framecnt set to 0x%x\n", __FUNCTION__, et_rxlazy_framecnt);
+
+	return pci_module_init(&et_pci_driver);
+}
+
+static void __exit
+et_module_exit(void)
+{
+	pci_unregister_driver(&et_pci_driver);
+}
+
+module_init(et_module_init);
+module_exit(et_module_exit);
+
+static void
+et_free(et_info_t *et)
+{
+	et_info_t **prev;
+	osl_t *osh;
+
+	if (et == NULL)
+		return;
+
+	ET_TRACE(("et: et_free\n"));
+
+#if defined(BCM_GMAC3)
+	if (DEV_FWDER(et->etc)) {
+		et->fwder_up = FALSE; /* Disable et_forward() */
+		ET_TRACE(("et%d: fwder<%d> dettached\n", et->etc->unit, et->etc->coreunit));
+		/* Dettach driver from fwder */
+		et->fwdh = fwder_dettach(et->fwdh, FWDER_UPSTREAM, et->etc->coreunit);
+	}
+#endif /* BCM_GMAC3 */
+
+	if (et->dev && et->dev->irq)
+		free_irq(et->dev->irq, et);
+
+#ifdef	NAPI2_POLL
+	napi_disable(&et->napi_poll);
+	netif_napi_del(&et->napi_poll);
+#endif	/* NAPI2_POLL */
+
+#ifdef HNDCTF
+	if (et->cih)
+		ctf_dev_unregister(et->cih, et->dev);
+#endif /* HNDCTF */
+
+	if (et->dev) {
+		unregister_netdev(et->dev);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 36)
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 0)
+		free_netdev(et->dev);
+#else
+		MFREE(et->osh, et->dev, sizeof(struct net_device));
+#endif
+		et->dev = NULL;
+#endif /* LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 36) */
+	}
+
+#ifdef CTFPOOL
+	/* free the buffers in fast pool */
+	osl_ctfpool_cleanup(et->osh);
+#endif /* CTFPOOL */
+
+#ifdef HNDCTF
+	/* free ctf resources */
+	if (et->cih)
+		ctf_detach(et->cih);
+#endif /* HNDCTF */
+
+	/* free common resources */
+	if (et->etc) {
+		etc_detach(et->etc);
+		et->etc = NULL;
+	}
+
+	/*
+	 * unregister_netdev() calls get_stats() which may read chip registers
+	 * so we cannot unmap the chip registers until after calling unregister_netdev() .
+	 */
+	if (et->regsva) {
+		iounmap((void *)et->regsva);
+		et->regsva = NULL;
+	}
+
+	/* remove us from the global linked list */
+	for (prev = &et_list; *prev; prev = &(*prev)->next)
+		if (*prev == et) {
+			*prev = et->next;
+			break;
+		}
+
+	osh = et->osh;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 36)
+	free_netdev(et->dev);
+	et->dev = NULL;
+#else
+	MFREE(et->osh, et, sizeof(et_info_t));
+#endif
+
+#ifdef BCMDBG_CTRACE
+	PKT_CTRACE_DUMP(osh, NULL);
+#endif
+
+	if (MALLOCED(osh))
+		printf("Memory leak of bytes %d\n", MALLOCED(osh));
+	ASSERT(MALLOCED(osh) == 0);
+
+	osl_detach(osh);
+}
+
+static int
+et_open(struct net_device *dev)
+{
+	et_info_t *et;
+
+	et = ET_INFO(dev);
+
+	ET_TRACE(("et%d: et_open\n", et->etc->unit));
+
+	et->etc->promisc = (dev->flags & IFF_PROMISC)? TRUE: FALSE;
+	et->etc->allmulti = (dev->flags & IFF_ALLMULTI)? TRUE: et->etc->promisc;
+
+	ET_LOCK(et);
+	et_up(et);
+	ET_UNLOCK(et);
+
+	OLD_MOD_INC_USE_COUNT;
+
+	return (0);
+}
+
+static int
+et_close(struct net_device *dev)
+{
+	et_info_t *et;
+
+	et = ET_INFO(dev);
+
+	ET_TRACE(("et%d: et_close\n", et->etc->unit));
+
+	et->etc->promisc = FALSE;
+	et->etc->allmulti = FALSE;
+
+	ET_LOCK(et);
+	et_down(et, 1);
+	ET_UNLOCK(et);
+
+	OLD_MOD_DEC_USE_COUNT;
+
+	return (0);
+}
+
+
+static void BCMFASTPATH
+et_txq_work(struct et_task *task)
+{
+	et_info_t *et = (et_info_t *)task->context;
+
+	ET_LOCK(et);
+	et_sendnext(et);
+	ET_UNLOCK(et);
+
+	return;
+}
+
+/*
+ * Driver level checksum offload. This is being done so that we can advertise
+ * checksum offload support to Linux.
+ */
+static void BCMFASTPATH_HOST
+et_cso(et_info_t *et, struct sk_buff *skb)
+{
+	struct ethervlan_header *evh;
+	uint8 *th = skb_transport_header(skb);
+	uint16 thoff, eth_type, *check;
+	uint8 prot;
+
+	ASSERT(!PKTISCTF(et->osh, skb));
+
+	evh = (struct ethervlan_header *)PKTDATA(et->osh, skb);
+	eth_type = ((evh->vlan_type == HTON16(ETHER_TYPE_8021Q)) ?
+	            evh->ether_type : evh->vlan_type);
+
+	/* tcp/udp checksum calculation */
+	thoff = (th - skb->data);
+	if (eth_type == HTON16(ETHER_TYPE_IP)) {
+		struct iphdr *ih = ip_hdr(skb);
+		prot = ih->protocol;
+		ASSERT((prot == IP_PROT_TCP) || (prot == IP_PROT_UDP));
+		check = (uint16 *)(th + ((prot == IP_PROT_UDP) ?
+			offsetof(struct udphdr, check) : offsetof(struct tcphdr, check)));
+		*check = 0;
+		skb->csum = skb_checksum(skb, thoff, skb->len - thoff, 0);
+		*check = csum_tcpudp_magic(ih->saddr, ih->daddr,
+		                           skb->len - thoff, prot, skb->csum);
+	} else if (eth_type == HTON16(ETHER_TYPE_IPV6)) {
+		struct ipv6hdr *ih = ipv6_hdr(skb);
+		prot = IPV6_PROT(ih);
+		ASSERT((prot == IP_PROT_TCP) || (prot == IP_PROT_UDP));
+		check = (uint16 *)(th + ((prot == IP_PROT_UDP) ?
+			offsetof(struct udphdr, check) : offsetof(struct tcphdr, check)));
+		*check = 0;
+		skb->csum = skb_checksum(skb, thoff, skb->len - thoff, 0);
+		*check = csum_ipv6_magic(&ih->saddr, &ih->daddr,
+		                         skb->len - thoff, prot, skb->csum);
+	} else
+		return;
+
+	if ((*check == 0) && (prot == IP_PROT_UDP))
+		*check = CSUM_MANGLED_0;
+}
+/*
+ * Called in non-passive mode when we need to send frames received on other CPU.
+ */
+static void BCMFASTPATH
+et_sched_tx_tasklet(void *t)
+{
+	et_info_t *et = (et_info_t *)t;
+	tasklet_schedule(&et->tx_tasklet);
+}
+
+#if defined(BCM_GMAC3)
+/**
+ * BCM_GMAC3: Forwarder transmit handler.
+ * WLAN driver may forward a packet chain, and not an array of packet pointers.
+ */
+static int BCMFASTPATH
+et_forward(struct fwder *fwder, struct sk_buff *skbs, int skb_cnt,
+           struct net_device *rx_dev)
+{
+	et_info_t *et;
+
+	/* Use the attached default net_device. */
+	ASSERT(fwder != NULL);
+	ASSERT(fwder->dev_def != NULL);
+
+	et = ET_INFO(fwder->dev_def);
+
+	if (!et->fwder_up)
+		return -ENETDOWN;
+
+	et_start((struct sk_buff *)skbs, fwder->dev_def);
+
+	return FWDER_SUCCESS;
+}
+
+static int
+et_dummy_start(struct sk_buff *skb, struct net_device *dev)
+{
+	et_info_t *et = ET_INFO(dev);
+
+	PKTFRMNATIVE(et->osh, skb);
+	PKTFREE(et->osh, skb, TRUE);
+	return 0;
+}
+#endif /* BCM_GMAC3 */
+
+/*
+ * Below wrapper functions for skb queue/dequeue maintain packet counters.
+ * In case of packet chaining, number of entries is not equal to no. of packets.
+ * Queuing threshold is to be compared against total packet count in a queue and
+ * not against the queue length.
+ */
+
+static void BCMFASTPATH
+et_skb_queue_tail(et_info_t *et, int qid,  struct sk_buff *skb)
+{
+	__skb_queue_tail(&et->txq[qid], skb);
+	et->txq_pktcnt[qid] += (PKTISCHAINED(skb) ? PKTCCNT(skb): 1);
+}
+
+static struct sk_buff * BCMFASTPATH
+et_skb_dequeue(et_info_t *et, int qid)
+{
+	struct sk_buff *skb;
+
+	skb = __skb_dequeue(&et->txq[qid]);
+	if (!skb) return skb;
+
+	ASSERT(et->txq_pktcnt[qid] > 0);
+	et->txq_pktcnt[qid] -= (PKTISCHAINED(skb) ? PKTCCNT(skb): 1);
+	ASSERT(et->txq_pktcnt[qid] >= 0);
+
+	return skb;
+}
+
+/*
+ * Yeah, queueing the packets on a tx queue instead of throwing them
+ * directly into the descriptor ring in the case of dma is kinda lame,
+ * but this results in a unified transmit path for both dma and pio
+ * and localizes/simplifies the netif_*_queue semantics, too.
+ */
+#ifdef CONFIG_SMP
+#define ET_CONFIG_SMP()	TRUE
+#else
+#define ET_CONFIG_SMP()	FALSE
+#endif /* CONFIG_SMP */
+#if defined(CONFIG_ET) || defined(CONFIG_ET_MODULE)
+#define ET_RTR()	TRUE
+#else
+#define ET_RTR()	FALSE
+#endif /* CONFIG_ET */
+static int BCMFASTPATH
+et_start(struct sk_buff *skb, struct net_device *dev)
+{
+	et_info_t *et;
+	uint32 q = 0;
+
+	et = ET_INFO(dev);
+
+	if (PKTISFAAUX(skb)) {
+		PKTCLRFAAUX(skb);
+		PKTFRMNATIVE(et->osh, skb);
+		PKTCFREE(et->osh, skb, TRUE);
+		return 0;
+	}
+
+	if (ET_GMAC(et->etc) && (et->etc->qos))
+		q = etc_up2tc(PKTPRIO(skb));
+
+	ET_TRACE(("et%d: et_start: len %d\n", et->etc->unit, skb->len));
+	ET_LOG("et%d: et_start: len %d", et->etc->unit, skb->len);
+
+	ET_TXQ_LOCK(et);
+
+	if (et_txq_thresh && (et->txq_pktcnt[q] >= et_txq_thresh)) {
+		ET_TXQ_UNLOCK(et);
+		PKTFRMNATIVE(et->osh, skb);
+		PKTCFREE(et->osh, skb, TRUE);
+		return 0;
+	}
+
+	/* put it on the tx queue and call sendnext */
+	et_skb_queue_tail(et, q, skb);
+	et->etc->txq_state |= (1 << q);
+	ET_TXQ_UNLOCK(et);
+
+	/* Call in the same context when we are UP and non-passive is enabled */
+	if (ET_ALL_PASSIVE_ENAB(et) || (ET_RTR() && ET_CONFIG_SMP())) {
+		/* In smp non passive mode, schedule tasklet for tx */
+		if (!ET_ALL_PASSIVE_ENAB(et) && txworkq == 0)
+			et_sched_tx_tasklet(et);
+#ifdef ET_ALL_PASSIVE
+		else {
+#ifdef CONFIG_SMP
+			if (online_cpus > 1)
+			schedule_work_on(1 - raw_smp_processor_id(), &et->txq_task.work);
+			else
+#endif /* CONFIG_SMP */
+			schedule_work(&et->txq_task.work);
+		}
+#endif /* ET_ALL_PASSIVE */
+	} else {
+			ET_LOCK(et);
+		et_sendnext(et);
+			ET_UNLOCK(et);
+	}
+
+	ET_LOG("et%d: et_start ret\n", et->etc->unit, 0);
+
+	return (0);
+}
+
+
+static void BCMFASTPATH
+et_tx_tasklet(ulong data)
+{
+	et_task_t task;
+	task.context = (void *)data;
+	et_txq_work(&task);
+}
+
+static void BCMFASTPATH
+et_sendnext(et_info_t *et)
+{
+	etc_info_t *etc;
+	struct sk_buff *skb;
+	void *p, *n;
+	uint32 priq = TX_Q0;
+	uint16 vlan_type;
+#ifdef DMA
+	uint32 txavail;
+	uint32 pktcnt;
+#endif
+
+	etc = et->etc;
+
+	ET_TRACE(("et%d: et_sendnext\n", etc->unit));
+	ET_LOG("et%d: et_sendnext", etc->unit, 0);
+
+	/* dequeue packets from highest priority queue and send */
+	while (1) {
+		ET_TXQ_LOCK(et);
+
+		if (etc->txq_state == 0)
+			break;
+
+		priq = etc_priq(etc->txq_state);
+
+		ET_TRACE(("et%d: txq_state %x priq %d txavail %d\n",
+		          etc->unit, etc->txq_state, priq,
+		          *(uint *)etc->txavail[priq]));
+
+		if ((skb = skb_peek(&et->txq[priq])) == NULL) {
+			etc->txq_state &= ~(1 << priq);
+			ET_TXQ_UNLOCK(et);
+			continue;
+		}
+
+#ifdef DMA
+		if (!PKTISCHAINED(skb)) {
+			pktcnt = skb_shinfo(skb)->nr_frags + 1;
+		} else {
+			pktcnt = PKTCCNT(skb);
+		}
+
+		/* current highest priority dma queue is full */
+		txavail = *(uint *)(etc->txavail[priq]);
+		if (txavail < pktcnt)
+#else /* DMA */
+		if (etc->pioactive != NULL)
+#endif /* DMA */
+			break;
+
+		skb = et_skb_dequeue(et, priq);
+
+		ET_TXQ_UNLOCK(et);
+		ET_PRHDR("tx", (struct ether_header *)skb->data, skb->len, etc->unit);
+		ET_PRPKT("txpkt", skb->data, skb->len, etc->unit);
+
+		/* convert the packet. */
+		p = PKTFRMNATIVE(etc->osh, skb);
+		ASSERT(p != NULL);
+
+		ET_TRACE(("%s: sdu %p chained %d chain sz %d next %p\n",
+		          __FUNCTION__, p, PKTISCHAINED(p), PKTCCNT(p), PKTCLINK(p)));
+
+		vlan_type = ((struct ethervlan_header *)PKTDATA(et->osh, p))->vlan_type;
+		FOREACH_CHAINED_PKT(p, n) {
+			PKTCLRCHAINED(et->osh, p);
+			/* replicate vlan header contents from curr frame */
+			if ((n != NULL) && (vlan_type == HTON16(ETHER_TYPE_8021Q))) {
+				uint8 *n_evh;
+				n_evh = PKTPUSH(et->osh, n, VLAN_TAG_LEN);
+				*(struct ethervlan_header *)n_evh =
+				*(struct ethervlan_header *)PKTDATA(et->osh, p);
+			} else if (n == NULL)
+				PKTCSETFLAG(p, 1);
+
+			if (PKTSUMNEEDED((struct sk_buff *)p))
+				et_cso(et, (struct sk_buff *)p);
+
+#ifdef ETFA
+			/* If this device is connected to FA, and FA is configures
+			 * to receive bcmhdr, add one.
+			 */
+			if (FA_TX_BCM_HDR((fa_t *)et->etc->fa)) {
+				p = fa_process_tx(et->etc->fa, p);
+
+				/* Bypass transmitting since the packet pointer is NULL */
+				if (p == NULL)
+					continue;
+			}
+#endif /* ETFA */
+			(*etc->chops->tx)(etc->ch, p);
+			etc->txframe++;
+			etc->txbyte += PKTLEN(et->osh, p);
+		}
+	}
+
+	ET_TXQ_UNLOCK(et);
+}
+
+void
+et_init(et_info_t *et, uint options)
+{
+	ET_TRACE(("et%d: et_init\n", et->etc->unit));
+	ET_LOG("et%d: et_init", et->etc->unit, 0);
+
+
+	etc_init(et->etc, options);
+}
+
+
+void
+et_reset(et_info_t *et)
+{
+	ET_TRACE(("et%d: et_reset\n", et->etc->unit));
+
+	etc_reset(et->etc);
+
+	/* zap any pending dpc interrupt bits */
+	et->events = 0;
+
+	/* dpc will not be rescheduled */
+	et->resched = 0;
+}
+
+void
+et_up(et_info_t *et)
+{
+	etc_info_t *etc;
+
+	etc = et->etc;
+
+	if (etc->up)
+		return;
+
+	ET_TRACE(("et%d: et_up\n", etc->unit));
+
+	etc_up(etc);
+
+	/* schedule one second watchdog timer */
+	et->timer.expires = jiffies + HZ;
+	add_timer(&et->timer);
+	et->set = TRUE;
+
+	netif_start_queue(et->dev);
+
+	ET_UNLOCK(et);
+	tasklet_enable(&et->tx_tasklet);
+	ET_LOCK(et);
+
+#if defined(BCM_GMAC3)
+	if (DEV_FWDER(et->etc)) {
+		ET_TRACE(("et%d: fwder<%d> up", etc->unit, etc->coreunit));
+		et->fwder_up = TRUE; /* enable et_forward() */
+	}
+#endif /* BCM_GMAC3 */
+
+#ifdef ETFA
+	if (et->etc->fa)
+		fa_et_up(et->etc->fa);
+#endif
+}
+
+void
+et_down(et_info_t *et, int reset)
+{
+	etc_info_t *etc;
+	struct sk_buff *skb;
+	int32 i;
+
+	etc = et->etc;
+
+	ET_TRACE(("et%d: et_down\n", etc->unit));
+
+#if defined(BCM_GMAC3)
+	if (DEV_FWDER(et->etc)) {
+		ET_TRACE(("et%d: fwder<%d> down", etc->unit, etc->coreunit));
+		et->fwder_up = FALSE; /* disable et_forward() */
+	}
+#endif /* BCM_GMAC3 */
+
+	netif_down(et->dev);
+	netif_stop_queue(et->dev);
+
+	/* stop watchdog timer */
+	del_timer(&et->timer);
+	et->set = FALSE;
+
+	/* LR:
+	 * Mark netif flag down,
+	 * to prevent tasklet from rescheduling itself,
+	 * and to prevent the ISR to scheduling any work items
+	 */
+	ET_FLAG_DOWN(etc);
+
+#if !defined(NAPI_POLL) && !defined(NAPI2_POLL)
+	/* kill dpc before cleaning out the queued buffers */
+	ET_UNLOCK(et);
+	tasklet_kill(&et->tasklet);
+	ET_LOCK(et);
+#endif /* NAPI_POLL */
+
+	/* kill tx tasklet */
+	ET_UNLOCK(et);
+	tasklet_disable(&et->tx_tasklet);
+	tasklet_kill(&et->tx_tasklet);
+	ET_LOCK(et);
+
+#ifdef ET_ALL_PASSIVE
+	/* Kill workqueue items too, or at least wait fo rthem to finisg */
+#ifdef	__USE_GPL_SYMBOLS_
+	/* LR:
+	 * This is the right way to do this, but we can't unless we release the
+	 * driver to GPL, which we're not allowed to.
+	 */
+	cancel_work_sync(&et->dpc_task.work);
+	cancel_work_sync(&et->txq_task.work);
+	cancel_work_sync(&et->wd_task.work);
+#else
+	flush_scheduled_work();
+#endif
+#endif /* ET_ALL_PASSIVE */
+
+	/*
+	 * LR: Now that all background activity ceased,
+	 * it should be safe to proceed with shutdown
+	 */
+
+	/* flush the txq(s) */
+	for (i = 0; i < NUMTXQ; i++)
+		while ((skb = et_skb_dequeue(et, i)))
+			PKTFREE(etc->osh, skb, TRUE);
+
+	/* Shut down the hardware, reclaim Rx buffers */
+	etc_down(etc, reset);
+
+#ifdef ETFA
+	if (et->etc->fa)
+		fa_et_down(et->etc->fa);
+#endif
+}
+
+/*
+ * These are interrupt on/off entry points. Disable interrupts
+ * during interrupt state transition.
+ */
+void
+et_intrson(et_info_t *et)
+{
+	unsigned long flags;
+	INT_LOCK(et, flags);
+	(*et->etc->chops->intrson)(et->etc->ch);
+	INT_UNLOCK(et, flags);
+}
+
+void
+et_discard(et_info_t *et, void *pkt)
+{
+	void * rxh = PKTDATA(et->osh, pkt);
+	int dataoff = HWRXOFF;
+
+#if defined(ETFA)
+	dataoff += et->fa_bhdr_sz;
+#endif
+	PKTPULL(et->osh, pkt, dataoff);
+
+	/* skb->data points to ethernet header for error reporting. */
+	et_error(et, (struct sk_buff *)pkt, rxh);
+
+	PKTFREE(et->osh, pkt, FALSE);
+}
+
+static void
+_et_watchdog(struct net_device *dev)
+{
+	et_info_t *et;
+
+	et = ET_INFO(dev);
+
+	ET_LOCK(et);
+
+	etc_watchdog(et->etc);
+
+	if (et->set) {
+		/* reschedule one second watchdog timer */
+		et->timer.expires = jiffies + HZ;
+		add_timer(&et->timer);
+	}
+
+#ifdef CTFPOOL
+	/* allocate and add a new skb to the pkt pool */
+	if (CTF_ENAB(et->cih))
+		osl_ctfpool_replenish(et->osh, CTFPOOL_REFILL_THRESH);
+#endif /* CTFPOOL */
+	ET_UNLOCK(et);
+}
+
+#ifdef ET_ALL_PASSIVE
+static void
+et_watchdog_task(et_task_t *task)
+{
+	et_info_t *et = (et_info_t *)task->context;
+
+	_et_watchdog((struct net_device *)et->dev);
+}
+#endif /* ET_ALL_PASSIVE */
+
+static void
+et_watchdog(ulong data)
+{
+	struct net_device *dev = (struct net_device *)data;
+#ifdef ET_ALL_PASSIVE
+	et_info_t *et = ET_INFO(dev);
+#endif /* ET_ALL_PASSIVE */
+
+	if (!ET_ALL_PASSIVE_ENAB(et))
+		_et_watchdog(dev);
+#ifdef ET_ALL_PASSIVE
+	else
+		schedule_work(&et->wd_task.work);
+#endif /* ET_ALL_PASSIVE */
+}
+
+
+static int
+et_get_settings(struct net_device *dev, struct ethtool_cmd *ecmd)
+{
+	et_info_t *et = ET_INFO(dev);
+
+	ecmd->supported = (SUPPORTED_10baseT_Half | SUPPORTED_10baseT_Full |
+	                   SUPPORTED_100baseT_Half | SUPPORTED_100baseT_Full |
+	                   SUPPORTED_Autoneg);
+	ecmd->advertising = ADVERTISED_TP;
+	ecmd->advertising |= (et->etc->advertise & ADV_10HALF) ?
+	        ADVERTISED_10baseT_Half : 0;
+	ecmd->advertising |= (et->etc->advertise & ADV_10FULL) ?
+	        ADVERTISED_10baseT_Full : 0;
+	ecmd->advertising |= (et->etc->advertise & ADV_100HALF) ?
+	        ADVERTISED_100baseT_Half : 0;
+	ecmd->advertising |= (et->etc->advertise & ADV_100FULL) ?
+	        ADVERTISED_100baseT_Full : 0;
+	ecmd->advertising |= (et->etc->advertise2 & ADV_1000FULL) ?
+	        ADVERTISED_1000baseT_Full : 0;
+	ecmd->advertising |= (et->etc->advertise2 & ADV_1000HALF) ?
+	        ADVERTISED_1000baseT_Half : 0;
+	ecmd->advertising |= (et->etc->forcespeed == ET_AUTO) ?
+	        ADVERTISED_Autoneg : 0;
+	if (et->etc->linkstate) {
+		ecmd->speed = (et->etc->speed == 1000) ? SPEED_1000 :
+		               ((et->etc->speed == 100) ? SPEED_100 : SPEED_10);
+		ecmd->duplex = (et->etc->duplex == 1) ? DUPLEX_FULL : DUPLEX_HALF;
+	} else {
+		ecmd->speed = 0;
+		ecmd->duplex = 0;
+	}
+	ecmd->port = PORT_TP;
+	ecmd->phy_address = 0;
+	ecmd->transceiver = XCVR_INTERNAL;
+	ecmd->autoneg = (et->etc->forcespeed == ET_AUTO) ? AUTONEG_ENABLE : AUTONEG_DISABLE;
+	ecmd->maxtxpkt = 0;
+	ecmd->maxrxpkt = 0;
+
+	return 0;
+}
+
+static int
+et_set_settings(struct net_device *dev, struct ethtool_cmd *ecmd)
+{
+	int speed;
+	et_info_t *et = ET_INFO(dev);
+
+	if (!capable(CAP_NET_ADMIN))
+		return (-EPERM);
+
+	else if (ecmd->speed == SPEED_10 && ecmd->duplex == DUPLEX_HALF)
+		speed = ET_10HALF;
+	else if (ecmd->speed == SPEED_10 && ecmd->duplex == DUPLEX_FULL)
+		speed = ET_10FULL;
+	else if (ecmd->speed == SPEED_100 && ecmd->duplex == DUPLEX_HALF)
+		speed = ET_100HALF;
+	else if (ecmd->speed == SPEED_100 && ecmd->duplex == DUPLEX_FULL)
+		speed = ET_100FULL;
+	else if (ecmd->speed == SPEED_1000 && ecmd->duplex == DUPLEX_FULL)
+		speed = ET_1000FULL;
+	else if (ecmd->autoneg == AUTONEG_ENABLE)
+		speed = ET_AUTO;
+	else
+		return (-EINVAL);
+
+	return etc_ioctl(et->etc, ETCSPEED, &speed);
+}
+
+static void
+et_get_driver_info(struct net_device *dev, struct ethtool_drvinfo *info)
+{
+	et_info_t *et = ET_INFO(dev);
+
+	bzero(info, sizeof(struct ethtool_drvinfo));
+	info->cmd = ETHTOOL_GDRVINFO;
+	sprintf(info->driver, "et%d", et->etc->unit);
+	strncpy(info->version, EPI_VERSION_STR, sizeof(info->version));
+	info->version[(sizeof(info->version))-1] = '\0';
+}
+
+#ifdef SIOCETHTOOL
+static int
+et_ethtool(et_info_t *et, struct ethtool_cmd *ecmd)
+{
+	int ret = 0;
+
+	ET_LOCK(et);
+
+	switch (ecmd->cmd) {
+	case ETHTOOL_GSET:
+		ret = et_get_settings(et->dev, ecmd);
+		break;
+	case ETHTOOL_SSET:
+		ret = et_set_settings(et->dev, ecmd);
+		break;
+	case ETHTOOL_GDRVINFO:
+		et_get_driver_info(et->dev, (struct ethtool_drvinfo *)ecmd);
+		break;
+	default:
+		ret = -EINVAL;
+		break;
+	}
+
+	ET_UNLOCK(et);
+
+	return (ret);
+}
+#endif /* SIOCETHTOOL */
+
+static int
+et_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+{
+	et_info_t *et;
+	int error;
+	char *buf;
+	int size, ethtoolcmd;
+	bool get = 0, set;
+	et_var_t *var = NULL;
+	void *buffer = NULL;
+
+	et = ET_INFO(dev);
+
+	ET_TRACE(("et%d: et_ioctl: cmd 0x%x\n", et->etc->unit, cmd));
+
+	switch (cmd) {
+#ifdef SIOCETHTOOL
+	case SIOCETHTOOL:
+		if (copy_from_user(&ethtoolcmd, ifr->ifr_data, sizeof(uint32)))
+			return (-EFAULT);
+
+		if (ethtoolcmd == ETHTOOL_GDRVINFO)
+			size = sizeof(struct ethtool_drvinfo);
+		else
+			size = sizeof(struct ethtool_cmd);
+		get = TRUE; set = TRUE;
+		break;
+#endif /* SIOCETHTOOL */
+	case SIOCGETCDUMP:
+		size = IOCBUFSZ;
+		get = TRUE; set = FALSE;
+		break;
+	case SIOCGETCPHYRD:
+	case SIOCGETCPHYRD2:
+	case SIOCGETCROBORD:
+		size = sizeof(int) * 4;
+		get = TRUE; set = TRUE;
+		break;
+	case SIOCSETCPHYWR:
+	case SIOCSETCPHYWR2:
+	case SIOCSETCROBOWR:
+		size = sizeof(int) * 4;
+		get = FALSE; set = TRUE;
+		break;
+	case SIOCSETGETVAR:
+		size = sizeof(et_var_t);
+		set = TRUE;
+		break;
+	default:
+		size = sizeof(int);
+		get = FALSE; set = TRUE;
+		break;
+	}
+
+	if ((buf = MALLOC(et->osh, size)) == NULL) {
+		ET_ERROR(("et: et_ioctl: out of memory, malloced %d bytes\n", MALLOCED(et->osh)));
+		return (-ENOMEM);
+	}
+
+	if (set && copy_from_user(buf, ifr->ifr_data, size)) {
+		MFREE(et->osh, buf, size);
+		return (-EFAULT);
+	}
+
+	if (cmd == SIOCSETGETVAR) {
+		var = (et_var_t *)buf;
+		if (var->buf) {
+			if (!var->set)
+				get = TRUE;
+
+			if (!(buffer = (void *) MALLOC(et->osh, var->len))) {
+				ET_ERROR(("et: et_ioctl: out of memory, malloced %d bytes\n",
+					MALLOCED(et->osh)));
+				MFREE(et->osh, buf, size);
+				return (-ENOMEM);
+			}
+
+			if (copy_from_user(buffer, var->buf, var->len)) {
+				MFREE(et->osh, buffer, var->len);
+				MFREE(et->osh, buf, size);
+				return (-EFAULT);
+			}
+		}
+	}
+
+	switch (cmd) {
+#ifdef SIOCETHTOOL
+	case SIOCETHTOOL:
+		error = et_ethtool(et, (struct ethtool_cmd *)buf);
+		break;
+#endif /* SIOCETHTOOL */
+	case SIOCSETGETVAR:
+		ET_LOCK(et);
+		error = etc_iovar(et->etc, var->cmd, var->set, buffer, var->len);
+		ET_UNLOCK(et);
+		if (!error && get)
+			error = copy_to_user(var->buf, buffer, var->len);
+
+		if (buffer)
+			MFREE(et->osh, buffer, var->len);
+		break;
+	default:
+		ET_LOCK(et);
+		error = etc_ioctl(et->etc, cmd - SIOCSETCUP, buf) ? -EINVAL : 0;
+		ET_UNLOCK(et);
+		break;
+	}
+
+	if (!error && get)
+		error = copy_to_user(ifr->ifr_data, buf, size);
+
+	MFREE(et->osh, buf, size);
+
+	return (error);
+}
+
+static struct net_device_stats *
+et_get_stats(struct net_device *dev)
+{
+	et_info_t *et;
+	etc_info_t *etc;
+	struct net_device_stats *stats;
+	int locked = 0;
+
+	et = ET_INFO(dev);
+
+	ET_TRACE(("et%d: et_get_stats\n", et->etc->unit));
+
+	if (!in_atomic()) {
+		locked = 1;
+		ET_LOCK(et);
+	}
+
+	etc = et->etc;
+	stats = &et->stats;
+	bzero(stats, sizeof(struct net_device_stats));
+
+	/* refresh stats */
+	if (et->etc->up)
+		(*etc->chops->statsupd)(etc->ch);
+
+	/* SWAG */
+	stats->rx_packets = etc->rxframe;
+	stats->tx_packets = etc->txframe;
+	stats->rx_bytes = etc->rxbyte;
+	stats->tx_bytes = etc->txbyte;
+	stats->rx_errors = etc->rxerror;
+	stats->tx_errors = etc->txerror;
+
+	if (ET_GMAC(etc)) {
+		gmacmib_t *mib;
+
+		mib = etc->mib;
+		stats->collisions = mib->tx_total_cols;
+		stats->rx_length_errors = (mib->rx_oversize_pkts + mib->rx_undersize);
+		stats->rx_crc_errors = mib->rx_crc_errs;
+		stats->rx_frame_errors = mib->rx_align_errs;
+		stats->rx_missed_errors = mib->rx_missed_pkts;
+	} else {
+		bcmenetmib_t *mib;
+
+		mib = etc->mib;
+		stats->collisions = mib->tx_total_cols;
+		stats->rx_length_errors = (mib->rx_oversize_pkts + mib->rx_undersize);
+		stats->rx_crc_errors = mib->rx_crc_errs;
+		stats->rx_frame_errors = mib->rx_align_errs;
+		stats->rx_missed_errors = mib->rx_missed_pkts;
+
+	}
+
+	stats->rx_fifo_errors = etc->rxoflo;
+	stats->rx_over_errors = etc->rxgiants;
+	stats->tx_fifo_errors = etc->txuflo;
+
+	if (locked)
+		ET_UNLOCK(et);
+
+	return (stats);
+}
+
+static int
+et_set_mac_address(struct net_device *dev, void *addr)
+{
+	et_info_t *et;
+	struct sockaddr *sa = (struct sockaddr *) addr;
+
+	et = ET_INFO(dev);
+	ET_TRACE(("et%d: et_set_mac_address\n", et->etc->unit));
+
+	if (et->etc->up)
+		return -EBUSY;
+
+	bcopy(sa->sa_data, dev->dev_addr, ETHER_ADDR_LEN);
+	bcopy(dev->dev_addr, &et->etc->cur_etheraddr, ETHER_ADDR_LEN);
+
+	return 0;
+}
+
+static void
+et_set_multicast_list(struct net_device *dev)
+{
+	et_info_t *et;
+	etc_info_t *etc;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 36)
+	struct dev_mc_list *mclist;
+#else
+	struct netdev_hw_addr *ha;
+#endif
+	int i;
+	int locked = 0;
+
+	et = ET_INFO(dev);
+	etc = et->etc;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 36)
+	mclist = NULL ;		/* fend off warnings */
+#else
+	ha = NULL;
+#endif
+
+	ET_TRACE(("et%d: et_set_multicast_list\n", etc->unit));
+
+	if (!in_atomic()) {
+		locked = 1;
+		ET_LOCK(et);
+	}
+
+	if (etc->up) {
+		etc->promisc = (dev->flags & IFF_PROMISC)? TRUE: FALSE;
+		etc->allmulti = (dev->flags & IFF_ALLMULTI)? TRUE: etc->promisc;
+
+		/* copy the list of multicasts into our private table */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 36)
+		for (i = 0, mclist = dev->mc_list; mclist && (i < dev->mc_count);
+			i++, mclist = mclist->next) {
+			if (i >= MAXMULTILIST) {
+				etc->allmulti = TRUE;
+				i = 0;
+				break;
+			}
+			etc->multicast[i] = *((struct ether_addr *)mclist->dmi_addr);
+		}
+#else	/* >= 2.6.36 */
+		i = 0;
+		netdev_for_each_mc_addr(ha, dev) {
+			i ++;
+			if (i >= MAXMULTILIST) {
+				etc->allmulti = TRUE;
+				i = 0;
+				break;
+			}
+			etc->multicast[i] = *((struct ether_addr *)ha->addr);
+		} /* for each ha */
+#endif /* LINUX_VERSION_CODE */
+		etc->nmulticast = i;
+
+		/* LR: partial re-init, DMA is already initialized */
+		et_init(et, ET_INIT_INTRON);
+	}
+
+	if (locked)
+		ET_UNLOCK(et);
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 20)
+static irqreturn_t BCMFASTPATH
+et_isr(int irq, void *dev_id)
+#else
+static irqreturn_t BCMFASTPATH
+et_isr(int irq, void *dev_id, struct pt_regs *ptregs)
+#endif
+{
+	et_info_t *et;
+	struct chops *chops;
+	void *ch;
+	uint events = 0;
+
+	et = (et_info_t *)dev_id;
+	chops = et->etc->chops;
+	ch = et->etc->ch;
+
+	/* guard against shared interrupts */
+	if (!et->etc->up)
+		goto done;
+
+	/* get interrupt condition bits */
+	events = (*chops->getintrevents)(ch, TRUE);
+
+	/* not for us */
+	if (!(events & INTR_NEW))
+		goto done;
+
+	ET_TRACE(("et%d: et_isr: events 0x%x\n", et->etc->unit, events));
+	ET_LOG("et%d: et_isr: events 0x%x", et->etc->unit, events);
+
+	/* disable interrupts */
+	(*chops->intrsoff)(ch);
+
+	/* save intstatus bits */
+	ASSERT(et->events == 0);
+	et->events = events;
+
+	ASSERT(et->resched == FALSE);
+
+#ifdef NAPI2_POLL
+
+	napi_schedule(&et->napi_poll);
+
+#elif defined(NAPI_POLL)
+	/* allow the device to be added to the cpu polling list if we are up */
+	if (netif_rx_schedule_prep(et->dev)) {
+		/* tell the network core that we have packets to send up */
+		__netif_rx_schedule(et->dev);
+	} else {
+		ET_ERROR(("et%d: et_isr: intr while in poll!\n",
+		          et->etc->unit));
+		(*chops->intrson)(ch);
+	}
+#else /* ! NAPI_POLL && ! NAPI2_POLL */
+	/* schedule dpc */
+#ifdef ET_ALL_PASSIVE
+	if (ET_ALL_PASSIVE_ENAB(et)) {
+		schedule_work(&et->dpc_task.work);
+	} else
+#endif /* ET_ALL_PASSIVE */
+	tasklet_schedule(&et->tasklet);
+#endif /* NAPI_POLL */
+
+done:
+	ET_LOG("et%d: et_isr ret", et->etc->unit, 0);
+
+	return IRQ_RETVAL(events & INTR_NEW);
+}
+
+#ifdef PKTC
+static void
+et_sendup_chain_error_handler(et_info_t *et, struct sk_buff *skb, uint sz, int32 err)
+{
+	struct sk_buff *nskb;
+	uint16 vlan_tag;
+	struct ethervlan_header *n_evh;
+
+	ASSERT(err != BCME_OK);
+
+	et->etc->chained -= sz;
+	et->etc->unchained += sz;
+
+	/* get original vlan tag from the first packet */
+	vlan_tag = ((struct ethervlan_header *)PKTDATA(et->osh, skb))->vlan_tag;
+
+	FOREACH_CHAINED_PKT(skb, nskb) {
+		PKTCLRCHAINED(et->osh, skb);
+		PKTCCLRFLAGS(skb);
+		if (nskb != NULL) {
+			/* update vlan header changed by CTF_HOTBRC_L2HDR_PREP */
+			n_evh = (struct ethervlan_header *)PKTDATA(et->osh, nskb);
+
+			if (n_evh->vlan_type == HTON16(ETHER_TYPE_8021Q)) {
+				/* change back original vlan tag */
+				n_evh = (struct ethervlan_header *)PKTDATA(et->osh, nskb);
+				n_evh->vlan_tag = vlan_tag;
+			}
+			else {
+				/* add back original vlan header */
+				n_evh = (struct ethervlan_header *)PKTPUSH(et->osh, nskb,
+					VLAN_TAG_LEN);
+				*n_evh = *(struct ethervlan_header *)PKTDATA(et->osh, skb);
+			}
+			nskb->dev = skb->dev;
+		}
+		PKTSETPRIO(skb, 0);
+		/* Update the PKTCCNT and PKTCLEN for unchained sendup cases */
+		PKTCSETCNT(skb, 1);
+		PKTCSETLEN(skb, PKTLEN(et->etc->osh, skb));
+
+		if (et_ctf_forward(et, skb) == BCME_OK) {
+			ET_ERROR(("et%d: shall not happen\n", et->etc->unit));
+		}
+
+		if (et->etc->qos)
+			pktsetprio(skb, TRUE);
+
+		skb->protocol = eth_type_trans(skb, skb->dev);
+
+			/* send it up */
+#if defined(NAPI_POLL) || defined(NAPI2_POLL)
+		netif_receive_skb(skb);
+#else /* NAPI_POLL */
+		netif_rx(skb);
+#endif /* NAPI_POLL */
+	}
+}
+
+static void BCMFASTPATH
+et_sendup_chain(et_info_t *et, void *h)
+{
+	struct sk_buff *skb;
+	uint sz = PKTCCNT(h);
+	osl_t * osh = et->etc->osh;
+	int32 err;
+
+	ASSERT(h != NULL);
+
+	ASSERT((sz > 0) && (sz <= PKTCBND));
+	ET_TRACE(("et%d: %s: sending up packet chain of sz %d\n",
+	          et->etc->unit, __FUNCTION__, sz));
+	et->etc->chained += sz;
+#ifdef BCMDBG
+	et->etc->chainsz[sz - 1] += sz;
+#endif
+	et->etc->currchainsz = sz;
+	et->etc->maxchainsz = MAX(et->etc->maxchainsz, sz);
+
+	skb = PKTTONATIVE(osh, h);
+	skb->dev = et->dev;
+
+#if defined(BCM_GMAC3)
+	/* Forward chain directly to wl transmit */
+	if (DEV_FWDER(et->etc)) { /* BCM_GMAC3 */
+		if (fwder_transmit(et->fwdh, skb, sz, skb->dev) != FWDER_SUCCESS) {
+			PKTFRMNATIVE(osh, skb);
+			PKTCFREE(osh, skb, FALSE);
+		}
+	} else
+#endif /* BCM_GMAC3 */
+	{
+		/* send up the packet chain */
+		if ((err = ctf_forward(et->cih, h, skb->dev)) == BCME_OK)
+			return;
+		et_sendup_chain_error_handler(et, skb, sz, err);
+	}
+}
+#endif /* PKTC */
+
+#ifdef ET_INGRESS_QOS
+static inline bool
+et_discard_rx(et_info_t *et, struct chops *chops,
+	void *ch, uint8 *evh, uint8 prio, uint16 toss, int quota)
+{
+	uint16 left;
+
+	/* Regardless of DMA RX discard policy ICMP and IGMP packets are passed */
+	if (IP_PROT46(evh + ETHERVLAN_HDR_LEN) != IP_PROT_IGMP &&
+		IP_PROT46(evh + ETHERVLAN_HDR_LEN) != IP_PROT_ICMP) {
+		ASSERT(chops->activerxbuf);
+		left = (*chops->activerxbuf)(ch);
+		if (left < et->etc->dma_rx_thresh && toss < (quota << TOSS_CAP)) {
+			if ((et->etc->dma_rx_policy == DMA_RX_POLICY_TOS &&
+				prio != IPV4_TOS_CRITICAL) ||
+				(et->etc->dma_rx_policy == DMA_RX_POLICY_UDP &&
+				IP_PROT46(evh + ETHERVLAN_HDR_LEN) != IP_PROT_UDP)) {
+				/* discard the packet */
+				return TRUE;
+			}
+		}
+	}
+	return FALSE;
+}
+#endif /* ET_INGRESS_QOS */
+
+#if defined(PKTC)
+/*
+ * +----------------------------------------------------------------------------
+ *
+ * Packet Chaining PASS #2. PKTC handles all bridged packets by explicitly
+ * chaining them before fwding via the CTF layer. A chain database is first
+ * initialized. The chain database is populated with first seen Mac addresses.
+ * The chain database is also used to compose a chain for all packets that match
+ * the CD entry as well as meet several criteria, e.g. match Eth Da, Sa, prio,
+ * EtherType, etc with an hashed looked up entry in the hot brc cache.
+ * Chained packets are forwarded in one shot via CTF.
+ *
+ * Packets that miss the chain database, are returned for single packet
+ * processing via an attempt through CTF.
+ *
+ * +----------------------------------------------------------------------------
+ */
+static inline int
+et_chain_rx(et_info_t *et, int rxcnt, void **rxpkts, const int dataoff,
+            struct chops *chops, void *ch)
+{
+	void *pkt;
+	osl_t *osh = et->osh;
+	int nrx, nochain = 0;
+	bool stop_chain = FALSE;
+#ifdef ET_INGRESS_QOS
+	uint16 left = NRXBUFPOST, tossed = 0, quota = rxcnt;
+#endif /* ET_INGRESS_QOS */
+	pktc_data_t cd[PKTCMC] = {{0}};
+	uint8 *evh, prio;
+	int32 i = 0, cidx = 0;
+#if defined(USBAP)
+	bool check_tcp_ctrl = SKIP_TCP_CTRL_CHECK(et);
+#endif /* USBAP */
+
+	for (nrx = 0; nrx < rxcnt; nrx++) {
+
+		pkt = rxpkts[nrx]; /* fetch the next pkt */
+
+		ASSERT(pkt != NULL);
+		ASSERT(PKTCLINK(pkt) == NULL);
+
+		evh = PKTDATA(osh, pkt) + dataoff; /* fetch eth_vlan hdr start */
+
+#if defined(BCM_GMAC3)
+		if (DEV_FWDER(et->etc)) {
+			prio = IP_TOS46(evh + ETHER_HDR_LEN) >> IPV4_TOS_PREC_SHIFT;
+		} else
+#endif /* BCM_GMAC3 */
+		{
+			prio = IP_TOS46(evh + ETHERVLAN_HDR_LEN) >> IPV4_TOS_PREC_SHIFT;
+
+#ifdef ET_INGRESS_QOS
+			if (et->etc->dma_rx_policy) {
+				if (et_discard_rx(et, chops, ch, evh, prio, tossed, quota)) {
+					PKTFREE(et->osh, pkt, FALSE); /* toss the packet */
+					tossed++;
+					continue;
+				}
+			}
+#endif /* ET_INGRESS_QOS */
+		}
+
+		/* In case of WAN originating pkt, prio is incorrect */
+
+#if defined(USBAP)
+		if (check_tcp_ctrl && PKT_IS_TCP_CTRL(osh, pkt)) {
+			rxpkts[nochain] = pkt;
+			nochain++;
+		} else
+#endif /* USBAP */
+		{
+			if (cd[0].h_da == NULL) {
+				cd[0].h_da = evh; cd[0].h_sa = evh + ETHER_ADDR_LEN;
+				cd[0].h_prio = prio;
+			}
+
+			for (i = 0; i <= cidx; i++) {
+				if (is_pkt_chainable(et, pkt, evh, prio, &cd[i],
+				                     DEV_NTKIF(et->etc))) {
+					break;
+				}
+				else if ((i + 1 < PKTCMC) && (cd[i + 1].h_da == NULL)) {
+					cidx++;
+					cd[cidx].h_da = evh;
+					cd[cidx].h_sa = evh + ETHER_ADDR_LEN;
+					cd[cidx].h_prio = prio;
+				}
+			}
+
+			/* entry matched or new entry created in cd[] */
+			if ((i < PKTCMC) && !stop_chain) {
+
+				int pktlen = PKTLEN(osh, pkt);
+
+				/* enqueue chainable packet into cd's list */
+				PKTCENQTAIL(cd[i].chead, cd[i].ctail, pkt);
+
+				et->etc->rxbyte += pktlen;
+				PKTSETLEN(osh, pkt, pktlen - ETHER_CRC_LEN); /* strip crc32 */
+
+#if defined(ETFA)
+				{
+					int nid;
+					if (et->fa_bhdr_sz) {
+						nid = fa_get_nid_rx(osh, pkt, HWRXOFF);
+					} else {
+						nid = BCM_FA_INVALID_IDX_VAL;
+					}
+					PKTSETFAHIDX(pkt, BCM_FA_INVALID_IDX_VAL);
+				}
+#endif /* ETFA */
+
+				/* Pull in one shot, both HW Rx Hdr (and BRCMHdr, if present) */
+				PKTPULL(osh, pkt, dataoff);
+
+				/* update header for non-first frames */
+				if (DEV_NTKIF(et->etc) && cd[i].chead != pkt) {
+					/* Possibly another PKTPULL to pop VLAN hdr */
+					CTF_HOTBRC_L2HDR_PREP(osh, et->brc_hot, prio,
+					                      PKTDATA(osh, pkt), pkt);
+				}
+
+				PKTCINCRCNT(cd[i].chead);
+				PKTSETCHAINED(osh, pkt);
+				PKTCADDLEN(cd[i].chead, PKTLEN(osh, pkt));
+
+				if (PKTCCNT(cd[i].chead) >= PKTCBND)
+					stop_chain = TRUE;
+
+			} else { /* not chainable, so return pkt via rxpkts array */
+
+				rxpkts[nochain] = pkt; /* for, single sendup processing */
+				nochain++;
+			}
+		}
+	}   /* for nrx < rxcnt */
+
+	et->etc->rxframe += rxcnt - nochain;
+#ifdef ET_INGRESS_QOS
+	et->etc->rxframe -= tossed;
+#endif
+
+	/* send up the chain(s) at one fell swoop */
+	ASSERT(cidx < PKTCMC);
+
+	for (i = 0; i <= cidx; i++) {
+		if (cd[i].chead != NULL) {
+			PKTSETPRIO(cd[i].chead, cd[i].h_prio);
+			et_sendup_chain(et, cd[i].chead);
+		}
+	}
+
+	return nochain; /* number of single pkt processing pass */
+}
+#endif /* PKTC */
+
+/*
+ * +----------------------------------------------------------------------------
+ * CTF forwarded PASS #3. All packets that miss WOFA and PKTC, are now processed
+ * one at a time.
+ * +----------------------------------------------------------------------------
+ */
+static inline void
+et_single_rx(et_info_t *et, int rxcnt, void **rxpkts, int dataoff)
+{
+	int nrx;
+	struct sk_buff *skb;
+
+	et->etc->unchained += rxcnt;
+
+	for (nrx = 0; nrx < rxcnt; nrx++) {
+		ASSERT(rxpkts[nrx] != NULL);
+
+		skb = PKTTONATIVE(et->osh, rxpkts[nrx]);
+
+#if defined(BCM_GMAC3)
+		if (DEV_FWDER(et->etc)) {
+			struct ether_header *eh;
+			eh = (struct ether_header *)(skb->data + dataoff);
+			skb->priority = IP_TOS46(eh + ETHER_HDR_LEN) >> IPV4_TOS_PREC_SHIFT;
+		} else
+#endif /* BCM_GMAC3 */
+		{
+			PKTSETPRIO(skb, 0);
+		}
+
+		et_sendup(et, skb, dataoff);
+	}
+}
+
+static /* inline */ int BCMFASTPATH
+et_rxevent(void * ch, int quota, struct chops *chops, et_info_t *et)
+{
+	int rxcnt;
+	void *rxpkts[ETCQUOTA_MAX];
+#if defined(ETFA)
+	const int dataoff = HWRXOFF + et->fa_bhdr_sz;
+#else  /* ! ETFA */
+	const int dataoff = HWRXOFF;
+#endif /* ! ETFA */
+
+	/* fetch max quota number of pkts from rx ring, and save in rxpkts */
+	/* chiprxquota does not check RXH_FLAGS,etc. and only prefetches 8x64bits */
+	rxcnt = (*chops->rxquota)(ch, quota, rxpkts); /* refills at the end */
+
+	/* reschedule et_dpc()/et_poll(): if pkts may be pending in rx ring */
+	et->resched = (rxcnt >= quota); /* Need fixup for ET_INGRESS_QOS */
+	quota = rxcnt;  /* quota: total number of pkts that will be processed */
+
+#if defined(ETFA)
+	if (et->fa_aux_dev) /* No bulk bypass processing for FA aux port */
+		goto fa_aux_skip_bulk_bypass;
+#endif /* ETFA */
+
+#if defined(BCM_GMAC3)
+	/* If Dongle mode forwarder, transmit array of packets to dongle host driver
+	 * which will consume all packets (or free them on error).
+	 */
+	if (DEV_FWDER(et->etc) && (fwder_is_mode(et->fwdh, FWDER_DNG_MODE))) {
+
+		/* Bulk decrement pktalloced count. If fwder fails to transfer the pkts,
+		 * then increment pktalloced count before freeing to ctfpool.
+		 */
+		PKTTOFWDER(et->osh, rxpkts, rxcnt);
+
+		if (fwder_transmit(et->fwdh, (void *)rxpkts, rxcnt, et->dev) != FWDER_SUCCESS) {
+			int cnt;
+			PKTFRMFWDER(et->osh, rxpkts, rxcnt);
+			for (cnt = 0; cnt < rxcnt; cnt++) {
+				PKTFREE(et->osh, rxpkts[cnt], FALSE);
+			}
+		}
+		goto fwder_dng_bypass;
+	}
+#endif /* BCM_GMAC3 */
+
+	/* DEV FWDER::FWDER_NIC_MODE or DEV_NTK.
+	 * DEV_FWDER: NIC Mode fwder will bridge pkts to WLAN using pkt chaining.
+	 * DEV_NTK: Network device will bridge/route packets with chaining/CTF.
+	 */
+#if defined(PKTC)
+	if (PKTC_ENAB(et)) {
+		rxcnt = et_chain_rx(et, rxcnt, rxpkts, dataoff, chops, ch);
+	}
+#endif /* PKTC */
+
+#if defined(ETFA)
+fa_aux_skip_bulk_bypass:
+#endif /* ET_FA */
+
+	/* Process leftover rxcnt number of unchained pkts, sendup one at a time. */
+	(void)et_single_rx(et, rxcnt, rxpkts, dataoff);
+
+#if defined(BCM_GMAC3)
+fwder_dng_bypass:
+#endif
+
+#if defined(BCMDBG)
+	et->etc->rxprocessed += quota;
+#endif /* BCMDBG */
+
+	return quota; /* total number of processed pkts */
+}
+
+#if defined(NAPI2_POLL)
+static int BCMFASTPATH
+et_poll(struct napi_struct *napi, int budget)
+{
+	int quota = budget;
+	struct net_device *dev = napi->dev;
+	et_info_t *et = ET_INFO(dev);
+
+#elif defined(NAPI_POLL)
+static int BCMFASTPATH
+et_poll(struct net_device *dev, int *budget)
+{
+	int quota = min(RXBND, *budget);
+	et_info_t *et = ET_INFO(dev);
+#else /* NAPI_POLL */
+static void BCMFASTPATH
+et_dpc(ulong data)
+{
+	et_info_t *et = (et_info_t *)data;
+	int quota = et->etc->quota;
+#endif /* NAPI_POLL */
+	struct chops *chops;
+	void *ch;
+	uint nrx = 0;
+
+	chops = et->etc->chops;
+	ch = et->etc->ch;
+
+	ET_TRACE(("et%d: et_dpc: events 0x%x\n", et->etc->unit, et->events));
+	ET_LOG("et%d: et_dpc: events 0x%x", et->etc->unit, et->events);
+
+#if !defined(NAPI_POLL) && !defined(NAPI2_POLL)
+	ET_LOCK(et);
+#endif /* ! NAPIx_POLL */
+
+	if (!et->etc->up)
+		goto done;
+
+	/* get interrupt condition bits again when dpc was rescheduled */
+	if (et->resched) {
+		et->events = (*chops->getintrevents)(ch, FALSE);
+		et->resched = FALSE;
+	}
+
+	if (et->events & INTR_RX) {
+		nrx = et_rxevent(ch, quota, chops, et);
+	}
+
+	if (et->events & INTR_TX)
+		(*chops->txreclaim)(ch, FALSE);
+
+	(*chops->rxfill)(ch);
+
+	/* handle error conditions, if reset required leave interrupts off! */
+	if (et->events & INTR_ERROR) {
+		if ((*chops->errors)(ch))
+			et_init(et, ET_INIT_INTROFF);
+		else
+			if (nrx < quota) {
+				nrx += et_rxevent(ch, quota, chops, et);
+			}
+	}
+
+	/* run the tx queue */
+	if (et->etc->txq_state != 0) {
+		if (!ET_ALL_PASSIVE_ENAB(et) && txworkq == 0)
+			et_sendnext(et);
+#ifdef ET_ALL_PASSIVE
+#ifdef CONFIG_SMP
+		else if (txworkq && online_cpus > 1) {
+			schedule_work_on(1 - raw_smp_processor_id(), &et->txq_task.work);
+		}
+#endif
+		else {
+			schedule_work(&et->txq_task.work);
+		}
+#endif /* ET_ALL_PASSIVE */
+	}
+
+	/* clear this before re-enabling interrupts */
+	et->events = 0;
+
+	/* something may bring the driver down */
+	if (!et->etc->up) {
+		et->resched = FALSE;
+		goto done;
+	}
+
+#if !defined(NAPI_POLL) && !defined(NAPI2_POLL)
+#ifdef ET_ALL_PASSIVE
+	if (et->resched) {
+		if (!ET_ALL_PASSIVE_ENAB(et)) {
+			tasklet_schedule(&et->tasklet);
+		} else {
+			schedule_work(&et->dpc_task.work);
+		}
+	}
+	else {
+#if defined(BCM_GMAC3)
+		if (DEV_FWDER(et->etc)) {
+			(*chops->rxlazy)(ch);
+		}
+#endif /* BCM_GMAC3 */
+		(*chops->intrson)(ch);
+	}
+#else /* ET_ALL_PASSIVE */
+	/* there may be frames left, reschedule et_dpc() */
+	if (et->resched) {
+		tasklet_schedule(&et->tasklet);
+	/* re-enable interrupts */
+	} else {
+#if defined(BCM_GMAC3)
+		if (DEV_FWDER(et->etc)) {
+			(*chops->rxlazy)(ch);
+		}
+#endif /* BCM_GMAC3 */
+		(*chops->intrson)(ch);
+	}
+#endif /* ET_ALL_PASSIVE */
+#endif /* ! NAPIx_POLL */
+
+done:
+	ET_LOG("et%d: et_dpc ret", et->etc->unit, 0);
+
+#if defined(NAPI_POLL) || defined(NAPI2_POLL)
+#ifdef	NAPI_POLL
+	/* update number of frames processed */
+	*budget -= nrx;
+	dev->quota -= nrx;
+
+	ET_TRACE(("et%d: et_poll: quota %d budget %d\n",
+	          et->etc->unit, dev->quota, *budget));
+#else
+	ET_TRACE(("et%d: et_poll: budget %d\n",
+	          et->etc->unit, budget));
+#endif
+
+	/* we got packets but no quota */
+	if (et->resched)
+		/* indicate that we are not done, don't enable
+		 * interrupts yet. linux network core will call
+		 * us again.
+		 */
+		return (1);
+
+#ifdef	NAPI2_POLL
+	napi_complete(napi);
+#else	/* NAPI_POLL */
+	netif_rx_complete(dev);
+#endif
+
+	/* enable interrupts now */
+	(*chops->intrson)(ch);
+
+	/* indicate that we are done */
+	return (0);
+#else /* NAPI_POLL */
+	ET_UNLOCK(et);
+	return;
+#endif /* NAPI_POLL */
+}
+
+#ifdef ET_ALL_PASSIVE
+static void BCMFASTPATH
+et_dpc_work(struct et_task *task)
+{
+#if !defined(NAPI_POLL) && !defined(NAPI2_POLL)
+	et_info_t *et = (et_info_t *)task->context;
+	et_dpc((unsigned long)et);
+#else
+	BUG_ON(1);
+#endif
+	return;
+}
+#endif /* ET_ALL_PASSIVE */
+
+static void
+et_error(et_info_t *et, struct sk_buff *skb, void *rxh)
+{
+	uchar eabuf[32];
+	struct ether_header *eh;
+
+	eh = (struct ether_header *)skb->data;
+	bcm_ether_ntoa((struct ether_addr *)eh->ether_shost, eabuf);
+
+	if (RXH_FLAGS(et->etc, rxh) & htol16(GRXF_OVF)) {
+		ET_ERROR(("et%d: chiprx, dma overflow\n", et->etc->unit));
+		et->etc->rxoflodiscards++;
+	}
+
+	if (RXH_OVERSIZE(et->etc, rxh)) {
+		ET_ERROR(("et%d: rx: over size packet from %s\n", et->etc->unit, eabuf));
+	}
+	if (RXH_CRC(et->etc, rxh)) {
+		ET_ERROR(("et%d: rx: crc error from %s\n", et->etc->unit, eabuf));
+	}
+	if (RXH_OVF(et->etc, rxh)) {
+		ET_ERROR(("et%d: rx: fifo overflow\n", et->etc->unit));
+	}
+	if (RXH_NO(et->etc, rxh)) {
+		ET_ERROR(("et%d: rx: crc error (odd nibbles) from %s\n",
+		          et->etc->unit, eabuf));
+	}
+	if (RXH_RXER(et->etc, rxh)) {
+		ET_ERROR(("et%d: rx: symbol error from %s\n", et->etc->unit, eabuf));
+	}
+}
+
+#ifdef CONFIG_IP_NF_DNSMQ
+typedef int (*dnsmqHitHook)(struct sk_buff *skb);
+extern dnsmqHitHook dnsmq_hit_hook;
+#endif
+
+static inline int32
+et_ctf_forward(et_info_t *et, struct sk_buff *skb)
+{
+#ifdef HNDCTF
+	int ret;
+#endif
+
+#ifdef CONFIG_IP_NF_DNSMQ
+	if(dnsmq_hit_hook&&dnsmq_hit_hook(skb))
+		return (BCME_ERROR);
+#endif
+
+#ifdef HNDCTF
+	/* try cut thru first */
+	if (CTF_ENAB(et->cih) && (ret = ctf_forward(et->cih, skb, skb->dev)) != BCME_ERROR) {
+		if (ret == BCME_EPERM)
+			PKTCFREE(et->osh, skb, FALSE);
+		return (BCME_OK);
+	}
+
+	/* clear skipct flag before sending up */
+	PKTCLRSKIPCT(et->osh, skb);
+#endif /* HNDCTF */
+
+#ifdef CTFPOOL
+	/* allocate and add a new skb to the pkt pool */
+	if (PKTISFAST(et->osh, skb))
+		osl_ctfpool_add(et->osh);
+
+	/* clear fast buf flag before sending up */
+	PKTCLRFAST(et->osh, skb);
+
+	/* re-init the hijacked field */
+	CTFPOOLPTR(et->osh, skb) = NULL;
+#endif /* CTFPOOL */
+
+#ifdef	CTFMAP
+	/* map the unmapped buffer memory before sending up */
+	if (PKTLEN(et->osh, skb) > (CTFMAPSZ - 4))
+		PKTCTFMAP(et->osh, skb);
+	else {
+		PKTCLRCTF(et->osh, skb);
+		CTFMAPPTR(et->osh, skb) = NULL;
+	}
+#endif	/* CTFMAP */
+
+	return (BCME_ERROR);
+}
+
+void BCMFASTPATH
+et_sendup(et_info_t *et, struct sk_buff *skb, int dataoff)
+{
+	etc_info_t *etc;
+	void *rxh;
+
+	etc = et->etc;
+
+	/* packet buffer starts with rxhdr */
+	rxh = skb->data;
+
+	/* strip off rxhdr */
+	__skb_pull(skb, dataoff);
+
+	ET_TRACE(("et%d: et_sendup: %d bytes\n", et->etc->unit, skb->len));
+	ET_LOG("et%d: et_sendup: len %d", et->etc->unit, skb->len);
+
+	etc->rxframe++;
+	etc->rxbyte += skb->len;
+
+	/* eh should now be aligned 2-mod-4 */
+	ASSERT(ISALIGNED(skb->data, 2)); /* ((ulong)skb->data & 3) == 2 */
+
+	/* strip off crc32 */
+	skb_trim(skb, skb->len - ETHER_CRC_LEN);
+
+	/* Update the PKTCCNT and PKTCLEN for unchained sendup cases */
+
+	PKTCSETCNT(skb, 1);
+	PKTCSETLEN(skb, PKTLEN(etc->osh, skb));
+	ET_PRHDR("rx", (struct ether_header *)skb->data, skb->len, etc->unit);
+	ET_PRPKT("rxpkt", skb->data, skb->len, etc->unit);
+
+#if !defined(BCM_GMAC3)
+	{
+		/* get the error flags */
+		uint16 flags;
+		flags = RXH_FLAGS(etc, rxh);
+
+		/* check for reported frame errors */
+		if (flags)
+			goto err;
+	}
+#endif /* ! BCM_GMAC3 */
+
+	skb->dev = et->dev;
+
+#ifdef ETFA
+	if (FA_RX_BCM_HDR((fa_t *)et->etc->fa) || FA_IS_AUX_DEV((fa_t *)et->etc->fa))
+		fa_process_rx(et->etc->fa, skb);
+	else
+		PKTSETFAHIDX(skb, BCM_FA_INVALID_IDX_VAL);
+#endif /* ETFA */
+
+#ifdef PLC
+	if (et->plc.hw && (et_plc_recv(et, skb) == 0))
+		return;
+#endif /* PLC */
+
+#if defined(BCM_GMAC3)
+	/* Forward single pkt directly to wl transmit */
+	if (DEV_FWDER(et->etc)) { /* BCM_GMAC3 */
+		if (fwder_transmit(et->fwdh, skb, 1, skb->dev) != FWDER_SUCCESS) {
+			PKTFRMNATIVE(etc->osh, skb);
+			PKTFREE(etc->osh, skb, FALSE);
+		}
+		return;
+	}
+#endif /* BCM_GMAC3 */
+
+#ifdef HNDCTF
+	/* try cut thru' before sending up */
+	if (et_ctf_forward(et, skb) != BCME_ERROR)
+		return;
+
+	PKTCLRTOBR(etc->osh, skb);
+	if (PKTISFAFREED(skb)) {
+		/* HW FA ate it */
+		PKTCLRFAAUX(skb);
+		PKTCLRFAFREED(skb);
+		PKTFRMNATIVE(etc->osh, skb);
+		PKTFREE(etc->osh, skb, FALSE);
+		return;
+	}
+#endif /* HNDCTF */
+
+	ASSERT(!PKTISCHAINED(skb));
+	ASSERT(PKTCGETFLAGS(skb) == 0);
+
+	/* extract priority from payload and store it out-of-band
+	 * in skb->priority
+	 */
+	if (et->etc->qos)
+		pktsetprio(skb, TRUE);
+
+	skb->protocol = eth_type_trans(skb, skb->dev);
+
+	/* send it up */
+#if defined(NAPI_POLL) || defined(NAPI2_POLL)
+	netif_receive_skb(skb);
+#else /* NAPI_POLL */
+	netif_rx(skb);
+#endif /* NAPI_POLL */
+
+	ET_LOG("et%d: et_sendup ret", et->etc->unit, 0);
+
+	return;
+
+#if !defined(BCM_GMAC3)
+err:
+	et_error(et, skb, rxh);
+	PKTFRMNATIVE(etc->osh, skb);
+	PKTFREE(etc->osh, skb, FALSE);
+
+	return;
+#endif /* ! BCM_GMAC3 */
+}
+
+#ifdef HNDCTF
+void
+et_dump_ctf(et_info_t *et, struct bcmstrbuf *b)
+{
+	ctf_dump(et->cih, b);
+}
+#endif
+
+#ifdef BCMDBG_CTRACE
+void et_dump_ctrace(et_info_t *et, struct bcmstrbuf *b)
+{
+	PKT_CTRACE_DUMP(et->etc->osh, b);
+}
+#endif
+
+#if defined(BCM_GMAC3)
+void et_dump_fwder(et_info_t *et, struct bcmstrbuf *b)
+{
+	fwder_dump(b);
+}
+#endif /* BCM_GMAC3 */
+
+void
+et_dump(et_info_t *et, struct bcmstrbuf *b)
+{
+	bcm_bprintf(b, "et%d: %s %s version %s\n", et->etc->unit,
+		__DATE__, __TIME__, EPI_VERSION_STR);
+
+#ifdef HNDCTF
+#if defined(BCMDBG)
+	ctf_dump(et->cih, b);
+#endif 
+#endif /* HNDCTF */
+
+#if defined(BCM_GMAC3)
+	et_dump_fwder(et, b);
+#endif /* BCM_GMAC3 */
+
+#ifdef BCMDBG
+	et_dumpet(et, b);
+	etc_dump(et->etc, b);
+#endif /* BCMDBG */
+
+#ifdef BCMDBG_CTRACE
+	PKT_CTRACE_DUMP(et->etc->osh, b);
+#endif
+}
+
+#ifdef BCMDBG
+static void
+et_dumpet(et_info_t *et, struct bcmstrbuf *b)
+{
+	bcm_bprintf(b, "et %p dev %p name %s tbusy %d txq[0].qlen %d malloced %d\n",
+		et, et->dev, et->dev->name, (uint)netif_queue_stopped(et->dev), et->txq[0].qlen,
+		MALLOCED(et->osh));
+}
+#endif	/* BCMDBG */
+
+void
+et_link_up(et_info_t *et)
+{
+	ET_ERROR(("et%d: link up (%d%s)\n",
+		et->etc->unit, et->etc->speed, (et->etc->duplex? "FD" : "HD")));
+}
+
+void
+et_link_down(et_info_t *et)
+{
+	ET_ERROR(("et%d: link down\n", et->etc->unit));
+}
+
+/*
+ * 47XX-specific shared mdc/mdio contortion:
+ * Find the et associated with the same chip as <et>
+ * and coreunit matching <coreunit>.
+ */
+void *
+et_phyfind(et_info_t *et, uint coreunit)
+{
+	et_info_t *tmp;
+	uint bus, slot;
+
+	bus = et->pdev->bus->number;
+	slot = PCI_SLOT(et->pdev->devfn);
+
+	/* walk the list et's */
+	for (tmp = et_list; tmp; tmp = tmp->next) {
+		if (et->etc == NULL)
+			continue;
+		if (tmp->pdev == NULL)
+			continue;
+		if (tmp->pdev->bus->number != bus)
+			continue;
+		if (tmp->etc->nicmode)
+			if (PCI_SLOT(tmp->pdev->devfn) != slot)
+				continue;
+		if (tmp->etc->coreunit != coreunit)
+			continue;
+		break;
+	}
+	return (tmp);
+}
+
+/* shared phy read entry point */
+uint16
+et_phyrd(et_info_t *et, uint phyaddr, uint reg)
+{
+	uint16 val;
+
+	ET_LOCK(et);
+	val = et->etc->chops->phyrd(et->etc->ch, phyaddr, reg);
+	ET_UNLOCK(et);
+
+	return (val);
+}
+
+/* shared phy write entry point */
+void
+et_phywr(et_info_t *et, uint phyaddr, uint reg, uint16 val)
+{
+	ET_LOCK(et);
+	et->etc->chops->phywr(et->etc->ch, phyaddr, reg, val);
+	ET_UNLOCK(et);
+}
+
+#ifdef ETFA
+void
+et_fa_lock_init(et_info_t *et)
+{
+	spin_lock_init(&et->fa_lock);
+}
+
+void
+et_fa_lock(et_info_t *et)
+{
+	spin_lock_bh(&et->fa_lock);
+}
+
+void
+et_fa_unlock(et_info_t *et)
+{
+	spin_unlock_bh(&et->fa_lock);
+}
+
+void *
+et_fa_get_fa_dev(et_info_t *et)
+{
+	return et->dev;
+}
+
+bool
+et_fa_dev_on(void *dev)
+{
+	if (dev == NULL)
+		return FALSE;
+
+	return ((struct net_device *)dev)->fa_on;
+}
+
+void
+et_fa_set_dev_on(et_info_t *et)
+{
+	et->dev->fa_on = TRUE;
+}
+
+/* Do nothing */
+static int
+et_fa_default_cb(void *dev, ctf_ipc_t *ipc, bool v6, int cmd)
+{
+	return BCME_OK;
+}
+
+static int
+et_fa_normal_cb(void *dev, ctf_ipc_t *ipc, bool v6, int cmd)
+{
+	int error = BCME_OK;
+	et_info_t *et;
+
+	/* Validate the input params */
+	if (dev == NULL || ipc == NULL)
+		return BCME_ERROR;
+
+	et = ET_INFO((struct net_device *)dev);
+	switch (cmd) {
+		case FA_CB_ADD_NAPT:
+			error = fa_napt_add(et->etc->fa, ipc, v6);
+			break;
+		case FA_CB_DEL_NAPT:
+			error = fa_napt_del(et->etc->fa, ipc, v6);
+			break;
+		case FA_CB_GET_LIVE:
+			fa_napt_live(et->etc->fa, ipc, v6);
+			break;
+		case FA_CB_CONNTRACK:
+			fa_conntrack(et->etc->fa, ipc, v6);
+			break;
+	}
+
+	return error;
+}
+
+void *
+et_fa_fs_create(void)
+{
+#ifdef CONFIG_PROC_FS
+	struct proc_dir_entry *proc_fa = NULL;
+
+	if ((proc_fa = create_proc_entry("fa", 0, NULL)))
+		proc_fa->read_proc = fa_read_proc;
+
+	return proc_fa;
+#else
+	return NULL;
+#endif /* CONFIG_PROC_FS */
+}
+
+void
+et_fa_fs_clean(void)
+{
+#ifdef CONFIG_PROC_FS
+	remove_proc_entry("fa", NULL);
+#endif /* CONFIG_PROC_FS */
+}
+
+#endif /* ETFA */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/et_linux.h b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_linux.h
new file mode 100644
index 0000000000..9e315133c3
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/et_linux.h
@@ -0,0 +1,117 @@
+/*
+ * Linux device driver tunables for
+ * Broadcom BCM47XX 10/100Mbps Ethernet Device Driver
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: et_linux.h 493119 2014-07-25 02:22:51Z $
+ */
+
+#ifndef _et_linux_h_
+#define _et_linux_h_
+
+/* tunables */
+#define	NTXD		512		/* # tx dma ring descriptors (must be ^2) */
+#define	NRXD		512		/* # rx dma ring descriptors (must be ^2) */
+#if defined(CONFIG_RAM_SIZE) && ((CONFIG_RAM_SIZE > 0) && (CONFIG_RAM_SIZE <= 16))
+#define NRXBUFPOST      256             /* try to keep this # rbufs posted to the chip */
+#else
+#ifdef ET_INGRESS_QOS
+#define NRXBUFPOST      511             /* try to keep this # rbufs posted to the chip */
+#else
+#define NRXBUFPOST      320             /* try to keep this # rbufs posted to the chip */
+#endif /* ET_INGRESS_QOS */
+#endif /* CONFIG_RAM_SIZE ... */
+
+#if defined(BCM_GMAC3)
+/*
+ * To ensure that a 2K slab is used,                                  2048
+ * Linux Add-ons: skb_shared_info=264, NET_SKB_PAD=32, align=32        352
+ * BCMEXTRAHDROOM= 32                                                   32
+ * RXBUFSZ = Buffer to hold ethernet frame = 2048 - 352 - 32        = 1664
+ * RXBUFSZ includes space for 30B HWRXOFF + 1514B 802.3 + VLAN|BRCM Tag
+ */
+#define BUFSZ       (1696)
+#define RXBUFSZ     (BUFSZ - BCMEXTRAHDROOM)
+#else /* ! BCM_GMAC3 */
+#define	BUFSZ		2048		/* packet data buffer size */
+#define	RXBUFSZ		(BUFSZ - 256)	/* receive buffer size */
+#endif /* ! BCM_GMAC3 */
+
+#ifndef RXBND
+#define RXBND		48		/* max # rx frames to process in dpc */
+#endif
+
+#if defined(ILSIM) || defined(__arch_um__)
+#undef	NTXD
+#define	NTXD		16
+#undef	NRXD
+#define	NRXD		16
+#undef	NRXBUFPOST
+#define	NRXBUFPOST	2
+#endif
+
+#define	PKTCBND		48		/* See also: IOV_PKTCBND */
+
+/* 80pkts per millisec @900Mbps */
+#define ET_RXLAZY_TIMEOUT   (1000U)  /* microseconds */
+#define ET_RXLAZY_FRAMECNT  (32U)    /* interrupt coalescing over frames */
+
+#if defined(CONFIG_RAM_SIZE) && ((CONFIG_RAM_SIZE > 0) && (CONFIG_RAM_SIZE <= 16))
+#define CTFPOOLSZ	512
+#else
+#ifdef __ARM_ARCH_7A__
+#define CTFPOOLSZ	1024
+#else  /* ! __ARM_ARCH_7A__ */
+#define CTFPOOLSZ	768
+#endif /* ! __ARM_ARCH_7A__ */
+#endif /* CONFIG_RAM_SIZE */
+
+#define	PREFSZ			96
+#ifdef PKTC
+#define ETPREFHDRS(h, sz)
+#else
+#define ETPREFHDRS(h, sz)	OSL_PREF_RANGE_ST((h), (sz))
+#endif
+
+/* dma tunables */
+#ifndef TXMR
+#define TXMR			2	/* number of outstanding reads */
+#endif
+
+#ifndef TXPREFTHRESH
+#define TXPREFTHRESH		8	/* prefetch threshold */
+#endif
+
+#ifndef TXPREFCTL
+#define TXPREFCTL		16	/* max descr allowed in prefetch request */
+#endif
+
+#ifndef TXBURSTLEN
+#define TXBURSTLEN		128	/* burst length for dma reads */
+#endif
+
+#ifndef RXPREFTHRESH
+#define RXPREFTHRESH		1	/* prefetch threshold */
+#endif
+
+#ifndef RXPREFCTL
+#define RXPREFCTL		8	/* max descr allowed in prefetch request */
+#endif
+
+#ifndef RXBURSTLEN
+#define RXBURSTLEN		128	/* burst length for dma writes */
+#endif
+
+#endif	/* _et_linux_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/etc.c b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc.c
new file mode 100644
index 0000000000..c2dfb0407c
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc.c
@@ -0,0 +1,1273 @@
+/*
+ * Common [OS-independent] portion of
+ * Broadcom Home Networking Division 10/100 Mbit/s Ethernet
+ * Device Driver.
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: etc.c 474541 2014-05-01 18:46:52Z $
+ */
+
+#include <et_cfg.h>
+#include <typedefs.h>
+#include <osl.h>
+#include <bcmendian.h>
+#include <proto/ethernet.h>
+#include <proto/vlan.h>
+#include <proto/bcmip.h>
+#include <proto/802.1d.h>
+#include <bcmenetmib.h>
+#include <bcmenetrxh.h>
+#include <bcmenetphy.h>
+#include <et_dbg.h>
+#include <etc.h>
+#include <et_export.h>
+#include <bcmutils.h>
+#include <hndsoc.h>
+#include <hndfwd.h>
+#ifdef ETFA
+#include <etc_fa.h>
+#endif
+
+#define ETC_TXERR_COUNTDOWN 3
+
+#ifdef ETROBO
+#ifndef	_siutils_h_
+typedef const struct si_pub  si_t;
+#endif
+#include <bcmrobo.h>
+#endif /* ETROBO */
+
+uint32 et_msg_level =
+#ifdef BCMDBG
+	1;
+#else
+	0;
+#endif /* BCMDBG */
+
+/* local prototypes */
+static void etc_loopback(etc_info_t *etc, int on);
+static void etc_dumpetc(etc_info_t *etc, struct bcmstrbuf *b);
+static void et_dump_arl_tbl(etc_info_t *etc, uint porv, uint num, struct bcmstrbuf *b);
+static void et_dump_port_status(etc_info_t *etc, uint portnum, struct bcmstrbuf *b);
+int et_get_portinfo(etc_info_t *etc, int port_id, et_sw_port_info_t *portstatus);
+
+/* 802.1d priority to traffic class mapping. queues correspond one-to-one
+ * with traffic classes.
+ */
+uint32 up2tc[NUMPRIO] = {
+	TC_BE,  	/* 0    BE    TC_BE    Best Effort */
+	TC_BK,  	/* 1    BK    TC_BK    Background */
+	TC_BK,  	/* 2    --    TC_BK    Background */
+	TC_BE,  	/* 3    EE    TC_BE    Best Effort */
+	TC_CL,  	/* 4    CL    TC_CL    Controlled Load */
+	TC_CL,  	/* 5    VI    TC_CL    Controlled Load */
+	TC_VO,  	/* 6    VO    TC_VO    Voice */
+	TC_VO   	/* 7    NC    TC_VO    Voice */
+};
+
+uint32 priq_selector[] = {
+	[0x0] = TC_NONE, [0x1] = TC_BK, [0x2] = TC_BE, [0x3] = TC_BE,
+	[0x4] = TC_CL,   [0x5] = TC_CL, [0x6] = TC_CL, [0x7] = TC_CL,
+	[0x8] = TC_VO,   [0x9] = TC_VO, [0xa] = TC_VO, [0xb] = TC_VO,
+	[0xc] = TC_VO,   [0xd] = TC_VO, [0xe] = TC_VO, [0xf] = TC_VO
+};
+
+/* find the chip opsvec for this chip */
+struct chops*
+etc_chipmatch(uint vendor, uint device)
+{
+#if !defined(_CFE_) || defined(CFG_ETC47XX)
+	{
+		extern struct chops bcm47xx_et_chops;
+
+		if (bcm47xx_et_chops.id(vendor, device))
+			return (&bcm47xx_et_chops);
+	}
+#endif
+
+#ifdef CFG_GMAC
+	{
+		extern struct chops bcmgmac_et_chops;
+
+		if (bcmgmac_et_chops.id(vendor, device))
+			return (&bcmgmac_et_chops);
+	}
+#endif /* CFG_GMAC */
+	return (NULL);
+}
+
+void*
+etc_attach(void *et, uint vendor, uint device, uint coreunit, void *osh, void *regsva)
+{
+	etc_info_t *etc;
+	uint unit = coreunit;
+
+	/* get unit from coreunit */
+	etc_unitmap(vendor, device, coreunit, &unit);
+
+	ET_TRACE(("et%d: etc_attach: vendor 0x%x device 0x%x\n", unit, vendor, device));
+
+	/* some code depends on packed structures */
+	ASSERT(sizeof(struct ether_addr) == ETHER_ADDR_LEN);
+	ASSERT(sizeof(struct ether_header) == ETHER_HDR_LEN);
+
+	/* allocate etc_info_t state structure */
+	if ((etc = (etc_info_t*) MALLOC(osh, sizeof(etc_info_t))) == NULL) {
+		ET_ERROR(("et%d: etc_attach: out of memory, malloced %d bytes\n", unit,
+		          MALLOCED(osh)));
+		return (NULL);
+	}
+	bzero((char*)etc, sizeof(etc_info_t));
+
+	etc->et = et;
+	etc->unit = unit;
+	etc->coreunit = coreunit;
+	etc->osh = osh;
+	etc->vendorid = (uint16) vendor;
+	etc->deviceid = (uint16) device;
+	etc->forcespeed = ET_AUTO;
+	etc->linkstate = FALSE;
+
+#ifdef ET_INGRESS_QOS
+	etc->dma_rx_thresh = DMA_RX_THRESH_DEFAULT;
+	etc->dma_rx_policy = DMA_RX_POLICY_NONE;
+#endif /* ET_INGRESS_QOS */
+
+#ifdef PKTC
+	/* initialize default pktc values */
+	etc->pktcbnd = MAX(PKTCBND, RXBND);
+#endif
+	etc_quota(etc);
+
+	/* set chip opsvec */
+	etc->chops = etc_chipmatch(vendor, device);
+	ASSERT(etc->chops);
+
+	/* chip attach */
+	if ((etc->ch = (*etc->chops->attach)(etc, osh, regsva)) == NULL) {
+		ET_ERROR(("et%d: chipattach error\n", unit));
+		goto fail;
+	}
+
+	return ((void*)etc);
+
+fail:
+	etc_detach(etc);
+	return (NULL);
+}
+
+void
+etc_detach(etc_info_t *etc)
+{
+	if (etc == NULL)
+		return;
+
+	/* free chip private state */
+	if (etc->ch) {
+		(*etc->chops->detach)(etc->ch);
+		etc->chops = etc->ch = NULL;
+	}
+
+	MFREE(etc->osh, etc, sizeof(etc_info_t));
+}
+
+void
+etc_reset(etc_info_t *etc)
+{
+	ET_TRACE(("et%d: etc_reset\n", etc->unit));
+
+	etc->reset++;
+
+	/* reset the chip */
+	(*etc->chops->reset)(etc->ch);
+
+	/* free any posted tx packets */
+	(*etc->chops->txreclaim)(etc->ch, TRUE);
+
+#ifdef DMA
+	/* free any posted rx packets */
+	(*etc->chops->rxreclaim)(etc->ch);
+#endif /* DMA */
+}
+
+void
+etc_init(etc_info_t *etc, uint options)
+{
+	ET_TRACE(("et%d: etc_init\n", etc->unit));
+
+	ASSERT(etc->pioactive == NULL);
+#if defined(BCM_GMAC3)
+	if (DEV_NTKIF(etc))
+		ASSERT(!ETHER_ISNULLADDR(&etc->cur_etheraddr));
+#else  /* ! BCM_GMAC3 */
+	ASSERT(!ETHER_ISNULLADDR(&etc->cur_etheraddr));
+#endif /* ! BCM_GMAC3 */
+	ASSERT(!ETHER_ISMULTI(&etc->cur_etheraddr));
+
+	/* init the chip */
+	(*etc->chops->init)(etc->ch, options);
+}
+
+/* mark interface up */
+void
+etc_up(etc_info_t *etc)
+{
+	etc->up = TRUE;
+
+	et_init(etc->et, ET_INIT_FULL | ET_INIT_INTRON);
+}
+
+/* mark interface down */
+uint
+etc_down(etc_info_t *etc, int reset)
+{
+	uint callback;
+
+	callback = 0;
+
+	ET_FLAG_DOWN(etc);
+
+	if (reset)
+		et_reset(etc->et);
+
+	/* suppress link state changes during power management mode changes */
+	if (etc->linkstate) {
+		etc->linkstate = FALSE;
+		if (!etc->pm_modechange)
+			et_link_down(etc->et);
+	}
+
+	return (callback);
+}
+
+#ifdef CONFIG_DUMP_PREV_OOPS_MSG
+extern void dump_previous_oops(void);
+#endif
+
+/* common iovar handler. return 0=ok, -1=error */
+int
+etc_iovar(etc_info_t *etc, uint cmd, uint set, void *arg, int len)
+{
+	int error;
+	uint *vecarg;
+#if defined(ETROBO) && !defined(_CFE_)
+	int i;
+	robo_info_t *robo = etc->robo;
+#endif /* ETROBO && _CFE_ */
+
+	error = 0;
+	vecarg = (uint *)arg;
+	ET_TRACE(("et%d: etc_iovar: cmd 0x%x\n", etc->unit, cmd));
+
+	switch (cmd) {
+#if defined(ETROBO) && !defined(_CFE_)
+		case IOV_ET_POWER_SAVE_MODE:
+			if (set)
+				error = robo_power_save_mode_set(robo, vecarg[1], vecarg[0]);
+			else {
+				/* get power save mode of all the phys */
+				if (vecarg[0] == MAX_NO_PHYS) {
+					for (i = 0; i < MAX_NO_PHYS; i++)
+						vecarg[i] = robo_power_save_mode_get(robo, i);
+					break;
+				}
+
+				/* get power save mode of the phy */
+				error = robo_power_save_mode_get(robo, vecarg[0]);
+				if (error != -1) {
+					vecarg[1] = error;
+					error = 0;
+				}
+			}
+			break;
+
+		case IOV_ET_ROBO_DEVID:
+			error = -1;
+
+			if (robo != NULL) {
+				*vecarg = robo->devid;
+				error = 0;
+			}
+			break;
+#endif /* ETROBO && !_CFE_ */
+#ifdef BCMDBG
+		case IOV_ET_CLEAR_DUMP:
+			if (set) {
+				uint size = ((char *)(&etc->rxbadlen) - (char *)(&etc->txframe));
+
+				bzero((char *)&etc->txframe, size + sizeof(etc->rxbadlen));
+				(*etc->chops->dumpmib)(etc->ch, NULL, TRUE);
+				error = 0;
+			}
+			break;
+#endif /* BCMDBG */
+
+		case IOV_PKTC:
+			if (set)
+				etc->pktc = *vecarg;
+			else
+				*vecarg = (uint)etc->pktc;
+			etc_quota(etc);
+			break;
+
+		case IOV_PKTCBND:
+			if (set)
+				etc->pktcbnd = MAX(*vecarg, 32);
+			else
+				*vecarg = etc->pktcbnd;
+			etc_quota(etc);
+			break;
+#ifdef ET_INGRESS_QOS
+		case IOV_DMA_RX_THRESH:
+			if (set)
+				/* Don't let the thresh to claim all descriptors */
+				etc->dma_rx_thresh = MIN(*vecarg, NRXD-12);
+			else
+				*vecarg = etc->dma_rx_thresh;
+			break;
+
+		case IOV_DMA_RX_POLICY:
+			if (set) {
+				if (*vecarg > DMA_RX_POLICY_LAST) {
+					error = -1;
+					break;
+				}
+#ifdef ETROBO
+				ASSERT(robo);
+
+				if (*vecarg) {
+					/* Disable flow control for IMP port */
+					error = bcm_robo_flow_control(robo, FALSE);
+				}
+				else {
+					/* Enable flow control for IMP port */
+					error = bcm_robo_flow_control(robo, TRUE);
+				}
+
+				if (error != 0)
+					break;
+#else
+				/* TBD: flow control on non-ROBO switches */
+				error = -1;
+				break;
+#endif /* ETROBO */
+				etc->dma_rx_policy = *vecarg;
+			}
+			else
+				*vecarg = etc->dma_rx_policy;
+			break;
+#endif /* ET_INGRESS_QOS */
+
+		case IOV_RXQUOTA:
+			if (set)
+				etc->quota = *vecarg;
+			else
+				*vecarg = etc->quota;
+			etc_quota(etc);
+			break;
+
+		case IOV_RXLAZYTO: /* rxlazy timeout */
+			if (set)
+				etc->rxlazy_timeout = *vecarg;
+			else
+				*vecarg = etc->rxlazy_timeout;
+			break;
+
+		case IOV_RXLAZYFC: /* rxlazy framecnt */
+			if (set)
+				etc->rxlazy_framecnt = *vecarg;
+			else
+				*vecarg = etc->rxlazy_framecnt;
+			break;
+
+		case IOV_COUNTERS:
+			{
+				struct bcmstrbuf b;
+				bcm_binit(&b, (char*)arg, len);
+				etc_dumpetc(etc, &b);
+			}
+			break;
+
+#ifdef CONFIG_DUMP_PREV_OOPS_MSG
+		case IOV_DUMP_OOPS:
+			dump_previous_oops();
+			break;
+#endif
+
+#ifdef HNDCTF
+		case IOV_DUMP_CTF:
+			{
+				struct bcmstrbuf b;
+				bcm_binit(&b, (char*)arg, len);
+				et_dump_ctf(etc->et, &b);
+			}
+			break;
+#endif /* HNDCTF */
+
+#ifdef BCMDBG_CTRACE
+		case IOV_DUMP_CTRACE:
+			{
+				struct bcmstrbuf b;
+				bcm_binit(&b, (char*)arg, len);
+				et_dump_ctrace(etc->et, &b);
+			}
+			break;
+#endif /* BCMDBG_CTRACE */
+
+#ifdef BCMDBG
+		case IOV_MACRD:
+			{
+				uint val;
+				val = (*etc->chops->macrd)(etc->ch, vecarg[0]);
+				ET_TRACE(("etc_ioctl: ETCMACRD reg_off 0x%x => 0x%x\n",
+				          vecarg[0], val));
+				vecarg[0] = val;
+			}
+			break;
+
+		case IOV_MACWR:
+			{
+				ET_TRACE(("etc_ioctl: ETCMACWR reg_off 0x%x <= 0x%x\n",
+				          vecarg[0], vecarg[1]));
+				(*etc->chops->macwr)(etc->ch, vecarg[0], vecarg[1]);
+			}
+			break;
+#endif /* BCMDBG */
+
+		case IOV_DUMP:
+		if (et_msg_level & 0x10000)
+			bcmdumplog((char *)arg, len);
+#ifdef BCMDBG
+		else
+		{
+			struct bcmstrbuf b;
+			bcm_binit(&b, (char*)arg, len);
+			et_dump(etc->et, &b);
+		}
+#endif /* BCMDBG */
+		break;
+
+#ifdef ETFA
+		case IOV_FA_DUMP:
+			{
+				struct bcmstrbuf b;
+				bcm_binit(&b, (char*)arg, len);
+				fa_dump(etc->fa, &b, FALSE);
+			}
+			break;
+#endif /* ETFA */
+
+#ifdef BCM_GMAC3
+		case IOV_DUMP_FWDER:
+			{
+				struct bcmstrbuf b;
+				bcm_binit(&b, (char*)arg, len);
+				et_dump_fwder(etc->et, &b);
+			}
+			break;
+#endif /* BCM_GMAC3 */
+
+		case IOV_PORTSTATS:
+			{
+				struct bcmstrbuf b;
+				bcm_binit(&b, (char*)arg, IOCBUFSZ);
+				et_dump_port_status(etc, *vecarg, &b);
+			}
+			break;
+
+		case IOV_SW_MCTBL:
+			{
+				struct bcmstrbuf b;
+				uint num, pov;
+				bcm_binit(&b, (char*)arg, IOCBUFSZ);
+				pov = (*vecarg & 0x1ffff) >> 16;
+				num = *vecarg & 0xffff;
+				et_dump_arl_tbl(etc, pov, num, &b);
+			}
+			break;
+
+		case IOV_CAP:
+			{
+				struct bcmstrbuf b;
+				bcm_binit(&b, (char*)arg, len);
+#ifdef ETFA
+				/* Do we need to consider the HW cap and nvram ctf_fa_mode? */
+				bcm_bprintf(&b, "fa ");
+#endif
+#ifdef BCM_GMAC3
+				if (!getvar(NULL, "gmac3_off"))
+					bcm_bprintf(&b, "gmac3 ");
+#endif
+			}
+			break;
+
+		default:
+			error = -1;
+	}
+
+	return (error);
+}
+
+/* common ioctl handler.  return: 0=ok, -1=error */
+int
+etc_ioctl(etc_info_t *etc, int cmd, void *arg)
+{
+	int error;
+	int val;
+	int *vec = (int*)arg;
+
+	error = 0;
+
+	val = arg ? *(int*)arg : 0;
+
+	ET_TRACE(("et%d: etc_ioctl: cmd 0x%x\n", etc->unit, cmd));
+
+	switch (cmd) {
+	case ETCUP:
+		et_up(etc->et);
+		break;
+
+	case ETCDOWN:
+		et_down(etc->et, TRUE);
+		break;
+
+	case ETCLOOP:
+		etc_loopback(etc, val);
+		break;
+
+	case ETCDUMP:
+		if (et_msg_level & 0x10000)
+			bcmdumplog((char *)arg, IOCBUFSZ);
+#ifdef BCMDBG
+		else
+		{
+			struct bcmstrbuf b;
+			bcm_binit(&b, (char*)arg, IOCBUFSZ);
+			et_dump(etc->et, &b);
+		}
+#endif /* BCMDBG */
+		break;
+
+	case ETCSETMSGLEVEL:
+		et_msg_level = val;
+		break;
+
+	case ETCPROMISC:
+		etc_promisc(etc, val);
+		break;
+
+	case ETCQOS:
+		etc_qos(etc, val);
+		break;
+
+	case ETCSPEED:
+		if (etc->phyaddr == EPHY_NOREG) {
+			/* Don't configure the MII interface speed through ioctl */
+			goto err;
+		}
+		if (val == ET_1000FULL) {
+			etc->speed = 1000;
+			etc->duplex = 1;
+		} else if (val == ET_1000HALF) {
+			etc->speed = 1000;
+			etc->duplex = 0;
+		} else if (val == ET_100FULL) {
+			etc->speed = 100;
+			etc->duplex = 1;
+		} else if (val == ET_100HALF) {
+			etc->speed = 100;
+			etc->duplex = 0;
+		} else if (val == ET_10FULL) {
+			etc->speed = 10;
+			etc->duplex = 1;
+		} else if (val == ET_10HALF) {
+			etc->speed = 10;
+			etc->duplex = 0;
+		} else if (val == ET_AUTO)
+			;
+		else
+			goto err;
+
+		etc->forcespeed = val;
+
+		/* explicitly reset the phy */
+		(*etc->chops->phyreset)(etc->ch, etc->phyaddr);
+
+		/* request restart autonegotiation if we're reverting to adv mode */
+		if (etc->forcespeed == ET_AUTO) {
+			etc->advertise = (ADV_100FULL | ADV_100HALF |
+			                  ADV_10FULL | ADV_10HALF);
+			etc->advertise2 = ADV_1000FULL;
+			etc->needautoneg = TRUE;
+		} else {
+			etc->advertise = etc->advertise2 = 0;
+			etc->needautoneg = FALSE;
+		}
+
+		et_init(etc->et, ET_INIT_INTRON);
+		break;
+
+	case ETCPHYRD:
+		if (vec) {
+			vec[1] = (*etc->chops->phyrd)(etc->ch, etc->phyaddr, vec[0]);
+			ET_TRACE(("etc_ioctl: ETCPHYRD of reg 0x%x => 0x%x\n", vec[0], vec[1]));
+		}
+		break;
+
+	case ETCPHYRD2:
+		if (vec) {
+			uint phyaddr, reg;
+			phyaddr = vec[0] >> 16;
+			if (phyaddr < MAXEPHY) {
+				reg = vec[0] & 0xffff;
+				vec[1] = (*etc->chops->phyrd)(etc->ch, phyaddr, reg);
+				ET_TRACE(("etc_ioctl: ETCPHYRD2 of phy 0x%x, reg 0x%x => 0x%x\n",
+				          phyaddr, reg, vec[1]));
+			}
+		}
+		break;
+
+	case ETCPHYWR:
+		if (vec) {
+			ET_TRACE(("etc_ioctl: ETCPHYWR to reg 0x%x <= 0x%x\n", vec[0], vec[1]));
+			(*etc->chops->phywr)(etc->ch, etc->phyaddr, vec[0], (uint16)vec[1]);
+		}
+		break;
+
+	case ETCPHYWR2:
+		if (vec) {
+			uint phyaddr, reg;
+			phyaddr = vec[0] >> 16;
+			if (phyaddr < MAXEPHY) {
+				reg = vec[0] & 0xffff;
+				(*etc->chops->phywr)(etc->ch, phyaddr, reg, (uint16)vec[1]);
+				ET_TRACE(("etc_ioctl: ETCPHYWR2 to phy 0x%x, reg 0x%x <= 0x%x\n",
+				          phyaddr, reg, vec[1]));
+			}
+		}
+		break;
+
+#ifdef ETROBO
+	case ETCROBORD:
+		if (etc->robo && vec) {
+			uint page, reg;
+			uint64 val;
+			int len = 2;
+			robo_info_t *robo = (robo_info_t *)etc->robo;
+
+			page = vec[0] >> 16;
+			reg = vec[0] & 0xffff;
+			if ((vec[1] >= 1) && (vec[1] <= 8))
+				len = vec[1];
+			/* For SPI mode, the length can only be 1, 2, and 4 bytes */
+			if ((len > 4) && (!strcmp(robo->ops->desc, "SPI (GPIO)"))) {
+				vec[1] = -1;
+				break;
+			}
+			val = 0;
+			robo->ops->read_reg(etc->robo, page, reg, &val, len);
+			*((unsigned long long *)&vec[2]) = val;
+			ET_TRACE(("etc_ioctl: ETCROBORD of page 0x%x, reg 0x%x  => 0x%016llX\n",
+			          page, reg, val));
+		}
+		break;
+
+	case ETCROBOWR:
+		if (etc->robo && vec) {
+			uint page, reg;
+			uint64 val;
+			robo_info_t *robo = (robo_info_t *)etc->robo;
+			int len = 2;
+			page = vec[0] >> 16;
+			reg = vec[0] & 0xffff;
+			if ((vec[1] >= 1) && (vec[1] <= 8))
+				len = vec[1];
+			/* For SPI mode, the length can only be 1, 2, and 4 bytes */
+			if ((len > 4) && (!strcmp(robo->ops->desc, "SPI (GPIO)"))) {
+				vec[1] = -1;
+				break;
+			}
+			val = *((unsigned long long *)&vec[2]);
+			robo->ops->write_reg(etc->robo, page, vec[0], &val, len);
+			ET_TRACE(("etc_ioctl: ETCROBOWR to page 0x%x, reg 0x%x <= 0x%016llX\n",
+			          page, reg, val));
+		}
+		break;
+#endif /* ETROBO */
+
+	default:
+	err:
+		error = -1;
+	}
+
+	return (error);
+}
+
+/* called once per second */
+void
+etc_watchdog(etc_info_t *etc)
+{
+	uint16 status;
+	uint16 lpa;
+#if defined(ETROBO)
+	robo_info_t *robo = (robo_info_t *)etc->robo;
+#endif
+#if defined(ETROBO) && !defined(_CFE_)
+	static uint32 sleep_timer = PWRSAVE_SLEEP_TIME, wake_timer = 0;
+#endif /* ETROBO && !_CFE_ */
+
+	etc->now++;
+
+#if defined(ETROBO)
+	/* BCM53125 EEE IOP WAR for some other vendor's wrong EEE implementation. */
+	if (robo)
+		robo_watchdog(robo);
+#endif
+
+#if defined(ETROBO) && !defined(_CFE_)
+	/* Every PWRSAVE_WAKE_TIME sec the phys that are in manual mode
+	 * is taken out of that mode and link status is checked after
+	 * PWRSAVE_SLEEP_TIME sec to see if any of the links is up
+	 * to take that port is taken out of the manual power save mode
+	 */
+	if (robo) {
+		if (ROBO_IS_PWRSAVE_MANUAL(robo)) {
+			if (etc->now == sleep_timer) {
+				robo_power_save_toggle(robo, FALSE);
+				wake_timer = sleep_timer + robo->pwrsave_wake_time;
+			} else if (etc->now == wake_timer) {
+				robo_power_save_toggle(robo, TRUE);
+				sleep_timer = wake_timer + robo->pwrsave_sleep_time;
+			}
+			else if (etc->now > sleep_timer && etc->now > wake_timer) {
+				/* Power save may be actived after startup */
+				etc->now = sleep_timer - 1;
+			}
+		}
+
+		/* Apply the auto configuration from the nvram variable in the beginning */
+		if ((etc->now == PWRSAVE_WAKE_TIME) && ROBO_IS_PWRSAVE_AUTO(robo)) {
+			robo_power_save_mode_update(robo);
+		}
+	}
+#endif /* ETROBO && !_CFE_ */
+
+	/* no local phy registers */
+	if (etc->phyaddr == EPHY_NOREG) {
+		etc->linkstate = TRUE;
+		etc->duplex = 1;
+		/* keep emac txcontrol duplex bit consistent with current phy duplex */
+		(*etc->chops->duplexupd)(etc->ch);
+		return;
+	}
+
+	status = (*etc->chops->phyrd)(etc->ch, etc->phyaddr, 1);
+	/* check for bad mdio read */
+	if (status == 0xffff) {
+		ET_ERROR(("et%d: etc_watchdog: bad mdio read: phyaddr %d mdcport %d\n",
+			etc->unit, etc->phyaddr, etc->mdcport));
+		return;
+	}
+
+	if (etc->forcespeed == ET_AUTO) {
+		uint16 adv, adv2 = 0, status2 = 0, estatus;
+
+		adv = (*etc->chops->phyrd)(etc->ch, etc->phyaddr, 4);
+		lpa = (*etc->chops->phyrd)(etc->ch, etc->phyaddr, 5);
+
+		/* read extended status register. if we are 1000BASE-T
+		 * capable then get our advertised capabilities and the
+		 * link partner capabilities from 1000BASE-T control and
+		 * status registers.
+		 */
+		estatus = (*etc->chops->phyrd)(etc->ch, etc->phyaddr, 15);
+		if ((estatus != 0xffff) && (estatus & EST_1000TFULL)) {
+			/* read 1000BASE-T control and status registers */
+			adv2 = (*etc->chops->phyrd)(etc->ch, etc->phyaddr, 9);
+			status2 = (*etc->chops->phyrd)(etc->ch, etc->phyaddr, 10);
+		}
+
+		/* update current speed and duplex */
+		if ((adv2 & ADV_1000FULL) && (status2 & LPA_1000FULL)) {
+			etc->speed = 1000;
+			etc->duplex = 1;
+		} else if ((adv2 & ADV_1000HALF) && (status2 & LPA_1000HALF)) {
+			etc->speed = 1000;
+			etc->duplex = 0;
+		} else if ((adv & ADV_100FULL) && (lpa & LPA_100FULL)) {
+			etc->speed = 100;
+			etc->duplex = 1;
+		} else if ((adv & ADV_100HALF) && (lpa & LPA_100HALF)) {
+			etc->speed = 100;
+			etc->duplex = 0;
+		} else if ((adv & ADV_10FULL) && (lpa & LPA_10FULL)) {
+			etc->speed = 10;
+			etc->duplex = 1;
+		} else {
+			etc->speed = 10;
+			etc->duplex = 0;
+		}
+	}
+
+	/* monitor link state */
+	if (!etc->linkstate && (status & STAT_LINK)) {
+		etc->linkstate = TRUE;
+		if (etc->pm_modechange)
+			etc->pm_modechange = FALSE;
+		else
+			et_link_up(etc->et);
+	} else if (etc->linkstate && !(status & STAT_LINK)) {
+		etc->linkstate = FALSE;
+		if (!etc->pm_modechange)
+			et_link_down(etc->et);
+	}
+
+	/* keep emac txcontrol duplex bit consistent with current phy duplex */
+	(*etc->chops->duplexupd)(etc->ch);
+
+	/* check for remote fault error */
+	if (status & STAT_REMFAULT) {
+		ET_ERROR(("et%d: remote fault\n", etc->unit));
+	}
+
+	/* check for jabber error */
+	if (status & STAT_JAB) {
+		ET_ERROR(("et%d: jabber\n", etc->unit));
+	}
+
+	/*
+	 * Read chip mib counters occationally before the 16bit ones can wrap.
+	 * We don't use the high-rate mib counters.
+	 */
+	if ((etc->now % 30) == 0)
+		(*etc->chops->statsupd)(etc->ch);
+}
+
+static void
+etc_loopback(etc_info_t *etc, int on)
+{
+	ET_TRACE(("et%d: etc_loopback: %d\n", etc->unit, on));
+
+	etc->loopbk = (bool) on;
+	et_init(etc->et, ET_INIT_INTRON);
+}
+
+void
+etc_promisc(etc_info_t *etc, uint on)
+{
+	ET_TRACE(("et%d: etc_promisc: %d\n", etc->unit, on));
+
+	etc->promisc = (bool) on;
+	et_init(etc->et, ET_INIT_INTRON);
+}
+
+void
+etc_qos(etc_info_t *etc, uint on)
+{
+	ET_TRACE(("et%d: etc_qos: %d\n", etc->unit, on));
+
+	etc->qos = (bool) on;
+	et_init(etc->et, ET_INIT_INTRON);
+}
+
+void
+etc_quota(etc_info_t *etc)
+{
+	int quota = ETCQUOTA_MAX;
+
+#ifdef PKTC
+	quota = (etc->pktc) ? etc->pktcbnd : RXBND;
+#endif
+
+	/* Cap to ETCQUOTA_MAX */
+	etc->quota = (quota > ETCQUOTA_MAX) ? ETCQUOTA_MAX : quota;
+}
+
+void
+etc_rxlazy(etc_info_t *etc, uint microsecs, uint framecnt)
+{
+	ASSERT(framecnt >= 1U);
+	ASSERT(etc->bp_ticks_usec != 0U);
+
+	etc->rxlazy_timeout = microsecs * etc->bp_ticks_usec;
+	etc->rxlazy_framecnt = framecnt;
+}
+
+/* WAR: BCM53115 switch is not retaining the tag while forwarding
+ * the vlan/priority tagged frames even when tag status preserve
+ * is enabled. This problem can be only worked around by doing
+ * double tagging for priority tagged frames. This will trick the
+ * switch in to just removing the outer tag on the egress. Inner
+ * tag remains which contains the prio.
+ */
+#ifdef ETROBO
+void *
+etc_bcm53115_war(etc_info_t *etc, void *p)
+{
+	struct ethervlan_header *evh;
+	uint16 vlan_tag;
+	int vlan_prio;
+	uint8 *data = PKTDATA(etc->osh, p);
+	uint8 *ip_body = data + sizeof(struct ethervlan_header);
+
+	evh = (struct ethervlan_header *)data;
+	/* No additional TAG added if IPTOS has priority != 0 */
+	if ((evh->vlan_type != hton16(ETHER_TYPE_8021Q)) ||
+	    (IP_TOS46(ip_body) & IPV4_TOS_PREC_MASK))
+		return (p);
+
+	vlan_tag = evh->vlan_tag;
+	vlan_prio = vlan_tag & hton16(VLAN_PRI_MASK << VLAN_PRI_SHIFT);
+
+	/* No need to do anything for priority 0 */
+	if (vlan_prio == 0)
+		return (p);
+
+	/* If the packet is shared or there is not enough headroom
+	 * then allocate new header buffer and link the original
+	 * buffer to it.
+	 */
+	if ((PKTHEADROOM(etc->osh, p) < VLAN_TAG_LEN) || PKTSHARED(p)) {
+		void *pkt;
+		uint16 ether_type;
+
+		if ((pkt = PKTGET(etc->osh, VLAN_TAG_LEN +
+		                  ETHERVLAN_HDR_LEN, TRUE)) == NULL) {
+			ET_ERROR(("et%d: PKTGET of size %d failed during expand head\n",
+			          etc->unit, VLAN_TAG_LEN + ETHERVLAN_HDR_LEN));
+			return (NULL);
+		}
+
+		/* Assign priority of original frame */
+		PKTSETPRIO(pkt, ntoh16(vlan_prio) >> VLAN_PRI_SHIFT);
+
+		ether_type = evh->ether_type;
+
+		/* Copy the vlan header to the first buffer */
+		memcpy(PKTDATA(etc->osh, pkt), data, ETHERVLAN_HDR_LEN);
+		PKTPULL(etc->osh, p, ETHERVLAN_HDR_LEN);
+
+		/* Align the pointer to initialize the inner vlan tag and type
+		 * fields.
+		 */
+		evh = (struct ethervlan_header *)(PKTDATA(etc->osh, pkt) + VLAN_TAG_LEN);
+		evh->vlan_tag = vlan_tag;
+		evh->ether_type = ether_type;
+
+		/* Chain the original buffer to new header buffer */
+		PKTSETNEXT(etc->osh, pkt, p);
+
+		p = pkt;
+	} else {
+		data = PKTPUSH(etc->osh, p, VLAN_TAG_LEN);
+		ETHERVLAN_MOVE_HDR(data, data + VLAN_TAG_LEN);
+		evh = (struct ethervlan_header *)(data + VLAN_TAG_LEN);
+	}
+
+	evh->vlan_type = hton16(ETHER_TYPE_8021Q);
+
+	/* Clear the vlan id in the inner tag */
+	evh->vlan_tag &= ~(hton16(VLAN_VID_MASK));
+
+	return (p);
+}
+#endif /* ETROBO */
+
+#ifdef BCMDBG
+void
+etc_dump(etc_info_t *etc, struct bcmstrbuf *b)
+{
+	etc_dumpetc(etc, b);
+	(*etc->chops->dump)(etc->ch, b);
+}
+#endif /* BCMDBG */
+
+static void
+etc_dumpetc(etc_info_t *etc, struct bcmstrbuf *b)
+{
+	char perm[32], cur[32];
+	uint i;
+
+	bcm_bprintf(b, "etc 0x%x et 0x%x unit %d msglevel %d speed/duplex %d%s\n",
+		(ulong)etc, (ulong)etc->et, etc->unit, et_msg_level,
+		etc->speed, (etc->duplex ? "full": "half"));
+	bcm_bprintf(b, "up %d promisc %d loopbk %d forcespeed %d advertise 0x%x "
+	               "advertise2 0x%x needautoneg %d\n",
+	               etc->up, etc->promisc, etc->loopbk, etc->forcespeed,
+	               etc->advertise, etc->advertise2, etc->needautoneg);
+	bcm_bprintf(b, "piomode %d pioactive 0x%x nmulticast %d allmulti %d qos %d\n",
+		etc->piomode, (ulong)etc->pioactive, etc->nmulticast, etc->allmulti, etc->qos);
+	bcm_bprintf(b, "vendor 0x%x device 0x%x rev %d coreunit %d phyaddr %d mdcport %d\n",
+		etc->vendorid, etc->deviceid, etc->chiprev,
+		etc->coreunit, etc->phyaddr, etc->mdcport);
+
+	bcm_bprintf(b, "perm_etheraddr %s cur_etheraddr %s\n",
+		bcm_ether_ntoa(&etc->perm_etheraddr, perm),
+		bcm_ether_ntoa(&etc->cur_etheraddr, cur));
+
+	if (etc->nmulticast) {
+		bcm_bprintf(b, "multicast: ");
+		for (i = 0; i < etc->nmulticast; i++)
+			bcm_bprintf(b, "%s ", bcm_ether_ntoa(&etc->multicast[i], cur));
+		bcm_bprintf(b, "\n");
+	}
+
+	bcm_bprintf(b, "linkstate %d\n", etc->linkstate);
+	bcm_bprintf(b, "\n");
+
+	/* refresh stat counters */
+	(*etc->chops->statsupd)(etc->ch);
+
+	/* summary stat counter line */
+	/* use sw frame and byte counters -- hw mib counters wrap too quickly */
+	bcm_bprintf(b, "txframe %d txbyte %d txerror %d rxframe %d rxbyte %d rxerror %d\n",
+		etc->txframe, etc->txbyte, etc->txerror,
+		etc->rxframe, etc->rxbyte, etc->rxerror);
+
+	/* transmit & receive stat counters */
+	/* hardware mib pkt and octet counters wrap too quickly to be useful */
+	(*etc->chops->dumpmib)(etc->ch, b, FALSE);
+
+	bcm_bprintf(b, "txnobuf %d reset %d dmade %d dmada %d dmape %d\n",
+	               etc->txnobuf, etc->reset, etc->dmade, etc->dmada, etc->dmape);
+
+	/* hardware mib pkt and octet counters wrap too quickly to be useful */
+	bcm_bprintf(b, "rxnobuf %d rxdmauflo %d rxoflo %d rxbadlen %d "
+	               "rxgiants %d rxoflodiscards %d\n",
+	               etc->rxnobuf, etc->rxdmauflo, etc->rxoflo, etc->rxbadlen,
+	               etc->rxgiants, etc->rxoflodiscards);
+
+	bcm_bprintf(b, "chained %d unchained %d maxchainsz %d currchainsz %d\n",
+	               etc->chained, etc->unchained, etc->maxchainsz, etc->currchainsz);
+
+#if defined(BCMDBG)
+#if defined(PKTC)
+	bcm_bprintf(b, "chain sz histo:");
+	for (i = 0; i < PKTCBND && etc->chained; i++) {
+		bcm_bprintf(b, "  %d(%d%%)", etc->chainsz[i],
+		            (etc->chainsz[i] * 100) / etc->chained);
+		if (((i % 8) == 7) && (i != PKTCBND - 1))
+			bcm_bprintf(b, "\n              :");
+	}
+#endif /* PKTC */
+
+	bcm_bprintf(b, "\nrx processed :%d", etc->rxprocessed);
+
+	for (i = 0; i < ETCQUOTA_MAX; i++) {
+		if (etc->quota_stats[i]) {
+			bcm_bprintf(b, "  %d %d\n", i, etc->quota_stats[i]);
+		}
+	}
+	bzero(etc->quota_stats, ETCQUOTA_MAX * sizeof(int));
+#endif /* BCMDBG */
+
+	bcm_bprintf(b, "\n");
+}
+
+uint
+etc_totlen(etc_info_t *etc, void *p)
+{
+	uint total;
+
+	total = 0;
+	for (; p; p = PKTNEXT(etc->osh, p))
+		total += PKTLEN(etc->osh, p);
+	return (total);
+}
+
+static void
+et_dump_arl_entry(uint porv, uint num,  uint64 reg_val64, uint32 reg_val32, struct bcmstrbuf *b)
+{
+	uint32  prtn;
+	uint64  vidn;
+
+	vidn = (reg_val64 & VID_MASK) >> 48;
+	prtn = (reg_val32 & 0x1ff);
+
+	if ((prtn <= 5) && ((num == 0xff) || (!porv && (vidn == num)) || (porv && (prtn == num)))) {
+		bcm_bprintf(b, "%012llx       ", (reg_val64 & MACADDR_MASK));
+		bcm_bprintf(b, "0x%0llx", vidn);
+		bcm_bprintf(b, "%12d   ", prtn);
+		bcm_bprintf(b, "0x%08x\n", reg_val32);
+	}
+}
+
+static void
+et_dump_arl_tbl(etc_info_t *etc, uint porv, uint num, struct bcmstrbuf *b)
+{
+	uint8	val8 = 0x80;
+	uint32  val32;
+	uint64  val64;
+	robo_info_t *robo = (robo_info_t *)etc->robo;
+
+	/* write 1 to bit 7 Page 5, address 0x50 */
+	robo->ops->write_reg(etc->robo, 5, 0x50, &val8, sizeof(val8));
+
+	OSL_DELAY(150);
+
+	bcm_bprintf(b, "MAC ADDRESS        VID        Port        Flags\n");
+	bcm_bprintf(b, "-----------        ---        ----        -----\n");
+
+	robo->ops->read_reg(etc->robo, 5, 0x50, &val8, sizeof(uint8));
+	val8 &= 0x81;	/* read bit 0 & 7  -- if "1", ARL search is started */
+					/* and valid entry is found */
+
+	while (val8) {
+		/* MAC-VID  1 */
+		robo->ops->read_reg(etc->robo, 5, 0x60, &val64, sizeof(uint64));
+		/* reading 0x68 should clears bit 0 of 0x50 & search to cont.. */
+		robo->ops->read_reg(etc->robo, 5, 0x68, &val32, sizeof(uint32));
+
+		if (val64 && (val8 & 0x01))
+			et_dump_arl_entry(porv, num, val64, val32, b);
+
+		/* MAC-VID  2 */
+		robo->ops->read_reg(etc->robo, 5, 0x70, &val64, sizeof(uint64));
+		robo->ops->read_reg(etc->robo, 5, 0x78, &val32, sizeof(uint32));
+		if (val64 && (val8 & 0x01))
+			et_dump_arl_entry(porv, num, val64, val32, b);
+
+		robo->ops->read_reg(etc->robo, 5, 0x50, &val8, sizeof(uint8));
+		if ((val8 & 0x80) == 0) {
+			break;
+		}
+
+		if ((val8 & 0x01) == 0) {
+			robo->ops->read_reg(etc->robo, 5, 0x50, &val8, sizeof(uint8));
+		}
+
+		val8 = (val8 & 0x81);
+	}
+}
+
+static void
+et_dump_port_status(etc_info_t *etc, uint portn, struct bcmstrbuf *b)
+{
+	uint16 i, val;
+	uint pstart, pend;
+	et_sw_port_info_t portinfo;
+	char *phy_speed[4] = {"Unknown", "100", "1000", "10"};
+
+	memset(&portinfo, 0, sizeof(et_sw_port_info_t));
+
+	if (et_get_portinfo(etc, portn, &portinfo) != 0)
+		return;
+
+	if(portn == 0xff)   {   /* all ports */
+		pstart = 0;
+		pend = 4;
+	} else if (portn < 5) {
+		pstart = pend = portn;
+	} else {
+		/* invalid port range */
+		return;
+	}
+
+	/* pretty print */
+	bcm_bprintf(b, "Port    Link    Speed(Mbps)    Duplex\n");
+	bcm_bprintf(b, "----    ----    -----------    ------\n");
+
+	for (i = pstart; i <= pend; i++) {
+		bcm_bprintf(b, "\n%4d    ", i);
+		if (portinfo.link_state & (1 << i)) {
+			bcm_bprintf(b, "  Up");
+
+			val = ((portinfo.speed >> (i * 2))) & 0x0003;
+			bcm_bprintf(b, "%15s      ", phy_speed[val]);
+
+			bcm_bprintf(b, portinfo.duplex & (1 << i) ? "Full" : "Half");
+
+		} else {
+			bcm_bprintf(b, "Down");
+		}
+	}
+}
+
+int
+et_get_portinfo(etc_info_t *etc, int port_id, et_sw_port_info_t *portstatus)
+{
+	uint page = 1, reg;
+	uint16 lnk, spd, dplx;
+	robo_info_t *robo = (robo_info_t *)etc->robo;
+
+	if ((etc == NULL) || (portstatus == NULL))
+		return -1;	/* fail */
+
+	reg = 0;
+	robo->ops->read_reg(etc->robo, page, reg, &lnk, 2);
+
+	reg = 4;
+	robo->ops->read_reg(etc->robo, page, reg, &spd, 2);
+
+	reg = 8;
+	robo->ops->read_reg(etc->robo, page, reg, &dplx, 2);
+
+	portstatus->speed = spd;
+	portstatus->link_state = lnk;
+	portstatus->duplex = dplx;
+
+	return 0;
+}
+
+#ifdef BCMDBG
+void
+etc_prhdr(char *msg, struct ether_header *eh, uint len, int unit)
+{
+	char da[32], sa[32];
+
+	if (msg && (msg[0] != '\0'))
+		printf("et%d: %s: ", unit, msg);
+	else
+		printf("et%d: ", unit);
+
+	printf("dst %s src %s type 0x%x len %d\n",
+		bcm_ether_ntoa((struct ether_addr *)eh->ether_dhost, da),
+		bcm_ether_ntoa((struct ether_addr *)eh->ether_shost, sa),
+		ntoh16(eh->ether_type),
+		len);
+}
+void
+etc_prhex(char *msg, uchar *buf, uint nbytes, int unit)
+{
+	if (msg && (msg[0] != '\0'))
+		printf("et%d: %s:\n", unit, msg);
+	else
+		printf("et%d:\n", unit);
+
+	prhex(NULL, buf, nbytes);
+}
+#endif /* BCMDBG */
+
+void
+etc_unitmap(uint vendor, uint device, uint coreunit, uint *unit)
+{
+#if !defined(_CFE_) || defined(CFG_ETC47XX)
+	{
+		extern struct chops bcm47xx_et_chops;
+
+		if (bcm47xx_et_chops.id(vendor, device))
+			*unit = coreunit;
+	}
+#endif
+
+#ifdef CFG_GMAC
+	{
+		extern struct chops bcmgmac_et_chops;
+
+		if (bcmgmac_et_chops.id(vendor, device))
+			bcmgmac_et_chops.unitmap(coreunit, unit);
+	}
+#endif /* CFG_GMAC */
+}
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/etc.h b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc.h
new file mode 100644
index 0000000000..b24ee6d0a3
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc.h
@@ -0,0 +1,366 @@
+/*
+ * Common [OS-independent] header file for
+ * Broadcom BCM47XX 10/100Mbps Ethernet Device Driver
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: etc.h 468275 2014-04-07 05:21:13Z $
+ */
+
+#ifndef _etc_h_
+#define _etc_h_
+
+#include <etioctl.h>
+
+#define	MAXMULTILIST	32
+
+#ifndef ch_t
+#define	ch_t void
+#endif
+
+#define NUMTXQ		4
+
+#define TXREC_THR       8
+#define ETCQUOTA_MAX	64 /* Max et quota in dpc mode: bounds IOV_PKTCBND */
+
+#if defined(__ECOS)
+#define IOCBUFSZ	4096
+#elif defined(__linux__)
+#define IOCBUFSZ	16384
+#else
+#define IOCBUFSZ	4096
+#endif
+struct etc_info;	/* forward declaration */
+struct bcmstrbuf;	/* forward declaration */
+
+#ifdef ET_INGRESS_QOS
+#define DMA_RX_THRESH_DEFAULT	250
+#define DMA_RX_POLICY_NONE	0
+#define DMA_RX_POLICY_UDP	1
+#define DMA_RX_POLICY_TOS	2
+#define DMA_RX_POLICY_LAST	2
+#endif /* ET_INGRESS_QOS */
+
+/* each chip type supports a set of chip-type-specific ops */
+struct chops {
+	bool (*id)(uint vendor, uint device);		/* return true if match */
+	void *(*attach)(struct etc_info *etc, void *dev, void *regs);
+	void (*detach)(ch_t *ch);			/* free chip private state */
+	void (*reset)(ch_t *ch);			/* chip reset */
+	void (*init)(ch_t *ch, uint options);		/* chip init */
+	bool (*tx)(ch_t *ch, void *p);			/* transmit frame */
+	void *(*rx)(ch_t *ch);				/* receive frame */
+	int  (*rxquota)(ch_t *ch, int quota, void **rxpkts); /* receive quota pkt */
+	void (*rxlazy)(ch_t *ch);
+	void (*rxfill)(ch_t *ch);			/* post dma rx buffers */
+	int (*getintrevents)(ch_t *ch, bool in_isr);	/* return intr events */
+	bool (*errors)(ch_t *ch);			/* handle chip errors */
+	bool (*dmaerrors)(ch_t *ch);			/* check chip dma errors */
+	void (*intrson)(ch_t *ch);			/* enable chip interrupts */
+	void (*intrsoff)(ch_t *ch);			/* disable chip interrupts */
+	void (*txreclaim)(ch_t *ch, bool all);		/* reclaim transmit resources */
+	void (*rxreclaim)(ch_t *ch);			/* reclaim receive resources */
+	void (*statsupd)(ch_t *ch);			/* update sw stat counters */
+	void (*dumpmib)(ch_t *ch, struct bcmstrbuf *, bool clear);	/* get sw mib counters */
+	void (*enablepme)(ch_t *ch);			/* enable PME */
+	void (*disablepme)(ch_t *ch);			/* disable PME */
+	void (*configtimer)(ch_t *ch, uint microsecs); /* enable|disable gptimer */
+	void (*phyreset)(ch_t *ch, uint phyaddr);	/* reset phy */
+	uint16 (*phyrd)(ch_t *ch, uint phyaddr, uint reg);	/* read phy register */
+	void (*phywr)(ch_t *ch, uint phyaddr, uint reg, uint16 val);	/* write phy register */
+	uint (*macrd)(ch_t *ch, uint reg);	/* read gmac register */
+	void (*macwr)(ch_t *ch, uint reg, uint val);	/* write gmac register */
+	void (*dump)(ch_t *ch, struct bcmstrbuf *b);		/* debugging output */
+	void (*longname)(ch_t *ch, char *buf, uint bufsize);	/* return descriptive name */
+	void (*duplexupd)(ch_t *ch);			/* keep mac duplex consistent */
+	void (*unitmap)(uint coreunit, uint *unit);	/* core unit to enet unit mapping */
+	uint (*activerxbuf)(ch_t *ch); /* calculate the number of available free rx descriptors */
+};
+
+/*
+ * "Common" os-independent software state structure.
+ */
+typedef struct etc_info {
+	void		*et;		/* pointer to os-specific private state */
+	uint		unit;		/* device instance number */
+	void 		*osh; 		/* pointer to os handler */
+	bool		gmac_fwd;	/* wl rx/tx forwarding over gmac: -DBCM_GMAC3 */
+	bool		pktc;		/* packet chaining enabled or not */
+
+	uint		bp_ticks_usec; /* backplane clock ticks per microsec */
+	uint		rxlazy_timeout; /* rxlazy timeout configuration */
+	uint		rxlazy_framecnt; /* rxlazy framecount configuration */
+
+	int         pktcbnd;	/* max # of packets to chain */
+	int         quota;		/* max # of packets to recv */
+
+	void		*mib;		/* pointer to s/w maintained mib counters */
+	bool		up;		/* interface up and running */
+	bool		promisc;	/* promiscuous destination address */
+	bool		qos;		/* QoS priority determination on rx */
+	bool		loopbk;		/* loopback override mode */
+
+	int		forcespeed;	/* disable autonegotiation and force speed/duplex */
+	uint		advertise;	/* control speed/duplex advertised caps */
+	uint		advertise2;	/* control gige speed/duplex advertised caps */
+	bool		needautoneg;	/* request restart autonegotiation */
+	int		speed;		/* current speed: 10, 100 */
+	int		duplex;		/* current duplex: 0=half, 1=full */
+
+	bool		piomode;	/* enable programmed io (!dma) */
+	void		*pioactive;	/* points to pio packet being transmitted */
+	volatile uint	*txavail[NUMTXQ];	/* dma: # tx descriptors available */
+
+	uint16		vendorid;	/* pci function vendor id */
+	uint16		deviceid;	/* pci function device id */
+	uint		chip;		/* chip number */
+	uint		chiprev;	/* chip revision */
+	uint		chippkg;	/* chip package option */
+	uint		coreid;		/* core id */
+	uint		corerev;	/* core revision */
+
+	bool		nicmode;	/* is this core using its own pci i/f */
+
+	struct chops	*chops;		/* pointer to chip-specific opsvec */
+	void		*ch;		/* pointer to chip-specific state */
+	void		*robo;		/* optional robo private data */
+
+	uint		txq_state;	/* tx queues state bits */
+	uint		coreunit;	/* sb chips: chip enet instance # */
+	uint		phyaddr;	/* sb chips: mdio 5-bit phy address */
+	uint		mdcport;	/* sb chips: which mii to use (enet core #) to access phy */
+
+	struct ether_addr cur_etheraddr; /* our local ethernet address */
+	struct ether_addr perm_etheraddr; /* original sprom local ethernet address */
+
+	struct ether_addr multicast[MAXMULTILIST];
+	uint		nmulticast;
+	bool		allmulti;	/* enable all multicasts */
+
+	bool		linkstate;	/* link integrity state */
+	bool		pm_modechange;	/* true if mode change is to due pm */
+
+	uint32		now;		/* elapsed seconds */
+
+	uint32		boardflags;	/* board flags */
+	uint32		txrec_thresh;	/* # of tx frames after which reclaim is done */
+
+#ifdef ET_INGRESS_QOS
+	uint16		dma_rx_thresh;	/* DMA red zone RX descriptor threshold */
+	uint16		dma_rx_policy;	/* DMA RX discard policy in red zone */
+#endif /* ET_INGRESS_QOS */
+
+	/* sw-maintained stat counters */
+	uint32		txframes[NUMTXQ];	/* transmitted frames on each tx fifo */
+	uint32		txframe;	/* transmitted frames */
+	uint32		txbyte;		/* transmitted bytes */
+	uint32		rxframe;	/* received frames */
+	uint32		rxbyte;		/* received bytes */
+	uint32		txerror;	/* total tx errors */
+	uint32		txnobuf;	/* tx out-of-buffer errors */
+	uint32		rxerror;	/* total rx errors */
+	uint32		rxgiants;	/* total rx giant frames */
+	uint32		rxnobuf;	/* rx out-of-buffer errors */
+	uint32		reset;		/* reset count */
+	uint32		dmade;		/* pci descriptor errors */
+	uint32		dmada;		/* pci data errors */
+	uint32		dmape;		/* descriptor protocol error */
+	uint32		rxdmauflo;	/* receive descriptor underflow */
+	uint32		rxoflo;		/* receive fifo overflow */
+	uint32		txuflo;		/* transmit fifo underflow */
+	uint32		rxoflodiscards;	/* frames discarded during rx fifo overflow */
+	uint32		rxbadlen;	/* 802.3 len field != read length */
+	uint32		chained;	/* number of frames chained */
+	uint32		unchained;	/* number of frames not chained */
+	uint32		maxchainsz;	/* max chain size so far */
+	uint32		currchainsz;	/* current chain size */
+#if defined(BCMDBG)
+#if defined(PKTC)
+	uint32		chainsz[PKTCBND];	/* chain size histo */
+#endif /* PKTC */
+	uint32		quota_stats[ETCQUOTA_MAX];
+#endif /* BCMDBG */
+	uint32		rxprocessed;
+	uint32		reset_countdown;
+#ifdef ETFA
+	void		*fa;		/* optional fa private data */
+#endif
+} etc_info_t;
+
+typedef struct et_sw_port_info {
+	uint16 port_id;
+	uint16 link_state;	/* 0:down  1:up */
+	uint16 speed;		/* 0:unknown  1:10M  2:100M  3:1000M  4:200M */
+	uint16 duplex;		/* 0:unknown  1:half  2:full */
+} et_sw_port_info_t;
+
+#define MACADDR_MASK	0x0000FFFFFFFFFFFFLL
+#define VID_MASK		0x0FFF000000000000LL
+
+/* interrupt event bitvec */
+#define	INTR_TX		0x1
+#define	INTR_RX		0x2
+#define	INTR_ERROR	0x4
+#define	INTR_TO		0x8
+#define	INTR_NEW	0x10
+
+/* forcespeed values */
+#define	ET_AUTO		-1
+#define	ET_10HALF	0
+#define	ET_10FULL	1
+#define	ET_100HALF	2
+#define	ET_100FULL	3
+#define	ET_1000HALF	4
+#define	ET_1000FULL	5
+#define	ET_2500FULL	6
+
+/* init options */
+#define ET_INIT_FULL     0x1
+#define ET_INIT_INTRON   0x2
+
+/* Specific init options for et_init */
+#define ET_INIT_DEF_OPTIONS   (ET_INIT_FULL | ET_INIT_INTRON)
+#define ET_INIT_INTROFF       (ET_INIT_FULL)
+#define ET_INIT_PARTIAL      (0)
+
+/* macro to safely clear the UP flag */
+#define ET_FLAG_DOWN(x)   (*(x)->chops->intrsoff)((x)->ch);  \
+			  (x)->up = FALSE;
+
+/*
+ * Least-common denominator rxbuf start-of-data offset:
+ * Must be >= size of largest rxhdr
+ * Must be 2-mod-4 aligned so IP is 0-mod-4
+ */
+#define	HWRXOFF		18
+
+#define TC_BK		0	/* background traffic class */
+#define TC_BE		1	/* best effort traffic class */
+#define TC_CL		2	/* controlled load traffic class */
+#define TC_VO		3	/* voice traffic class */
+#define TC_NONE		-1	/* traffic class none */
+
+#define RX_Q0		0	/* receive DMA queue */
+#define NUMRXQ		1	/* gmac has one rx queue */
+
+#define TX_Q0		TC_BK	/* DMA txq 0 */
+#define TX_Q1		TC_BE	/* DMA txq 1 */
+#define TX_Q2		TC_CL	/* DMA txq 2 */
+#define TX_Q3		TC_VO	/* DMA txq 3 */
+
+
+static inline uint32
+etc_up2tc(uint32 up)
+{
+	extern uint32 up2tc[];
+
+	return (up2tc[up]);
+}
+
+static inline uint32
+etc_priq(uint32 txq_state)
+{
+	extern uint32 priq_selector[];
+
+	return (priq_selector[txq_state]);
+}
+
+/* RXH_FLAGS: GMAC and ENET47XX versions. */
+#define IS_GMAC(etc)            ((etc)->coreid == GMAC_CORE_ID)
+
+/* Test whether any rx errors occurred. */
+#define GMAC_RXH_FLAGS(rxh) \
+	((((bcmgmacrxh_t *)(rxh))->flags) & htol16(GRXF_CRC | GRXF_OVF | GRXF_OVERSIZE))
+
+#define ENET47XX_RXH_FLAGS(rxh) \
+	((((bcmenetrxh_t *)(rxh))->flags) & htol16(RXF_NO | RXF_RXER | RXF_CRC | RXF_OV))
+
+#define RXH_FLAGS(etc, rxh) \
+	(IS_GMAC(etc) ? GMAC_RXH_FLAGS(rxh) : ENET47XX_RXH_FLAGS(rxh))
+
+/* Host order rx header error flag accessors. */
+#define GMAC_RXH_FLAG_NONE      (FALSE)
+#define ENET47XX_RXH_FLAG_NONE  (FALSE)
+
+#define GMAC_RXERROR(rxh, mask) \
+	((ltoh16(((bcmgmacrxh_t *)(rxh))->flags)) & (mask))
+#define ENET47XX_RXERROR(rxh, mask) \
+	((ltoh16(((bcmenetrxh_t *)(rxh))->flags)) & (mask))
+
+/* rx: over size packet error */
+#define RXH_OVERSIZE(etc, rxh) \
+	(IS_GMAC(etc) ? GMAC_RXERROR(rxh, GRXF_OVERSIZE) : ENET47XX_RXH_FLAG_NONE)
+
+/* rx: crc error. */
+#define RXH_CRC(etc, rxh) \
+	(IS_GMAC(etc) ? GMAC_RXERROR(rxh, GRXF_CRC) : ENET47XX_RXERROR(rxh, RXF_CRC))
+
+/* rx: fifo overflow error. */
+#define RXH_OVF(etc, rxh) \
+	(IS_GMAC(etc) ? GMAC_RXERROR(rxh, GRXF_OVF) : ENET47XX_RXERROR(rxh, RXF_OV))
+
+/* rx: symbol error */
+#define RXH_RXER(etc, rxh) \
+	(IS_GMAC(etc) ? GMAC_RXH_FLAG_NONE : ENET47XX_RXERROR(rxh, RXF_RXER))
+
+/* rx: crc error (odd nibbles) */
+#define RXH_NO(etc, rxh) \
+	(IS_GMAC(etc) ? GMAC_RXH_FLAG_NONE : ENET47XX_RXERROR(rxh, RXF_NO))
+
+
+#ifdef	CFG_GMAC
+#define ET_GMAC(etc)	((etc)->coreid == GMAC_CORE_ID)
+#else
+#define ET_GMAC(etc)	(0)
+#endif	/* CFG_GMAC */
+
+#if defined(BCM_GMAC3)
+/** Types of ethernet device driver.
+ * In the 3 GMAC Model, the ethernet driver operates as either a
+ * - FWD: HW Switch Forwarder to WLAN MAC Interface such as wl0, wl1
+ * - NTK: Ethernet Network Interface binding to network stack (via CTF)
+ */
+#define DEV_FWDER_NAME          "fwd"
+#define DEV_NTKIF(etc)          ((etc)->gmac_fwd == FALSE)
+#define DEV_FWDER(etc)          ((etc)->gmac_fwd == TRUE)
+#else  /* ! BCM_GMAC3 */
+#define DEV_FWDER_NAME          "eth"
+#define DEV_NTKIF(etc)          (TRUE)
+#define DEV_FWDER(etc)          (FALSE)
+#endif /* ! BCM_GMAC3 */
+
+/* exported prototypes */
+extern struct chops *etc_chipmatch(uint vendor, uint device);
+extern void *etc_attach(void *et, uint vendor, uint device, uint coreunit, void *dev, void *regsva);
+extern void etc_detach(etc_info_t *etc);
+extern void etc_reset(etc_info_t *etc);
+extern void etc_init(etc_info_t *etc, uint options);
+extern void etc_up(etc_info_t *etc);
+extern uint etc_down(etc_info_t *etc, int reset);
+extern int etc_ioctl(etc_info_t *etc, int cmd, void *arg);
+extern int etc_iovar(etc_info_t *etc, uint cmd, uint set, void *arg, int len);
+extern void etc_promisc(etc_info_t *etc, uint on);
+extern void etc_qos(etc_info_t *etc, uint on);
+extern void etc_quota(etc_info_t *etc);
+extern void etc_rxlazy(etc_info_t *etc, uint microsecs, uint framecnt);
+extern void etc_dump(etc_info_t *etc, struct bcmstrbuf *b);
+extern void etc_watchdog(etc_info_t *etc);
+extern uint etc_totlen(etc_info_t *etc, void *p);
+#ifdef ETROBO
+extern void *etc_bcm53115_war(etc_info_t *etc, void *p);
+#endif /* ETROBO */
+extern void etc_unitmap(uint vendor, uint device, uint coreunit, uint *unit);
+
+#endif	/* _etc_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/etc47xx.c b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc47xx.c
new file mode 100644
index 0000000000..d98e579b07
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc47xx.c
@@ -0,0 +1,1350 @@
+/*
+ * Broadcom Home Networking Division 10/100 Mbit/s Ethernet core.
+ *
+ * This file implements the chip-specific routines
+ * for Broadcom HNBU Sonics SiliconBackplane enet cores.
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: etc47xx.c 458474 2014-02-27 00:47:47Z $
+ */
+
+#include <et_cfg.h>
+#include <typedefs.h>
+#include <osl.h>
+#include <bcmdefs.h>
+#include <bcmendian.h>
+#include <bcmutils.h>
+#include <bcmdevs.h>
+#include <proto/ethernet.h>
+#include <siutils.h>
+#include <sbhnddma.h>
+#include <hnddma.h>
+#include <et_dbg.h>
+#include <hndsoc.h>
+#include <bcmenet47xx.h>
+#include <et_export.h>		/* for et_phyxx() routines */
+
+#ifdef ETROBO
+#include <bcmrobo.h>
+#endif /* ETROBO */
+#ifdef ETADM
+#include <etc_adm.h>
+#endif /* ETADM */
+
+struct bcm4xxx;	/* forward declaration */
+#define ch_t	struct bcm4xxx
+#include <etc.h>
+
+/* private chip state */
+struct bcm4xxx {
+	void 		*et;		/* pointer to et private state */
+	etc_info_t	*etc;		/* pointer to etc public state */
+
+	bcmenetregs_t	*regs;		/* pointer to chip registers */
+	osl_t 		*osh;		/* os handle */
+
+	void 		*etphy;		/* pointer to et for shared mdc/mdio contortion */
+
+	uint32		intstatus;	/* saved interrupt condition bits */
+	uint32		intmask;	/* current software interrupt mask */
+
+	hnddma_t	*di;		/* dma engine software state */
+
+	bool		mibgood;	/* true once mib registers have been cleared */
+	bcmenetmib_t	mib;		/* mib counters */
+	si_t 		*sih;		/* si utils handle */
+
+	char		*vars;		/* sprom name=value */
+	uint		vars_size;
+
+	void		*adm;		/* optional admtek private data */
+};
+
+/* local prototypes */
+static bool chipid(uint vendor, uint device);
+static void *chipattach(etc_info_t *etc, void *osh, void *regsva);
+static void chipdetach(ch_t *ch);
+static void chipreset(ch_t *ch);
+static void chipinit(ch_t *ch, uint options);
+static bool chiptx(ch_t *ch, void *p);
+static void *chiprx(ch_t *ch);
+static int  chiprxquota(ch_t *ch, int quota, void **rxpkts);
+static void chiprxlazy(ch_t *ch);
+static void chiprxfill(ch_t *ch);
+static int chipgetintrevents(ch_t *ch, bool in_isr);
+static bool chiperrors(ch_t *ch);
+static void chipintrson(ch_t *ch);
+static void chipintrsoff(ch_t *ch);
+static void chiptxreclaim(ch_t *ch, bool all);
+static void chiprxreclaim(ch_t *ch);
+static void chipstatsupd(ch_t *ch);
+static void chipdumpmib(ch_t *ch, struct bcmstrbuf *b, bool clear);
+static void chipenablepme(ch_t *ch);
+static void chipdisablepme(ch_t *ch);
+static void chipconfigtimer(ch_t *ch, uint microsecs);
+static void chipphyreset(ch_t *ch, uint phyaddr);
+static void chipphyinit(ch_t *ch, uint phyaddr);
+static uint16 chipphyrd(ch_t *ch, uint phyaddr, uint reg);
+static void chipdump(ch_t *ch, struct bcmstrbuf *b);
+static void chiplongname(ch_t *ch, char *buf, uint bufsize);
+static void chipduplexupd(ch_t *ch);
+static void chipwrcam(struct bcm4xxx *ch, struct ether_addr *ea, uint camindex);
+static void chipphywr(struct bcm4xxx *ch, uint phyaddr, uint reg, uint16 v);
+static void chipphyor(struct bcm4xxx *ch, uint phyaddr, uint reg, uint16 v);
+static void chipphyand(struct bcm4xxx *ch, uint phyaddr, uint reg, uint16 v);
+static void chipphyforce(struct bcm4xxx *ch, uint phyaddr);
+static void chipphyadvertise(struct bcm4xxx *ch, uint phyaddr);
+static uint chipmacrd(struct bcm4xxx *ch, uint reg);
+static void chipmacwr(struct bcm4xxx *ch, uint reg, uint val);
+#ifdef BCMDBG
+static void chipdumpregs(struct bcm4xxx *ch, bcmenetregs_t *regs, struct bcmstrbuf *b);
+#endif /* BCMDBG */
+
+/* chip interrupt bit error summary */
+#define	I_ERRORS	(I_PC | I_PD | I_DE | I_RU | I_RO | I_XU)
+#define	DEF_INTMASK	(I_XI | I_RI | I_ERRORS)
+
+struct chops bcm47xx_et_chops = {
+	chipid,
+	chipattach,
+	chipdetach,
+	chipreset,
+	chipinit,
+	chiptx,
+	chiprx,
+	chiprxquota,
+	chiprxlazy,
+	chiprxfill,
+	chipgetintrevents,
+	chiperrors,
+	NULL,
+	chipintrson,
+	chipintrsoff,
+	chiptxreclaim,
+	chiprxreclaim,
+	chipstatsupd,
+	chipdumpmib,
+	chipenablepme,
+	chipdisablepme,
+	chipconfigtimer,
+	chipphyreset,
+	chipphyrd,
+	chipphywr,
+	chipmacrd,
+	chipmacwr,
+	chipdump,
+	chiplongname,
+	chipduplexupd
+};
+
+static uint devices[] = {
+	BCM47XX_ENET_ID,
+	0x0000 };
+
+static bool
+chipid(uint vendor, uint device)
+{
+	int i;
+
+	if (vendor != VENDOR_BROADCOM)
+		return (FALSE);
+
+	for (i = 0; devices[i]; i++) {
+		if (device == devices[i])
+			return (TRUE);
+	}
+	return (FALSE);
+}
+
+static void *
+chipattach(etc_info_t *etc, void *osh, void *regsva)
+{
+	struct bcm4xxx *ch;
+	bcmenetregs_t *regs;
+	char name[16];
+	char *var;
+	uint boardflags, boardtype;
+
+	ET_TRACE(("et%d: chipattach: regsva 0x%lx\n", etc->unit, (ulong)regsva));
+
+	if ((ch = (struct bcm4xxx *)MALLOC(osh, sizeof(struct bcm4xxx))) == NULL) {
+		ET_ERROR(("et%d: chipattach: out of memory, malloced %d bytes\n", etc->unit,
+		          MALLOCED(osh)));
+		return (NULL);
+	}
+	bzero((char *)ch, sizeof(struct bcm4xxx));
+
+	ch->etc = etc;
+	ch->et = etc->et;
+	ch->osh = osh;
+
+	/* store the pointer to the sw mib */
+	etc->mib = (void *)&ch->mib;
+
+	/* get si handle */
+	if ((ch->sih = si_attach(etc->deviceid, ch->osh, regsva, PCI_BUS, NULL, &ch->vars,
+	                         &ch->vars_size)) == NULL) {
+		ET_ERROR(("et%d: chipattach: si_attach error\n", etc->unit));
+		goto fail;
+	}
+
+	/* We used to have an assert here like:
+	 *	si_coreid(ch->sih) == ENET_CORE_ID
+	 * but srom-less systems and simulators don't have a way to
+	 * provide a default bar0window so we were relying on nvram
+	 * variables. At some point we decided that we could do away
+	 * with that since the wireless driver was simply doing a
+	 * setcore in attach. So we need to do the same here for
+	 * the ethernet.
+	 */
+	if ((regs = (bcmenetregs_t *)si_setcore(ch->sih, ENET_CORE_ID, etc->unit)) == NULL) {
+		ET_ERROR(("et%d: chipattach: Could not setcore to the ENET core\n", etc->unit));
+		goto fail;
+	}
+
+	ch->regs = regs;
+	etc->chip = ch->sih->chip;
+	etc->chiprev = ch->sih->chiprev;
+	etc->coreid = si_coreid(ch->sih);
+	etc->corerev = si_corerev(ch->sih);
+	etc->nicmode = !(ch->sih->bustype == SI_BUS);
+	etc->coreunit = si_coreunit(ch->sih);
+	etc->boardflags = getintvar(ch->vars, "boardflags");
+
+	boardflags = etc->boardflags;
+	boardtype = ch->sih->boardtype;
+
+	/* Backplane clock ticks per microsecs: used by gptimer, intrecvlazy */
+	etc->bp_ticks_usec = si_clock(ch->sih) / 1000000;
+
+	/* get our local ether addr */
+	sprintf(name, "et%dmacaddr", etc->coreunit);
+	var = getvar(ch->vars, name);
+	if (var == NULL) {
+		ET_ERROR(("et%d: chipattach: NVRAM_GET(%s) not found\n", etc->unit, name));
+		goto fail;
+	}
+	bcm_ether_atoe(var, &etc->perm_etheraddr);
+
+	if (ETHER_ISNULLADDR(&etc->perm_etheraddr)) {
+		ET_ERROR(("et%d: chipattach: invalid format: %s=%s\n", etc->unit, name, var));
+		goto fail;
+	}
+	bcopy((char *)&etc->perm_etheraddr, (char *)&etc->cur_etheraddr, ETHER_ADDR_LEN);
+
+	/*
+	 * Too much can go wrong in scanning MDC/MDIO playing "whos my phy?" .
+	 * Instead, explicitly require the environment var "et<coreunit>phyaddr=<val>".
+	 */
+
+	/* get our phyaddr value */
+	sprintf(name, "et%dphyaddr", etc->coreunit);
+	var = getvar(ch->vars, name);
+	if (var == NULL) {
+		ET_ERROR(("et%d: chipattach: NVRAM_GET(%s) not found\n", etc->unit, name));
+		goto fail;
+	}
+	etc->phyaddr = bcm_atoi(var) & EPHY_MASK;
+
+	/* nvram says no phy is present */
+	if (etc->phyaddr == EPHY_NONE) {
+		ET_ERROR(("et%d: chipattach: phy not present\n", etc->unit));
+		goto fail;
+	}
+
+	/* get our mdc/mdio port number */
+	sprintf(name, "et%dmdcport", etc->coreunit);
+	var = getvar(ch->vars, name);
+	if (var == NULL) {
+		ET_ERROR(("et%d: chipattach: NVRAM_GET(%s) not found\n", etc->unit, name));
+		goto fail;
+	}
+	etc->mdcport = bcm_atoi(var);
+
+	/* configure pci core */
+	si_pci_setup(ch->sih, (1 << si_coreidx(ch->sih)));
+
+	/* reset the enet core */
+	chipreset(ch);
+
+	/* dma attach */
+	sprintf(name, "et%d", etc->coreunit);
+	if ((ch->di = dma_attach(osh, name, ch->sih,
+	                         (void *)&regs->dmaregs.xmt, (void *)&regs->dmaregs.rcv,
+	                         NTXD, NRXD, RXBUFSZ, -1, NRXBUFPOST, HWRXOFF,
+	                         &et_msg_level)) == NULL) {
+		ET_ERROR(("et%d: chipattach: dma_attach failed\n", etc->unit));
+		goto fail;
+	}
+	etc->txavail[TX_Q0] = (uint *)&ch->di->txavail;
+
+	/* set default sofware intmask */
+	ch->intmask = DEF_INTMASK;
+
+	/*
+	 * For the 5222 dual phy shared mdio contortion, our phy is
+	 * on someone elses mdio pins.  This other enet enet
+	 * may not yet be attached so we must defer the et_phyfind().
+	 */
+	/* if local phy: reset it once now */
+	if (etc->mdcport == etc->coreunit)
+		chipphyreset(ch, etc->phyaddr);
+
+#ifdef ETROBO
+	/*
+	 * Broadcom Robo ethernet switch.
+	 */
+	if ((boardflags & BFL_ENETROBO) &&
+	    (etc->phyaddr == EPHY_NOREG)) {
+		/* Attach to the switch */
+		if (!(etc->robo = bcm_robo_attach(ch->sih, ch, ch->vars,
+		                                  (miird_f)bcm47xx_et_chops.phyrd,
+		                                  (miiwr_f)bcm47xx_et_chops.phywr))) {
+			ET_ERROR(("et%d: chipattach: robo_attach failed\n", etc->unit));
+			goto fail;
+		}
+		/* Enable the switch and set it to a known good state */
+		if (bcm_robo_enable_device(etc->robo)) {
+			ET_ERROR(("et%d: chipattach: robo_enable_device failed\n", etc->unit));
+			goto fail;
+		}
+		/* Configure the switch to do VLAN */
+		if ((boardflags & BFL_ENETVLAN) &&
+		    bcm_robo_config_vlan(etc->robo, etc->perm_etheraddr.octet)) {
+			ET_ERROR(("et%d: chipattach: robo_config_vlan failed\n", etc->unit));
+			goto fail;
+		}
+		/* Enable switching/forwarding */
+		if (bcm_robo_enable_switch(etc->robo)) {
+			ET_ERROR(("et%d: chipattach: robo_enable_switch failed\n", etc->unit));
+			goto fail;
+		}
+	}
+#endif /* ETROBO */
+
+#ifdef ETADM
+	/*
+	 * ADMtek ethernet switch.
+	 */
+	if (boardflags & BFL_ENETADM) {
+		/* Attach to the device */
+		if (!(ch->adm = adm_attach(ch->sih, ch->vars))) {
+			ET_ERROR(("et%d: chipattach: adm_attach failed\n", etc->unit));
+			goto fail;
+		}
+		/* Enable the external switch and set it to a known good state */
+		if (adm_enable_device(ch->adm)) {
+			ET_ERROR(("et%d: chipattach: adm_enable_device failed\n", etc->unit));
+			goto fail;
+		}
+		/* Configure the switch */
+		if ((boardflags & BFL_ENETVLAN) && adm_config_vlan(ch->adm)) {
+			ET_ERROR(("et%d: chipattach: adm_config_vlan failed\n", etc->unit));
+			goto fail;
+		}
+	}
+#endif /* ETADM */
+
+	return ((void *)ch);
+
+fail:
+	chipdetach(ch);
+	return (NULL);
+}
+
+static void
+chipdetach(struct bcm4xxx *ch)
+{
+	ET_TRACE(("et%d: chipdetach\n", ch->etc->unit));
+
+	if (ch == NULL)
+		return;
+
+#ifdef ETROBO
+	/* free robo state */
+	if (ch->etc->robo)
+		bcm_robo_detach(ch->etc->robo);
+#endif /* ETROBO */
+
+#ifdef ETADM
+	/* free ADMtek state */
+	if (ch->adm)
+		adm_detach(ch->adm);
+#endif /* ETADM */
+
+	/* free dma state */
+	if (ch->di)
+		dma_detach(ch->di);
+	ch->di = NULL;
+
+	/* put the core back into reset */
+	if (ch->sih)
+		si_core_disable(ch->sih, 0);
+
+	/* free si handle */
+	si_detach(ch->sih);
+	ch->sih = NULL;
+
+	/* free vars */
+	if (ch->vars)
+		MFREE(ch->osh, ch->vars, ch->vars_size);
+
+	/* free chip private state */
+	MFREE(ch->osh, ch, sizeof(struct bcm4xxx));
+}
+
+static void
+chiplongname(struct bcm4xxx *ch, char *buf, uint bufsize)
+{
+	char *s;
+
+	switch (ch->etc->deviceid) {
+	case BCM47XX_ENET_ID:
+	default:
+		s = "Broadcom BCM47xx 10/100 Mbps Ethernet Controller";
+		break;
+	}
+
+	strncpy(buf, s, bufsize);
+	buf[bufsize - 1] = '\0';
+}
+
+static uint
+chipmacrd(struct bcm4xxx *ch, uint offset)
+{
+	ASSERT(offset < 4096); /* GMAC Register space is 4K size */
+	return R_REG(ch->osh, (uint *)((uint)(ch->regs) + offset));
+}
+
+static void
+chipmacwr(struct bcm4xxx *ch, uint offset, uint val)
+{
+	ASSERT(offset < 4096); /* GMAC Register space is 4K size */
+	W_REG(ch->osh, (uint *)((uint)(ch->regs) + offset), val);
+}
+
+static void
+chipdump(struct bcm4xxx *ch, struct bcmstrbuf *b)
+{
+#ifdef BCMDBG
+	bcm_bprintf(b, "regs 0x%x etphy 0x%x ch->intstatus 0x%x intmask 0x%x\n",
+		(ulong)ch->regs, (ulong)ch->etphy, ch->intstatus, ch->intmask);
+	bcm_bprintf(b, "\n");
+
+	/* dma engine state */
+	dma_dump(ch->di, b, FALSE);
+	bcm_bprintf(b, "\n");
+
+	/* registers */
+	chipdumpregs(ch, ch->regs, b);
+	bcm_bprintf(b, "\n");
+
+	/* switch registers */
+#ifdef ETROBO
+	if (ch->etc->robo)
+		robo_dump_regs(ch->etc->robo, b);
+#endif /* ETROBO */
+#ifdef ETADM
+	if (ch->adm)
+		adm_dump_regs(ch->adm, b->buf);
+#endif /* ETADM */
+#endif	/* BCMDBG */
+}
+
+#ifdef BCMDBG
+
+#define	PRREG(name)	bcm_bprintf(b, #name " 0x%x ", R_REG(ch->osh, &regs->name))
+#define	PRMIBREG(name)	bcm_bprintf(b, #name " 0x%x ", R_REG(ch->osh, &regs->mib.name))
+
+static void
+chipdumpregs(struct bcm4xxx *ch, bcmenetregs_t *regs, struct bcmstrbuf *b)
+{
+	uint phyaddr;
+
+	phyaddr = ch->etc->phyaddr;
+
+	PRREG(devcontrol); PRREG(biststatus); PRREG(wakeuplength);
+	bcm_bprintf(b, "\n");
+	PRREG(intstatus); PRREG(intmask); PRREG(gptimer);
+	bcm_bprintf(b, "\n");
+	PRREG(emactxmaxburstlen); PRREG(emacrxmaxburstlen);
+	PRREG(emaccontrol); PRREG(emacflowcontrol);
+	bcm_bprintf(b, "\n");
+	PRREG(intrecvlazy);
+	bcm_bprintf(b, "\n");
+
+	/* emac registers */
+	PRREG(rxconfig); PRREG(rxmaxlength); PRREG(txmaxlength);
+	bcm_bprintf(b, "\n");
+	PRREG(mdiocontrol); PRREG(camcontrol); PRREG(enetcontrol);
+	bcm_bprintf(b, "\n");
+	PRREG(txcontrol); PRREG(txwatermark); PRREG(mibcontrol);
+	bcm_bprintf(b, "\n");
+
+	/* mib registers */
+	PRMIBREG(tx_good_octets); PRMIBREG(tx_good_pkts); PRMIBREG(tx_octets); PRMIBREG(tx_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(tx_broadcast_pkts); PRMIBREG(tx_multicast_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(tx_jabber_pkts); PRMIBREG(tx_oversize_pkts); PRMIBREG(tx_fragment_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(tx_underruns); PRMIBREG(tx_total_cols); PRMIBREG(tx_single_cols);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(tx_multiple_cols); PRMIBREG(tx_excessive_cols); PRMIBREG(tx_late_cols);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(tx_defered); PRMIBREG(tx_carrier_lost); PRMIBREG(tx_pause_pkts);
+	bcm_bprintf(b, "\n");
+
+	PRMIBREG(rx_good_octets); PRMIBREG(rx_good_pkts); PRMIBREG(rx_octets); PRMIBREG(rx_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(rx_broadcast_pkts); PRMIBREG(rx_multicast_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(rx_jabber_pkts); PRMIBREG(rx_oversize_pkts); PRMIBREG(rx_fragment_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(rx_missed_pkts); PRMIBREG(rx_crc_align_errs); PRMIBREG(rx_undersize);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(rx_crc_errs); PRMIBREG(rx_align_errs); PRMIBREG(rx_symbol_errs);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(rx_pause_pkts); PRMIBREG(rx_nonpause_pkts);
+	bcm_bprintf(b, "\n");
+
+	if (phyaddr != EPHY_NOREG) {
+		/* print a few interesting phy registers */
+		bcm_bprintf(b, "phy0 0x%x phy1 0x%x phy2 0x%x phy3 0x%x\n",
+		               chipphyrd(ch, phyaddr, 0),
+		               chipphyrd(ch, phyaddr, 1),
+		               chipphyrd(ch, phyaddr, 2),
+		               chipphyrd(ch, phyaddr, 3));
+		bcm_bprintf(b, "phy4 0x%x phy5 0x%x phy24 0x%x phy25 0x%x\n",
+		               chipphyrd(ch, phyaddr, 4),
+		               chipphyrd(ch, phyaddr, 5),
+		               chipphyrd(ch, phyaddr, 24),
+		               chipphyrd(ch, phyaddr, 25));
+	}
+
+}
+#endif	/* BCMDBG */
+
+#define	MDC_RATIO	5000000
+
+static void
+chipreset(struct bcm4xxx *ch)
+{
+	bcmenetregs_t *regs;
+	uint32 clk, mdc;
+
+	ET_TRACE(("et%d: chipreset\n", ch->etc->unit));
+
+	regs = ch->regs;
+
+	if (!si_iscoreup(ch->sih)) {
+		if (!ch->etc->nicmode)
+			si_pci_setup(ch->sih, (1 << si_coreidx(ch->sih)));
+		/* power on reset: reset the enet core */
+		si_core_reset(ch->sih, 0, 0);
+		goto chipinreset;
+	}
+
+	/* read counters before resetting the chip */
+	if (ch->mibgood)
+		chipstatsupd(ch);
+
+	/* reset the tx dma engine */
+	if (ch->di)
+		dma_txreset(ch->di);
+
+	/* set emac into loopback mode to ensure no rx traffic */
+	W_REG(ch->osh, &regs->rxconfig, ERC_LE);
+	OSL_DELAY(1);
+
+	/* reset the rx dma engine */
+	if (ch->di)
+		dma_rxreset(ch->di);
+
+	/* reset core */
+	si_core_reset(ch->sih, 0, 0);
+
+chipinreset:
+
+	/* must clear mib registers by hand */
+	W_REG(ch->osh, &regs->mibcontrol, EMC_RZ);
+	(void) R_REG(ch->osh, &regs->mib.tx_broadcast_pkts);
+	(void) R_REG(ch->osh, &regs->mib.tx_multicast_pkts);
+	(void) R_REG(ch->osh, &regs->mib.tx_len_64);
+	(void) R_REG(ch->osh, &regs->mib.tx_len_65_to_127);
+	(void) R_REG(ch->osh, &regs->mib.tx_len_128_to_255);
+	(void) R_REG(ch->osh, &regs->mib.tx_len_256_to_511);
+	(void) R_REG(ch->osh, &regs->mib.tx_len_512_to_1023);
+	(void) R_REG(ch->osh, &regs->mib.tx_len_1024_to_max);
+	(void) R_REG(ch->osh, &regs->mib.tx_jabber_pkts);
+	(void) R_REG(ch->osh, &regs->mib.tx_oversize_pkts);
+	(void) R_REG(ch->osh, &regs->mib.tx_fragment_pkts);
+	(void) R_REG(ch->osh, &regs->mib.tx_underruns);
+	(void) R_REG(ch->osh, &regs->mib.tx_total_cols);
+	(void) R_REG(ch->osh, &regs->mib.tx_single_cols);
+	(void) R_REG(ch->osh, &regs->mib.tx_multiple_cols);
+	(void) R_REG(ch->osh, &regs->mib.tx_excessive_cols);
+	(void) R_REG(ch->osh, &regs->mib.tx_late_cols);
+	(void) R_REG(ch->osh, &regs->mib.tx_defered);
+	(void) R_REG(ch->osh, &regs->mib.tx_carrier_lost);
+	(void) R_REG(ch->osh, &regs->mib.tx_pause_pkts);
+	(void) R_REG(ch->osh, &regs->mib.rx_broadcast_pkts);
+	(void) R_REG(ch->osh, &regs->mib.rx_multicast_pkts);
+	(void) R_REG(ch->osh, &regs->mib.rx_len_64);
+	(void) R_REG(ch->osh, &regs->mib.rx_len_65_to_127);
+	(void) R_REG(ch->osh, &regs->mib.rx_len_128_to_255);
+	(void) R_REG(ch->osh, &regs->mib.rx_len_256_to_511);
+	(void) R_REG(ch->osh, &regs->mib.rx_len_512_to_1023);
+	(void) R_REG(ch->osh, &regs->mib.rx_len_1024_to_max);
+	(void) R_REG(ch->osh, &regs->mib.rx_jabber_pkts);
+	(void) R_REG(ch->osh, &regs->mib.rx_oversize_pkts);
+	(void) R_REG(ch->osh, &regs->mib.rx_fragment_pkts);
+	(void) R_REG(ch->osh, &regs->mib.rx_missed_pkts);
+	(void) R_REG(ch->osh, &regs->mib.rx_crc_align_errs);
+	(void) R_REG(ch->osh, &regs->mib.rx_undersize);
+	(void) R_REG(ch->osh, &regs->mib.rx_crc_errs);
+	(void) R_REG(ch->osh, &regs->mib.rx_align_errs);
+	(void) R_REG(ch->osh, &regs->mib.rx_symbol_errs);
+	(void) R_REG(ch->osh, &regs->mib.rx_pause_pkts);
+	(void) R_REG(ch->osh, &regs->mib.rx_nonpause_pkts);
+	ch->mibgood = TRUE;
+
+	/*
+	 * We want the phy registers to be accessible even when
+	 * the driver is "downed" so initialize MDC preamble, frequency,
+	 * and whether internal or external phy here.
+	 */
+	/* default:  100Mhz SI clock and external phy */
+	W_REG(ch->osh, &regs->mdiocontrol, 0x94);
+	if (ch->etc->deviceid == BCM47XX_ENET_ID) {
+		/* 47xx chips: find out the clock */
+		if ((clk = si_clock(ch->sih)) != 0) {
+			mdc = 0x80 | ((clk + (MDC_RATIO / 2)) / MDC_RATIO);
+			W_REG(ch->osh, &regs->mdiocontrol, mdc);
+		} else {
+			ET_ERROR(("et%d: chipreset: Could not figure out backplane clock, "
+			          "using 100Mhz\n",
+			          ch->etc->unit));
+		}
+	}
+
+	/* some chips have internal phy, some don't */
+	if (!(R_REG(ch->osh, &regs->devcontrol) & DC_IP)) {
+		W_REG(ch->osh, &regs->enetcontrol, EC_EP);
+	} else if (R_REG(ch->osh, &regs->devcontrol) & DC_ER) {
+		AND_REG(ch->osh, &regs->devcontrol, ~DC_ER);
+		OSL_DELAY(100);
+		chipphyinit(ch, ch->etc->phyaddr);
+	}
+
+	/* clear persistent sw intstatus */
+	ch->intstatus = 0;
+}
+
+/*
+ * Initialize all the chip registers.  If dma mode, init tx and rx dma engines
+ * but leave the devcontrol tx and rx (fifos) disabled.
+ */
+static void
+chipinit(struct bcm4xxx *ch, uint options)
+{
+	etc_info_t *etc;
+	bcmenetregs_t *regs;
+	uint idx;
+	uint i;
+
+	regs = ch->regs;
+	etc = ch->etc;
+	idx = 0;
+
+	ET_TRACE(("et%d: chipinit\n", etc->unit));
+
+	/* enable crc32 generation */
+	OR_REG(ch->osh, &regs->emaccontrol, EMC_CG);
+
+	/* enable one rx interrupt per received frame */
+	W_REG(ch->osh, &regs->intrecvlazy, (1 << IRL_FC_SHIFT));
+
+	/* enable 802.3x tx flow control (honor received PAUSE frames) */
+	W_REG(ch->osh, &regs->rxconfig, ERC_FE | ERC_UF);
+
+	/* initialize CAM */
+	if (etc->promisc || (R_REG(ch->osh, &regs->rxconfig) & ERC_CA))
+		OR_REG(ch->osh, &regs->rxconfig, ERC_PE);
+	else {
+		/* our local address */
+		chipwrcam(ch, &etc->cur_etheraddr, idx++);
+
+		/* allmulti or a list of discrete multicast addresses */
+		if (etc->allmulti)
+			OR_REG(ch->osh, &regs->rxconfig, ERC_AM);
+		else if (etc->nmulticast) {
+			for (i = 0; i < etc->nmulticast; i++)
+				chipwrcam(ch, &etc->multicast[i], idx++);
+		}
+
+		/* enable cam */
+		OR_REG(ch->osh, &regs->camcontrol, CC_CE);
+	}
+
+	/* optionally enable mac-level loopback */
+	if (etc->loopbk)
+		OR_REG(ch->osh, &regs->rxconfig, ERC_LE);
+
+	/* set max frame lengths - account for possible vlan tag */
+	W_REG(ch->osh, &regs->rxmaxlength, ETHER_MAX_LEN + 32);
+	W_REG(ch->osh, &regs->txmaxlength, ETHER_MAX_LEN + 32);
+
+	/* set tx watermark */
+	W_REG(ch->osh, &regs->txwatermark, 56);
+
+	/*
+	 * Optionally, disable phy autonegotiation and force our speed/duplex
+	 * or constrain our advertised capabilities.
+	 */
+	if (etc->forcespeed != ET_AUTO)
+		chipphyforce(ch, etc->phyaddr);
+	else if (etc->advertise && etc->needautoneg)
+		chipphyadvertise(ch, etc->phyaddr);
+
+	if (options & ET_INIT_FULL) {
+		/* initialize the tx and rx dma channels */
+		dma_txinit(ch->di);
+		dma_rxinit(ch->di);
+
+		/* post dma receive buffers */
+		dma_rxfill(ch->di);
+
+		/* lastly, enable interrupts */
+		if (options & ET_INIT_INTRON)
+			et_intrson(etc->et);
+	}
+	else
+		dma_rxenable(ch->di);
+
+	/* turn on the emac */
+	OR_REG(ch->osh, &regs->enetcontrol, EC_EE);
+}
+
+/* dma transmit */
+static bool BCMFASTPATH
+chiptx(struct bcm4xxx *ch, void *p0)
+{
+	int error;
+
+	ET_TRACE(("et%d: chiptx\n", ch->etc->unit));
+	ET_LOG("et%d: chiptx", ch->etc->unit, 0);
+
+	error = dma_txfast(ch->di, p0, TRUE);
+
+	if (error) {
+		ET_ERROR(("et%d: chiptx: out of txds\n", ch->etc->unit));
+		ch->etc->txnobuf++;
+		return FALSE;
+	}
+	return TRUE;
+}
+
+/* reclaim completed transmit descriptors and packets */
+static void BCMFASTPATH
+chiptxreclaim(struct bcm4xxx *ch, bool forceall)
+{
+	ET_TRACE(("et%d: chiptxreclaim\n", ch->etc->unit));
+	dma_txreclaim(ch->di, forceall ? HNDDMA_RANGE_ALL : HNDDMA_RANGE_TRANSMITTED);
+	ch->intstatus &= ~I_XI;
+}
+
+/* dma receive: returns a pointer to the next frame received, or NULL if there are no more */
+static void * BCMFASTPATH
+chiprx(struct bcm4xxx *ch)
+{
+	void *p;
+
+	ET_TRACE(("et%d: chiprx\n", ch->etc->unit));
+	ET_LOG("et%d: chiprx", ch->etc->unit, 0);
+
+	if ((p = dma_rx(ch->di)) == NULL)
+		ch->intstatus &= ~I_RI;
+
+	return (p);
+}
+
+static int BCMFASTPATH
+chiprxquota(ch_t *ch, int quota, void **rxpkts)
+{
+	int rxcnt;
+	void * pkt;
+	uint8 * addr;
+
+	ET_TRACE(("et%d: chiprxquota\n", ch->etc->unit));
+	ET_LOG("et%d: chiprxquota", ch->etc->unit, 0);
+
+	rxcnt = 0;
+
+	while ((quota > 0) && ((pkt = dma_rx(ch->di)) != NULL)) {
+		addr = PKTDATA(ch->osh, pkt);
+#if !defined(_CFE_)
+		bcm_prefetch_32B(addr + 32, 1);
+#endif /* _CFE_ */
+		rxpkts[rxcnt] = pkt;
+		rxcnt++;
+		quota--;
+	}
+
+	if (rxcnt < quota) { /* ring is "possibly" empty, enable et interrupts */
+		ch->intstatus &= ~I_RI;
+	}
+
+	return rxcnt; /* rxpkts[] has rxcnt number of pkts to be processed */
+}
+
+
+static void BCMFASTPATH
+chiprxlazy(ch_t *ch)
+{
+	uint reg_val = ((ch->etc->rxlazy_timeout & IRL_TO_MASK) |
+	                (ch->etc->rxlazy_framecnt << IRL_FC_SHIFT));
+	W_REG(ch->osh, &ch->regs->intrecvlazy, reg_val);
+}
+
+/* reclaim completed dma receive descriptors and packets */
+static void
+chiprxreclaim(struct bcm4xxx *ch)
+{
+	ET_TRACE(("et%d: chiprxreclaim\n", ch->etc->unit));
+	dma_rxreclaim(ch->di);
+	ch->intstatus &= ~I_RI;
+}
+
+/* allocate and post dma receive buffers */
+static void BCMFASTPATH
+chiprxfill(struct bcm4xxx *ch)
+{
+	ET_TRACE(("et%d: chiprxfill\n", ch->etc->unit));
+	ET_LOG("et%d: chiprx", ch->etc->unit, 0);
+	dma_rxfill(ch->di);
+}
+
+/* get current and pending interrupt events */
+static int BCMFASTPATH
+chipgetintrevents(struct bcm4xxx *ch, bool in_isr)
+{
+	bcmenetregs_t *regs;
+	uint32 intstatus;
+	int events;
+
+	regs = ch->regs;
+	events = 0;
+
+	/* read the interrupt status register */
+	intstatus = R_REG(ch->osh, &regs->intstatus);
+
+	/* defer unsolicited interrupts */
+	intstatus &= (in_isr ? ch->intmask : DEF_INTMASK);
+
+	/* clear non-error interrupt conditions */
+	if (intstatus != 0) {
+		W_REG(ch->osh, &regs->intstatus, intstatus);
+		events = INTR_NEW;
+	}
+
+	/* or new bits into persistent intstatus */
+	intstatus = (ch->intstatus |= intstatus);
+
+	/* return if no events */
+	if (intstatus == 0)
+		return (0);
+
+	/* convert chip-specific intstatus bits into generic intr event bits */
+	if (intstatus & I_RI)
+		events |= INTR_RX;
+	if (intstatus & I_XI)
+		events |= INTR_TX;
+	if (intstatus & I_ERRORS)
+		events |= INTR_ERROR;
+	if (intstatus & I_TO)
+		events |= INTR_TO;
+
+	return (events);
+}
+
+/* enable chip interrupts */
+static void BCMFASTPATH
+chipintrson(struct bcm4xxx *ch)
+{
+	ch->intmask = DEF_INTMASK;
+	W_REG(ch->osh, &ch->regs->intmask, ch->intmask);
+}
+
+/* disable chip interrupts */
+static void BCMFASTPATH
+chipintrsoff(struct bcm4xxx *ch)
+{
+	W_REG(ch->osh, &ch->regs->intmask, 0);
+	(void) R_REG(ch->osh, &ch->regs->intmask);	/* sync readback */
+	ch->intmask = 0;
+}
+
+/* return true of caller should re-initialize, otherwise false */
+static bool BCMFASTPATH
+chiperrors(struct bcm4xxx *ch)
+{
+	uint32 intstatus;
+	etc_info_t *etc;
+
+	etc = ch->etc;
+
+	intstatus = ch->intstatus;
+	ch->intstatus &= ~(I_ERRORS);
+
+	ET_TRACE(("et%d: chiperrors: intstatus 0x%x\n", etc->unit, intstatus));
+
+	if (intstatus & I_PC) {
+		ET_ERROR(("et%d: descriptor error\n", etc->unit));
+		etc->dmade++;
+	}
+
+	if (intstatus & I_PD) {
+		ET_ERROR(("et%d: data error\n", etc->unit));
+		etc->dmada++;
+	}
+
+	if (intstatus & I_DE) {
+		ET_ERROR(("et%d: descriptor protocol error\n", etc->unit));
+		etc->dmape++;
+	}
+	/* NOTE : this ie NOT an error. It becomes an error only
+	 * when the rx fifo overflows
+	 */
+	if (intstatus & I_RU) {
+		ET_ERROR(("et%d: receive descriptor underflow\n", etc->unit));
+		etc->rxdmauflo++;
+	}
+
+	if (intstatus & I_RO) {
+		ET_ERROR(("et%d: receive fifo overflow\n", etc->unit));
+		etc->rxoflo++;
+	}
+
+	if (intstatus & I_XU) {
+		ET_ERROR(("et%d: transmit fifo underflow\n", etc->unit));
+		etc->txuflo++;
+	}
+	/* if overflows or decriptors underflow, don't report it
+	 * as an error and  provoque a reset
+	 */
+	if (intstatus & ~(I_RU) & I_ERRORS)
+		return (TRUE);
+	return FALSE;
+}
+
+static void
+chipwrcam(struct bcm4xxx *ch, struct ether_addr *ea, uint camindex)
+{
+	uint32 w;
+
+	ASSERT((R_REG(ch->osh, &ch->regs->camcontrol) & (CC_CB | CC_CE)) == 0);
+
+	w = (ea->octet[2] << 24) | (ea->octet[3] << 16) | (ea->octet[4] << 8)
+		| ea->octet[5];
+	W_REG(ch->osh, &ch->regs->camdatalo, w);
+	w = CD_V | (ea->octet[0] << 8) | ea->octet[1];
+	W_REG(ch->osh, &ch->regs->camdatahi, w);
+	W_REG(ch->osh, &ch->regs->camcontrol, ((camindex << CC_INDEX_SHIFT) | CC_WR));
+
+	/* spin until done */
+	SPINWAIT((R_REG(ch->osh, &ch->regs->camcontrol) & CC_CB), 1000);
+
+	/*
+	 * This assertion is usually caused by the phy not providing a clock
+	 * to the bottom portion of the mac..
+	 */
+	ASSERT((R_REG(ch->osh, &ch->regs->camcontrol) & CC_CB) == 0);
+}
+
+static void
+chipstatsupd(struct bcm4xxx *ch)
+{
+	etc_info_t *etc;
+	bcmenetregs_t *regs;
+	bcmenetmib_t *m;
+
+	etc = ch->etc;
+	regs = ch->regs;
+	m = &ch->mib;
+
+	/*
+	 * mib counters are clear-on-read.
+	 * Don't bother using the pkt and octet counters since they are only
+	 * 16bits and wrap too quickly to be useful.
+	 */
+	m->tx_broadcast_pkts += R_REG(ch->osh, &regs->mib.tx_broadcast_pkts);
+	m->tx_multicast_pkts += R_REG(ch->osh, &regs->mib.tx_multicast_pkts);
+	m->tx_len_64 += R_REG(ch->osh, &regs->mib.tx_len_64);
+	m->tx_len_65_to_127 += R_REG(ch->osh, &regs->mib.tx_len_65_to_127);
+	m->tx_len_128_to_255 += R_REG(ch->osh, &regs->mib.tx_len_128_to_255);
+	m->tx_len_256_to_511 += R_REG(ch->osh, &regs->mib.tx_len_256_to_511);
+	m->tx_len_512_to_1023 += R_REG(ch->osh, &regs->mib.tx_len_512_to_1023);
+	m->tx_len_1024_to_max += R_REG(ch->osh, &regs->mib.tx_len_1024_to_max);
+	m->tx_jabber_pkts += R_REG(ch->osh, &regs->mib.tx_jabber_pkts);
+	m->tx_oversize_pkts += R_REG(ch->osh, &regs->mib.tx_oversize_pkts);
+	m->tx_fragment_pkts += R_REG(ch->osh, &regs->mib.tx_fragment_pkts);
+	m->tx_underruns += R_REG(ch->osh, &regs->mib.tx_underruns);
+	m->tx_total_cols += R_REG(ch->osh, &regs->mib.tx_total_cols);
+	m->tx_single_cols += R_REG(ch->osh, &regs->mib.tx_single_cols);
+	m->tx_multiple_cols += R_REG(ch->osh, &regs->mib.tx_multiple_cols);
+	m->tx_excessive_cols += R_REG(ch->osh, &regs->mib.tx_excessive_cols);
+	m->tx_late_cols += R_REG(ch->osh, &regs->mib.tx_late_cols);
+	m->tx_defered += R_REG(ch->osh, &regs->mib.tx_defered);
+	m->tx_carrier_lost += R_REG(ch->osh, &regs->mib.tx_carrier_lost);
+	m->tx_pause_pkts += R_REG(ch->osh, &regs->mib.tx_pause_pkts);
+	m->rx_broadcast_pkts += R_REG(ch->osh, &regs->mib.rx_broadcast_pkts);
+	m->rx_multicast_pkts += R_REG(ch->osh, &regs->mib.rx_multicast_pkts);
+	m->rx_len_64 += R_REG(ch->osh, &regs->mib.rx_len_64);
+	m->rx_len_65_to_127 += R_REG(ch->osh, &regs->mib.rx_len_65_to_127);
+	m->rx_len_128_to_255 += R_REG(ch->osh, &regs->mib.rx_len_128_to_255);
+	m->rx_len_256_to_511 += R_REG(ch->osh, &regs->mib.rx_len_256_to_511);
+	m->rx_len_512_to_1023 += R_REG(ch->osh, &regs->mib.rx_len_512_to_1023);
+	m->rx_len_1024_to_max += R_REG(ch->osh, &regs->mib.rx_len_1024_to_max);
+	m->rx_jabber_pkts += R_REG(ch->osh, &regs->mib.rx_jabber_pkts);
+	m->rx_oversize_pkts += R_REG(ch->osh, &regs->mib.rx_oversize_pkts);
+	m->rx_fragment_pkts += R_REG(ch->osh, &regs->mib.rx_fragment_pkts);
+	m->rx_missed_pkts += R_REG(ch->osh, &regs->mib.rx_missed_pkts);
+	m->rx_crc_align_errs += R_REG(ch->osh, &regs->mib.rx_crc_align_errs);
+	m->rx_undersize += R_REG(ch->osh, &regs->mib.rx_undersize);
+	m->rx_crc_errs += R_REG(ch->osh, &regs->mib.rx_crc_errs);
+	m->rx_align_errs += R_REG(ch->osh, &regs->mib.rx_align_errs);
+	m->rx_symbol_errs += R_REG(ch->osh, &regs->mib.rx_symbol_errs);
+	m->rx_pause_pkts += R_REG(ch->osh, &regs->mib.rx_pause_pkts);
+	m->rx_nonpause_pkts += R_REG(ch->osh, &regs->mib.rx_nonpause_pkts);
+
+	/*
+	 * Aggregate transmit and receive errors that probably resulted
+	 * in the loss of a frame are computed on the fly.
+	 *
+	 * We seem to get lots of tx_carrier_lost errors when flipping
+	 * speed modes so don't count these as tx errors.
+	 *
+	 * Arbitrarily lump the non-specific dma errors as tx errors.
+	 */
+	etc->rxgiants = ch->di->rxgiants;
+	etc->txerror = m->tx_jabber_pkts + m->tx_oversize_pkts
+		+ m->tx_underruns + m->tx_excessive_cols
+		+ m->tx_late_cols + etc->txnobuf + etc->dmade
+		+ etc->dmada + etc->dmape + etc->txuflo;
+	etc->rxerror = m->rx_jabber_pkts + m->rx_oversize_pkts
+		+ m->rx_missed_pkts + m->rx_crc_align_errs
+		+ m->rx_undersize + m->rx_crc_errs
+		+ m->rx_align_errs + m->rx_symbol_errs
+		+ etc->rxnobuf + etc->rxdmauflo + etc->rxoflo + etc->rxbadlen + etc->rxgiants;
+}
+
+static void
+chipdumpmib(ch_t *ch, struct bcmstrbuf *b, bool clear)
+{
+	bcmenetmib_t *m;
+
+	m = &ch->mib;
+
+	if (clear) {
+		bzero((char *)m, sizeof(bcmenetmib_t));
+		return;
+	}
+
+	bcm_bprintf(b, "tx_broadcast_pkts %d tx_multicast_pkts %d tx_jabber_pkts %d "
+	               "tx_oversize_pkts %d\n",
+	               m->tx_broadcast_pkts, m->tx_multicast_pkts,
+	               m->tx_jabber_pkts,
+	               m->tx_oversize_pkts);
+	bcm_bprintf(b, "tx_fragment_pkts %d tx_underruns %d\n",
+	               m->tx_fragment_pkts, m->tx_underruns);
+	bcm_bprintf(b, "tx_total_cols %d tx_single_cols %d tx_multiple_cols %d "
+	               "tx_excessive_cols %d\n",
+	               m->tx_total_cols, m->tx_single_cols, m->tx_multiple_cols,
+	               m->tx_excessive_cols);
+	bcm_bprintf(b, "tx_late_cols %d tx_defered %d tx_carrier_lost %d tx_pause_pkts %d\n",
+	               m->tx_late_cols, m->tx_defered, m->tx_carrier_lost,
+	               m->tx_pause_pkts);
+
+	/* receive stat counters */
+	/* hardware mib pkt and octet counters wrap too quickly to be useful */
+	bcm_bprintf(b, "rx_broadcast_pkts %d rx_multicast_pkts %d rx_jabber_pkts %d "
+	               "rx_oversize_pkts %d\n",
+	               m->rx_broadcast_pkts, m->rx_multicast_pkts,
+	               m->rx_jabber_pkts, m->rx_oversize_pkts);
+	bcm_bprintf(b, "rx_fragment_pkts %d rx_missed_pkts %d rx_crc_align_errs %d "
+	               "rx_undersize %d\n",
+	               m->rx_fragment_pkts, m->rx_missed_pkts,
+	               m->rx_crc_align_errs, m->rx_undersize);
+	bcm_bprintf(b, "rx_crc_errs %d rx_align_errs %d rx_symbol_errs %d\n",
+	               m->rx_crc_errs, m->rx_align_errs, m->rx_symbol_errs);
+	bcm_bprintf(b, "rx_pause_pkts %d rx_nonpause_pkts %d\n",
+	               m->rx_pause_pkts, m->rx_nonpause_pkts);
+}
+
+static void
+chipenablepme(struct bcm4xxx *ch)
+{
+	bcmenetregs_t *regs;
+
+	regs = ch->regs;
+
+	/* enable chip wakeup pattern matching */
+	OR_REG(ch->osh, &regs->devcontrol, DC_PM);
+
+	/* enable sonics bus PME */
+	si_core_cflags(ch->sih, SICF_PME_EN, SICF_PME_EN);
+}
+
+static void
+chipdisablepme(struct bcm4xxx *ch)
+{
+	bcmenetregs_t *regs;
+
+	regs = ch->regs;
+
+	AND_REG(ch->osh, &regs->devcontrol, ~DC_PM);
+	si_core_cflags(ch->sih, SICF_PME_EN, 0);
+}
+
+static void
+chipduplexupd(struct bcm4xxx *ch)
+{
+	uint32 txcontrol;
+
+	txcontrol = R_REG(ch->osh, &ch->regs->txcontrol);
+	if (ch->etc->duplex && !(txcontrol & EXC_FD))
+		OR_REG(ch->osh, &ch->regs->txcontrol, EXC_FD);
+	else if (!ch->etc->duplex && (txcontrol & EXC_FD))
+		AND_REG(ch->osh, &ch->regs->txcontrol, ~EXC_FD);
+}
+
+static uint16
+chipphyrd(struct bcm4xxx *ch, uint phyaddr, uint reg)
+{
+	bcmenetregs_t *regs;
+
+	ASSERT(phyaddr < MAXEPHY);
+
+	/*
+	 * BCM5222 dualphy shared mdio contortion.
+	 * remote phy: another emac controls our phy.
+	 */
+	if (ch->etc->mdcport != ch->etc->coreunit) {
+		if (ch->etphy == NULL) {
+			ch->etphy = et_phyfind(ch->et, ch->etc->mdcport);
+
+			/* first time reset */
+			if (ch->etphy)
+				chipphyreset(ch, ch->etc->phyaddr);
+		}
+		if (ch->etphy)
+			return (et_phyrd(ch->etphy, phyaddr, reg));
+		else
+			return (0xffff);
+	}
+
+	/* local phy: our emac controls our phy */
+
+	regs = ch->regs;
+
+	/* clear mii_int */
+	W_REG(ch->osh, &regs->emacintstatus, EI_MII);
+
+	/* issue the read */
+	W_REG(ch->osh, &regs->mdiodata,  (MD_SB_START | MD_OP_READ | (phyaddr << MD_PMD_SHIFT)
+		| (reg << MD_RA_SHIFT) | MD_TA_VALID));
+
+	/* wait for it to complete */
+	SPINWAIT(((R_REG(ch->osh, &regs->emacintstatus) & EI_MII) == 0), 100);
+	if ((R_REG(ch->osh, &regs->emacintstatus) & EI_MII) == 0) {
+		ET_ERROR(("et%d: chipphyrd: did not complete\n", ch->etc->unit));
+	}
+
+	return (R_REG(ch->osh, &regs->mdiodata) & MD_DATA_MASK);
+}
+
+static void
+chipphywr(struct bcm4xxx *ch, uint phyaddr, uint reg, uint16 v)
+{
+	bcmenetregs_t *regs;
+
+	ASSERT(phyaddr < MAXEPHY);
+
+	/*
+	 * BCM5222 dualphy shared mdio contortion.
+	 * remote phy: another emac controls our phy.
+	 */
+	if (ch->etc->mdcport != ch->etc->coreunit) {
+		if (ch->etphy == NULL)
+			ch->etphy = et_phyfind(ch->et, ch->etc->mdcport);
+		if (ch->etphy)
+			et_phywr(ch->etphy, phyaddr, reg, v);
+		return;
+	}
+
+	/* local phy: our emac controls our phy */
+
+	regs = ch->regs;
+
+	/* clear mii_int */
+	W_REG(ch->osh, &regs->emacintstatus, EI_MII);
+	ASSERT((R_REG(ch->osh, &regs->emacintstatus) & EI_MII) == 0);
+
+	/* issue the write */
+	W_REG(ch->osh, &regs->mdiodata,  (MD_SB_START | MD_OP_WRITE | (phyaddr << MD_PMD_SHIFT)
+		| (reg << MD_RA_SHIFT) | MD_TA_VALID | v));
+
+	/* wait for it to complete */
+	SPINWAIT(((R_REG(ch->osh, &regs->emacintstatus) & EI_MII) == 0), 100);
+	if ((R_REG(ch->osh, &regs->emacintstatus) & EI_MII) == 0) {
+		ET_ERROR(("et%d: chipphywr: did not complete\n", ch->etc->unit));
+	}
+}
+
+static void
+chipphyor(struct bcm4xxx *ch, uint phyaddr, uint reg, uint16 v)
+{
+	uint16 tmp;
+
+	tmp = chipphyrd(ch, phyaddr, reg);
+	tmp |= v;
+	chipphywr(ch, phyaddr, reg, tmp);
+}
+
+static void
+chipphyand(struct bcm4xxx *ch, uint phyaddr, uint reg, uint16 v)
+{
+	uint16 tmp;
+
+	tmp = chipphyrd(ch, phyaddr, reg);
+	tmp &= v;
+	chipphywr(ch, phyaddr, reg, tmp);
+}
+
+static void
+chipconfigtimer(struct bcm4xxx *ch, uint microsecs)
+{
+	ASSERT(ch->etc->bp_ticks_usec != 0);
+
+	/* Enable general purpose timer in periodic mode */
+	W_REG(ch->osh, &ch->regs->gptimer, microsecs * ch->etc->bp_ticks_usec);
+}
+
+static void
+chipphyreset(struct bcm4xxx *ch, uint phyaddr)
+{
+	ASSERT(phyaddr < MAXEPHY);
+
+	if (phyaddr == EPHY_NOREG)
+		return;
+
+	chipphywr(ch, phyaddr, 0, CTL_RESET);
+	OSL_DELAY(100);
+	if (chipphyrd(ch, phyaddr, 0) & CTL_RESET) {
+		ET_ERROR(("et%d: chipphyreset: reset not complete\n", ch->etc->unit));
+	}
+
+	chipphyinit(ch, phyaddr);
+}
+
+static void
+chipphyinit(struct bcm4xxx *ch, uint phyaddr)
+{
+	uint	phyid = 0;
+
+	/* enable activity led */
+	chipphyand(ch, phyaddr, 26, 0x7fff);
+
+	/* enable traffic meter led mode */
+	chipphyor(ch, phyaddr, 27, (1 << 6));
+
+	phyid = chipphyrd(ch, phyaddr, 0x2);
+	phyid |=  chipphyrd(ch, phyaddr, 0x3) << 16;
+	if (phyid == 0x55210022) {
+		chipphywr(ch, phyaddr, 30, (uint16) (chipphyrd(ch, phyaddr, 30) | 0x3000));
+		chipphywr(ch, phyaddr, 22, (uint16) (chipphyrd(ch, phyaddr, 22) & 0xffdf));
+	}
+}
+
+static void
+chipphyforce(struct bcm4xxx *ch, uint phyaddr)
+{
+	etc_info_t *etc;
+	uint16 ctl;
+
+	ASSERT(phyaddr < MAXEPHY);
+
+	if (phyaddr == EPHY_NOREG)
+		return;
+
+	etc = ch->etc;
+
+	if (etc->forcespeed == ET_AUTO)
+		return;
+
+	ctl = chipphyrd(ch, phyaddr, 0);
+	ctl &= ~(CTL_SPEED | CTL_ANENAB | CTL_DUPLEX);
+
+	switch (etc->forcespeed) {
+	case ET_10HALF:
+		break;
+
+	case ET_10FULL:
+		ctl |= CTL_DUPLEX;
+		break;
+
+	case ET_100HALF:
+		ctl |= CTL_SPEED;
+		break;
+
+	case ET_100FULL:
+		ctl |= (CTL_SPEED | CTL_DUPLEX);
+		break;
+	}
+
+	chipphywr(ch, phyaddr, 0, ctl);
+}
+
+/* set selected capability bits in autonegotiation advertisement */
+static void
+chipphyadvertise(struct bcm4xxx *ch, uint phyaddr)
+{
+	etc_info_t *etc;
+	uint16 adv;
+
+	ASSERT(phyaddr < MAXEPHY);
+
+	if (phyaddr == EPHY_NOREG)
+		return;
+
+	etc = ch->etc;
+
+	if ((etc->forcespeed != ET_AUTO) || !etc->needautoneg)
+		return;
+
+	ASSERT(etc->advertise);
+
+	/* reset our advertised capabilitity bits */
+	adv = chipphyrd(ch, phyaddr, 4);
+	adv &= ~(ADV_100FULL | ADV_100HALF | ADV_10FULL | ADV_10HALF);
+	adv |= etc->advertise;
+	chipphywr(ch, phyaddr, 4, adv);
+
+	/* restart autonegotiation */
+	chipphyor(ch, phyaddr, 0, CTL_RESTART);
+
+	etc->needautoneg = FALSE;
+}
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_adm.c b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_adm.c
new file mode 100644
index 0000000000..8b0f7a1f03
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_adm.c
@@ -0,0 +1,548 @@
+/*
+ * ADMtek switch setup functions
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: etc_adm.c 286404 2011-09-27 19:29:08Z $
+ */
+
+#include <et_cfg.h>
+#include <typedefs.h>
+#include <osl.h>
+#include <bcmutils.h>
+#include <siutils.h>
+#include <bcmendian.h>
+#include <bcmparams.h>
+#include <etc_adm.h>
+#include <et_dbg.h>
+
+/* Private state per ADM switch */
+struct adm_info_s {
+	si_t *sih;			/* SiliconBackplane handle */
+	void *vars;			/* variables handle */
+	uint coreidx;			/* Current core index */
+	uint32 eecs, eesk, eedi;	/* GPIO mapping */
+};
+
+/* Minimum timing constants */
+#define EECK_EDGE_TIME	3	/* 3us - max(adm 2.5us, 93c 1us) */
+#define EEDI_SETUP_TIME	1	/* 1us - max(adm 10ns, 93c 400ns) */
+#define EECS_SETUP_TIME	1	/* 1us - max(adm no, 93c 200ns) */
+
+/* Allocate private resource */
+adm_info_t *
+adm_attach(si_t *sih, char *vars)
+{
+	adm_info_t *adm;
+	int gpio;
+
+	/* Allocate private data */
+	if (!(adm = MALLOC(si_osh(sih), sizeof(adm_info_t)))) {
+		ET_ERROR(("adm_attach: out of memory, malloc %d bytes", MALLOCED(si_osh(sih))));
+		return NULL;
+	}
+	bzero((char *) adm, sizeof(adm_info_t));
+	adm->sih = sih;
+	adm->vars = vars;
+
+	/* Init GPIO mapping. Default GPIO: 2, 3, 4 */
+	gpio = getgpiopin(vars, "adm_eecs", 2);
+	ET_ERROR(("adm_attach: got %d as adm_eecs", gpio));
+	if (gpio == GPIO_PIN_NOTDEFINED) {
+		ET_ERROR(("adm_attach: adm_eecs gpio fail: GPIO 2 in use"));
+		goto error;
+	}
+	adm->eecs = 1 << gpio;
+
+	gpio = getgpiopin(vars, "adm_eesk", 3);
+	ET_ERROR(("adm_attach: got %d as adm_eesk", gpio));
+	if (gpio == GPIO_PIN_NOTDEFINED) {
+		ET_ERROR(("adm_attach: adm_eesk gpio fail: GPIO 3 in use"));
+		goto error;
+	}
+	adm->eesk = 1 << gpio;
+
+	gpio = getgpiopin(vars, "adm_eedi", 4);
+	ET_ERROR(("adm_attach: got %d as adm_eedi", gpio));
+	if (gpio == GPIO_PIN_NOTDEFINED) {
+		ET_ERROR(("adm_attach: adm_eedi gpio fail: GPIO 4 in use"));
+		goto error;
+	}
+	adm->eedi = 1 << gpio;
+
+	return adm;
+
+error:
+	adm_detach(adm);
+	return NULL;
+}
+
+/* Release private resource */
+void
+adm_detach(adm_info_t *adm)
+{
+	/* Free private data */
+	MFREE(si_osh(adm->sih), adm, sizeof(adm_info_t));
+}
+
+/*
+* The following local functions provide chip access control. The
+* general rules in writing these supporting routines are:
+*
+*   1. EECS should be kept low after each routine.
+*   2. EESK should be kept low after each routine.
+*/
+/* Enable register access to the chip */
+static void
+adm_enable(adm_info_t *adm)
+{
+	void *regs;
+
+	/* Save current core index */
+	adm->coreidx = si_coreidx(adm->sih);
+
+	/* Switch to GPIO core for faster access */
+	regs = si_gpiosetcore(adm->sih);
+	ASSERT(regs);
+}
+
+/* Disable register access to the chip */
+static void
+adm_disable(adm_info_t *adm)
+{
+	/* Switch back to original core */
+	si_setcoreidx(adm->sih, adm->coreidx);
+}
+
+/* Enable outputs with specified value to the chip */
+static void
+adm_enout(adm_info_t *adm, uint32 pins, uint val)
+{
+	/* Prepare GPIO output value */
+	si_gpioout(adm->sih, pins, val, GPIO_DRV_PRIORITY);
+	/* Enable GPIO outputs */
+	si_gpioouten(adm->sih, pins, pins, GPIO_DRV_PRIORITY);
+	OSL_DELAY(EECK_EDGE_TIME);
+}
+
+/* Disable outputs to the chip */
+static void
+adm_disout(adm_info_t *adm, uint32 pins)
+{
+	/* Disable GPIO outputs */
+	si_gpioouten(adm->sih, pins, 0, GPIO_DRV_PRIORITY);
+	OSL_DELAY(EECK_EDGE_TIME);
+}
+
+/* Advance clock(s) */
+static void
+adm_adclk(adm_info_t *adm, int clocks)
+{
+	int i;
+	for (i = 0; i < clocks; i ++) {
+		/* Clock high */
+		si_gpioout(adm->sih, adm->eesk, adm->eesk, GPIO_DRV_PRIORITY);
+		OSL_DELAY(EECK_EDGE_TIME);
+		/* Clock low */
+		si_gpioout(adm->sih, adm->eesk, 0, GPIO_DRV_PRIORITY);
+		OSL_DELAY(EECK_EDGE_TIME);
+	}
+}
+
+/* Write a bit stream to the chip */
+static void
+adm_write(adm_info_t *adm, int cs, uint8 *buf, uint bits)
+{
+	uint i, len = (bits + 7) / 8;
+	uint8 mask;
+
+	/* CS high/low */
+	if (cs)
+		si_gpioout(adm->sih, adm->eecs, adm->eecs, GPIO_DRV_PRIORITY);
+	else
+		si_gpioout(adm->sih, adm->eecs, 0, GPIO_DRV_PRIORITY);
+	OSL_DELAY(EECK_EDGE_TIME);
+
+	/* Byte assemble from MSB to LSB */
+	for (i = 0; i < len; i++) {
+		/* Bit bang from MSB to LSB */
+		for (mask = 0x80; mask && bits > 0; mask >>= 1, bits --) {
+			/* Clock low */
+			si_gpioout(adm->sih, adm->eesk, 0, GPIO_DRV_PRIORITY);
+			OSL_DELAY(EECK_EDGE_TIME);
+
+			/* Output on rising edge */
+			if (mask & buf[i])
+				si_gpioout(adm->sih, adm->eedi, adm->eedi, GPIO_DRV_PRIORITY);
+			else
+				si_gpioout(adm->sih, adm->eedi, 0, GPIO_DRV_PRIORITY);
+			OSL_DELAY(EEDI_SETUP_TIME);
+
+			/* Clock high */
+			si_gpioout(adm->sih, adm->eesk, adm->eesk, GPIO_DRV_PRIORITY);
+			OSL_DELAY(EECK_EDGE_TIME);
+		}
+	}
+
+	/* Clock low */
+	si_gpioout(adm->sih, adm->eesk, 0, GPIO_DRV_PRIORITY);
+	OSL_DELAY(EECK_EDGE_TIME);
+
+	/* CS low */
+	if (cs)
+		si_gpioout(adm->sih, adm->eecs, 0, GPIO_DRV_PRIORITY);
+}
+
+/* Handy macros for writing fixed length values */
+#define adm_write8(adm, cs, b) { uint8 val = (uint8) (b); adm_write(adm, cs, &val, sizeof(val)*8); }
+#define adm_write16(adm, cs, w) { uint16 val = hton16(w); \
+		adm_write(adm, cs, (uint8 *)&val, sizeof(val)*8); }
+#define adm_write32(adm, cs, i) { uint32 val = hton32(i); \
+		adm_write(adm, cs, (uint8 *)&val, sizeof(val)*8); }
+
+/* Write chip configuration register */
+/* Follow 93c66 timing and chip's min EEPROM timing requirement */
+static void
+adm_wreg(adm_info_t *adm, uint8 addr, uint16 val)
+{
+	/* cmd(27bits): sb(1) + opc(01) + addr(bbbbbbbb) + data(bbbbbbbbbbbbbbbb) */
+	uint8 bits[4] = {
+		(0x05 << 5) | (addr >> 3),
+		(addr << 5) | (uint8)(val >> 11),
+		(uint8)(val >> 3),
+		(uint8)(val << 5)
+	};
+
+	ET_TRACE(("adm_wreg: addr %02x val %04x (%02X%02X%02X%02X)\n",
+		addr, val, bits[0], bits[1], bits[2], bits[3]));
+
+	/* Enable GPIO outputs with all pins to 0 */
+	adm_enout(adm, adm->eecs | adm->eesk | adm->eedi, 0);
+
+	/* Write cmd. Total 27 bits */
+	adm_write(adm, 1, bits, 27);
+
+	/* Extra clock(s) required per datasheet */
+	adm_adclk(adm, 2);
+
+	/* Disable GPIO outputs */
+	adm_disout(adm, adm->eecs | adm->eesk | adm->eedi);
+}
+
+/* Configure the chip based on nvram settings */
+int
+adm_config_vlan(adm_info_t *adm)
+{
+	/* Port configuration */
+	struct {
+		uint8 addr;	/* port configuration register */
+		uint16 vlan;	/* vlan port mapping */
+		uint8 tagged;	/* output tagging */
+		uint8 cpu;	/* cpu port? 1 - yes, 0 - no */
+		uint16 pvid;	/* cpu port pvid */
+	} port_cfg_tab[] = {
+		{1, 1<<0, 0, 0, -1},
+		{3, 1<<2, 0, 0, -1},
+		{5, 1<<4, 0, 0, -1},
+		{7, 1<<6, 0, 0, -1},
+		{8, 1<<7, 0, 0, -1},
+#if defined(PMON) || defined(_CFE_)
+		{9, 1<<8, 0, 1, -1}	/* no output tagging for pmon/cfe */
+#else	/* #if defined(PMON) || defined(CFE) */
+		{9, 1<<8, 1, 1, -1}	/* output tagging for linux... */
+#endif	/* #if defined(PMON) || defined(CFE) */
+	};
+	/* Vlan ports bitmap */
+	struct {
+		uint8 addr;	/* vlan port map register */
+	} vlan_cfg_tab[] = {
+		{0x13},
+		{0x14},
+		{0x15},
+		{0x16},
+		{0x17},
+		{0x18},
+		{0x19},
+		{0x1a},
+		{0x1b},
+		{0x1c},
+		{0x1d},
+		{0x1e},
+		{0x1f},
+		{0x20},
+		{0x21},
+		{0x22}
+	};
+	uint16 vid, i;
+
+	/* Enable access to the switch */
+	adm_enable(adm);
+
+	/* vlan mode select register (0x11): vlan on, mac clone */
+	adm_wreg(adm, 0x11, 0xff30);
+
+	/* vlan port group: port configuration, vlan port map */
+	/* VLAN ID is equal to vlan number, max 16 vlans */
+	for (vid = 0; vid < 16; vid ++) {
+		char port[] = "XXXX", *ports, *next, *cur;
+		char vlanports[] = "vlanXXXXports";
+		uint16 vlan_map = 0;
+		int port_num, len;
+		uint16 port_cfg;
+
+		/* no members if VLAN id is out of limitation */
+		if (vid > VLAN_MAXVID)
+			goto vlan_setup;
+
+		/* get nvram port settings */
+		sprintf(vlanports, "vlan%dports", vid);
+		ports = getvar(adm->vars, vlanports);
+
+		/* disable this vlan if not defined */
+		if (!ports)
+			goto vlan_setup;
+
+		/*
+		* port configuration register (0x01, 0x03, 0x05, 0x07, 0x08, 0x09):
+		*   input/output tagging, pvid, auto mdix, auto negotiation, ...
+		* cpu port needs special handing to support pmon/cfe/linux...
+		*/
+		for (cur = ports; cur; cur = next) {
+			/* tokenize the port list */
+			while (*cur == ' ')
+				cur ++;
+			next = bcmstrstr(cur, " ");
+			len = next ? next - cur : strlen(cur);
+			if (!len)
+				break;
+			if (len > sizeof(port) - 1)
+				len = sizeof(port) - 1;
+			strncpy(port, cur, len);
+			port[len] = 0;
+
+			/* make sure port # is within the range */
+			port_num = bcm_atoi(port);
+			if (port_num >= sizeof(port_cfg_tab) / sizeof(port_cfg_tab[0])) {
+				ET_ERROR(("port number %d is out of range\n", port_num));
+				continue;
+			}
+
+			/* build vlan port map */
+			vlan_map |= port_cfg_tab[port_num].vlan;
+
+			/* cpu port needs special care */
+			if (port_cfg_tab[port_num].cpu) {
+				/* cpu port's default VLAN is lan! */
+				if (strchr(port, '*'))
+					port_cfg_tab[port_num].pvid = vid;
+				/* will be done later */
+				continue;
+			}
+
+			/* configure port */
+			port_cfg = 0x8000 |	/* auto mdix */
+				(vid << 10) | 	/* pvid */
+				0x000f;		/* full duplex, 100Mbps, auto neg, flow ctrl */
+			adm_wreg(adm, port_cfg_tab[port_num].addr, port_cfg);
+		}
+vlan_setup:
+		/* vlan port map register (0x13 - 0x22) */
+		adm_wreg(adm, vlan_cfg_tab[vid].addr, vlan_map);
+	}
+
+	/* cpu port config: auto mdix, pvid, output tagging, ... */
+	for (i = 0; i < sizeof(port_cfg_tab)/sizeof(port_cfg_tab[0]); i ++) {
+		uint16 tagged, pvid;
+		uint16 port_cfg;
+
+		/* cpu port only */
+		if (port_cfg_tab[i].cpu == 0 || port_cfg_tab[i].pvid == 0xffff)
+			continue;
+
+		/* configure port */
+		tagged = port_cfg_tab[i].tagged ? 1 : 0;
+		pvid = port_cfg_tab[i].pvid;
+		port_cfg = 0x8000 |	/* auto mdix */
+			(pvid << 10) | 	/* pvid */
+			(tagged << 4) |	/* output tagging */
+			0x000f;		/* full duplex, 100Mbps, auto neg, flow ctrl */
+		adm_wreg(adm, port_cfg_tab[i].addr, port_cfg);
+	}
+
+	/* Disable access to the switch */
+	adm_disable(adm);
+
+	return 0;
+}
+
+/*
+* Enable the chip with preset default configuration:
+*
+*  TP Auto MDIX (EESK/GPIO = 1)
+*  Single Color LED (EEDI/GPIO = 0)
+*  EEPROM Disable (H/W pull down)
+*/
+int
+adm_enable_device(adm_info_t *adm)
+{
+	uint32 rc;
+	int i;
+
+	/* Check nvram override existance */
+	if ((rc = getgpiopin(adm->vars, "adm_rc", GPIO_PIN_NOTDEFINED)) == GPIO_PIN_NOTDEFINED)
+		return 0;
+	rc = 1 << rc;
+
+	/* Enable access to the switch */
+	adm_enable(adm);
+	/*
+	* Reset sequence: RC high->low(100ms)->high(30ms)
+	*
+	* WAR: Certain boards don't have the correct power on
+	* reset logic therefore we must explicitly perform the
+	* sequece in software.
+	*/
+	/* Keep RC high for at least 20ms */
+	adm_enout(adm, rc, rc);
+	for (i = 0; i < 20; i ++)
+		OSL_DELAY(1000);
+	/* Keep RC low for at least 100ms */
+	adm_enout(adm, rc, 0);
+	for (i = 0; i < 100; i++)
+		OSL_DELAY(1000);
+	/* Set default configuration */
+	adm_enout(adm, adm->eesk | adm->eedi, adm->eesk);
+	/* Keep RC high for at least 30ms */
+	adm_enout(adm, rc, rc);
+	for (i = 0; i < 30; i++)
+		OSL_DELAY(1000);
+	/* Leave RC high and disable GPIO outputs */
+	adm_disout(adm, adm->eecs | adm->eesk | adm->eedi);
+	/* Disable access to the switch */
+	adm_disable(adm);
+	return 0;
+}
+
+#ifdef BCMDBG
+/* Read a bit stream from the chip */
+static void
+adm_read(adm_info_t *adm, int cs, uint32 pin, uint8 *buf, uint bits)
+{
+	uint i, len = (bits + 7) / 8;
+
+	/* CS high/low */
+	if (cs)
+		si_gpioout(adm->sih, adm->eecs, adm->eecs, GPIO_DRV_PRIORITY);
+	else
+		si_gpioout(adm->sih, adm->eecs, 0, GPIO_DRV_PRIORITY);
+	OSL_DELAY(EECK_EDGE_TIME);
+
+	/* Byte assemble from MSB to LSB */
+	for (i = 0; i < len; i ++) {
+		uint8 mask, byte = 0;
+		/* Bit bang from MSB to LSB */
+		for (mask = 0x80; mask && bits > 0; mask >>= 1, bits --) {
+			/* Clock high */
+			si_gpioout(adm->sih, adm->eesk, adm->eesk, GPIO_DRV_PRIORITY);
+			OSL_DELAY(EECK_EDGE_TIME);
+
+			/* Sample on rising edge */
+			if (si_gpioin(adm->sih) & pin)
+				byte |= mask;
+
+			/* Clock low */
+			si_gpioout(adm->sih, adm->eesk, 0, GPIO_DRV_PRIORITY);
+			OSL_DELAY(EECK_EDGE_TIME);
+		}
+		buf[i] = byte;
+	}
+
+	/* CS low */
+	if (cs)
+		si_gpioout(adm->sih, adm->eecs, 0, GPIO_DRV_PRIORITY);
+}
+
+/* Handy macros for reading fixed length values */
+#define adm_read8(adm, cs, pin, b) { uint8 val; \
+		adm_read(adm, cs, pin, &val, sizeof(val) * 8); *(b) = val; }
+#define adm_read16(adm, cs, pin, w) { uint16 val; \
+		adm_read(adm, cs, pin, (uint8 *)&val, sizeof(val) * 8); *(w) = ntoh16(val); }
+#define adm_read32(adm, cs, pin, i) { uint32 val; \
+		adm_read(adm, cs, pin, (uint8 *)&val, sizeof(val) * 8); *(i) = ntoh32(val); }
+
+/* Read counter/config register. table 0 - config registers, 1 - internal counters */
+/* Follow chip's SMI timing */
+static uint32
+adm_rreg(adm_info_t *adm, int addr, int table)
+{
+	/* Command: preamble(11) + start(01) + opcode(10) + table(b) +
+	* device(00) + register(bbbbbbb)
+	*/
+	uint16 cmd = (3 << 14) | (1 << 12) | (2 << 10) | (table << 9) | (0 << 7) | addr;
+	uint32 data;
+
+	/* Enable GPIO outputs */
+	adm_enout(adm, adm->eecs | adm->eesk | adm->eedi, 0);
+
+	/* Preamble: at lease 32 bit 1s */
+	adm_write32(adm, 0, 0xffffffff);
+
+	/* Command: 2 extra preamble bits plus 14 command bits */
+	adm_write16(adm, 0, cmd);
+
+	/* Z EEDI: the switch will drive it */
+	adm_disout(adm, adm->eedi);
+
+	/* Turn around: 1 bit */
+	adm_adclk(adm, 1);
+
+	/* Register value: 32 bits */
+	adm_read32(adm, 0, adm->eedi, &data);
+
+	/* Idle: at least 1 extra clock */
+	adm_adclk(adm, 2);
+
+	/* Disable GPIO outputs */
+	adm_disout(adm, adm->eecs | adm->eesk);
+
+	return data;
+}
+
+char*
+adm_dump_regs(adm_info_t *adm, char *buf)
+{
+	uint32 v;
+	int i;
+
+	/* enable access to the switch */
+	adm_enable(adm);
+
+	/* dump admtek switch registers */
+	buf += sprintf(buf, "admtek:\n");
+	for (i = 0; i <= 0x2d; i++) {
+		v = adm_rreg(adm, i, 0);
+		buf += sprintf(buf, "%04x ",
+			((i % 2) ? ((v >> 16) & 0xffff) :  (v & 0xffff)));
+		if ((i % 8) == 7)
+			buf += sprintf(buf, "\n");
+	}
+	buf += sprintf(buf, "\n");
+
+	/* disable access to the switch */
+	adm_disable(adm);
+
+	return (buf);
+}
+#endif /* BCMDBG */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_adm.h b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_adm.h
new file mode 100644
index 0000000000..c5cb3b156b
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_adm.h
@@ -0,0 +1,36 @@
+/*
+ * ADMtek switch setup functions
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: etc_adm.h 267700 2011-06-19 15:41:07Z $
+ */
+
+#ifndef _adm_h_
+#define _adm_h_
+
+/* forward declarations */
+typedef struct adm_info_s adm_info_t;
+
+/* interface prototypes */
+extern adm_info_t *adm_attach(si_t *sih, char *vars);
+extern void adm_detach(adm_info_t *adm);
+extern int adm_enable_device(adm_info_t *adm);
+extern int adm_config_vlan(adm_info_t *adm);
+#ifdef BCMDBG
+extern char *adm_dump_regs(adm_info_t *adm, char *buf);
+#endif
+
+#endif /* _adm_h_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_fa.c b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_fa.c
new file mode 100755
index 0000000000..5d30f1576c
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_fa.c
@@ -0,0 +1,1990 @@
+/*
+ *  Flow Accelerator setup functions
+ *
+ * Copyright (C) 2015, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: $
+ */
+#include <typedefs.h>
+#include <osl.h>
+#include <bcmdefs.h>
+#include <bcmdevs.h>
+#include <bcmendian.h>
+#include <siutils.h>
+#include <hndsoc.h>
+#include <fa_core.h>
+#include <etc_fa.h>
+#include <et_export.h>	/* for et_fa_xx() routines */
+#include <chipcommonb.h>
+#include <bcmrobo.h>
+#include <etioctl.h>
+
+
+#define ETC_FA_LOCK_INIT(fai)	et_fa_lock_init((fai)->et)
+#define ETC_FA_LOCK(fai)	et_fa_lock((fai)->et)
+#define ETC_FA_UNLOCK(fai)	et_fa_unlock((fai)->et)
+
+#ifdef	BCMDBG
+#define	ET_ERROR(args)	printf args
+#define	ET_TRACE(args)
+#else	/* BCMDBG */
+#define	ET_ERROR(args)
+#define	ET_TRACE(args)
+#endif	/* BCMDBG */
+#define	ET_MSG(args)
+
+
+#define NHOP_FULL		CTF_MAX_NEXTHOP_TABLE_INDEX
+#define PEEKNEXT_NHIDX(nhi)     ((nhi)->free_idx)
+#define GETNEXT_NHIDX(nhi) \
+({ \
+	uint8 idx = (nhi)->free_idx; \
+	(nhi)->free_idx = (nhi)->flist[idx]; \
+	(nhi)->flist[idx] = 0; \
+	idx; \
+})
+
+#define PUTNEXT_NHIDX(nhi, i) \
+{ \
+	if ((nhi)->free_idx == NHOP_FULL) \
+		(nhi)->free_idx = i; \
+	(nhi)->flist[i] = (nhi)->free_idx; \
+	(nhi)->free_idx = i; \
+}
+
+/* FA dump options */
+#define CTF_FA_DUMP_VALID       1
+#define CTF_FA_DUMP_VALID_NF    2
+#define CTF_FA_DUMP_VALID_NH    3
+#define CTF_FA_DUMP_VALID_NP    4
+#define CTF_FA_DUMP_ALL_NF	5
+#define CTF_FA_DUMP_ALL_NH	6
+#define CTF_FA_DUMP_ALL_NP	7
+#define CTF_FA_DUMP_ALL		8
+
+#define SELECT_MACC_TABLE_RD(f, t, i) \
+{ \
+	W_REG(si_osh((f)->sih), &(f)->regs->mem_acc_ctl, \
+	CTF_MEMACC_RD_TABLE(t, i)); \
+}
+
+#define SELECT_MACC_TABLE_WR(f, t, i) \
+{ \
+	W_REG(si_osh((f)->sih), &(f)->regs->mem_acc_ctl, \
+	CTF_MEMACC_WR_TABLE(t, i)); \
+}
+
+#define CTF_FA_MACC_RD(f, d, n) \
+{ \
+	int i; \
+	d[0] = R_REG(si_osh((f)->sih), &(f)->regs->m_accdata[0]); \
+	for (i = (n); i; i--) { \
+		d[i-1] = R_REG(si_osh((f)->sih), &(f)->regs->m_accdata[i-1]); \
+	} \
+	W_REG(si_osh((f)->sih), &(f)->regs->mem_acc_ctl, 0); \
+}
+
+#define CTF_FA_MACC_WR(f, d, n) \
+{ \
+	int i; \
+	for (i = (n); i; i--) { \
+		W_REG(si_osh((f)->sih), &(f)->regs->m_accdata[i-1], d[i-1]); \
+	} \
+}
+
+#define CTF_FA_GET_NH_DA(d, s) \
+{ \
+	d[5] = (uint8_t)((s[0] >> 19) & 0xFF); \
+	d[4] = (uint8_t)((s[0] >> 27) & 0x1F) | \
+		(uint8_t)((s[1] & 0x00000007) << 5); \
+	d[3] = (uint8_t)((s[1] >> 3) & 0xFF); \
+	d[2] = (uint8_t)((s[1] >> 11) & 0xFF); \
+	d[1] = (uint8_t)((s[1] >> 19) & 0xFF); \
+	d[0] = (uint8_t)((s[1] >> 27) & 0x1F) | \
+		(uint8_t)((s[2] & 0x7) << 5); \
+}
+
+#define CTF_FA_SET_NH_ENTRY(d, s, ft, o, vt) \
+{ \
+	d[0] = (((ft) & 0x1) | (((o) & 0x3) << 1) | \
+		 (((vt) & 0xFFFF) << 3) | \
+		 (s[5] << 19) | (s[4] & 0x1F) << 27); \
+	d[1] = (((s[4] & 0xE0) >> 5) | (s[3] << 3) | \
+		 (s[2] << 11) | (s[1] << 19) | \
+		 (s[0] & 0x1F) << 27); \
+	d[2] = ((s[0] & 0xE0) >> 5); \
+}
+
+#define CTF_FA_GET_NP_SA(d, s) \
+{ \
+	d[5] = (uint8_t)((s[0] >> 1) & 0xFF); \
+	d[4] = (uint8_t)((s[0] >> 9) & 0xFF); \
+	d[3] = (uint8_t)((s[0] >> 17) & 0xFF); \
+	d[2] = (uint8_t)(((s[0] >> 25) & 0x7F) | \
+			((s[1] & 0x1) << 7)); \
+	d[1] = (uint8_t)((s[1] >> 1) & 0xFF); \
+	d[0] = (uint8_t)((s[1] >> 9) & 0xFF); \
+}
+
+#define CTF_FA_SET_NP_ENTRY(d, s, e) \
+{ \
+	d[0] = ((e & 0x1) | (s[5] << 1) | (s[4] << 9) | \
+		(s[3] << 17) | (s[2] & 0x7F) << 25); \
+	d[1] = ((((s[2] & 0x80) >> 7) << 0) | \
+		 (s[1] << 1) | (s[0] << 9)); \
+}
+
+#define CTF_FA_W_REG(osh, reg, m, v) \
+{ \
+	if (m) { \
+		uint32 val = R_REG((osh), (reg)); \
+		val &= ~(m); \
+		(val) |= ((v) & (m)); \
+		W_REG((osh), (reg), val); \
+	} \
+	R_REG((osh), (reg)); \
+}
+
+#define CTF_FA_WAR777_ON(f) \
+{ \
+	if ((f)->pub.flags & FA_777WAR_ENABLED) { \
+		CTF_FA_W_REG(si_osh((f)->sih), &((f)->regs->control), \
+		CTF_CTL_HWQ_THRESHLD_MASK, 0); \
+		OSL_DELAY(1000); \
+	} \
+}
+
+#define CTF_FA_WAR777_OFF(f) \
+{ \
+	if ((f)->pub.flags & FA_777WAR_ENABLED) { \
+		CTF_FA_W_REG(si_osh((f)->sih), &((f)->regs->control), \
+		 CTF_CTL_HWQ_THRESHLD_MASK, \
+		 (0x140 << 4)); \
+	} \
+}
+
+#define	PRINT_FLOW_TABLE_HDR(pr, b) pr(b, "%-4s %-35s %-35s %4s %5s %5s %-3s %-8s %-4s %5s " \
+					"%-35s %5s %4s %4s %4s %3s Action\n", "Fidx", \
+					"Sip", "dip", "Prot", "SPort", "DPort", "Ts", \
+					"Hits", "Dir", "RPort", "Rip", "Valid", "Ipv4", \
+					"Nidx", "Pidx", "Dma");
+
+#define	PRINT_NHOP_TABLE_HDR(pr, b) pr(b, "%-5s %-17s %-8s %6s L2_Frame_type\n", "Nhidx", \
+					"NH-Mac", "Vlan-TCI", "Tag-op");
+
+#define	PRINT_POOL_TABLE_HDR(pr, b) pr(b, "%-8s %-17s External\n", "Pool-idx", "Rmap_SA");
+
+#define FA_CAPABLE(rev, chip)		(((rev) >= 3) || (CHIPID(chip) == BCM47094_CHIP_ID))
+#define FA_ON_MODE_VALID()	(getintvar(NULL, "ctf_fa_mode") == CTF_FA_BYPASS || \
+				 getintvar(NULL, "ctf_fa_mode") == CTF_FA_NORMAL)
+
+static int aux_unit = -1;
+#define FA_DEFAULT_AUX_UNIT	0
+
+#define FA_FA_ENET_UNIT		((aux_unit == -1) ? FA_DEFAULT_AUX_UNIT : aux_unit)
+#define FA_AUX_ENET_UNIT	2
+
+#define FA_FA_CORE_UNIT		2
+#define FA_AUX_CORE_UNIT	((aux_unit == -1) ? FA_DEFAULT_AUX_UNIT : aux_unit)
+
+#define FA_FA_CORE(u)	(((u) == FA_FA_CORE_UNIT) ? TRUE : FALSE)
+#define FA_AUX_CORE(u)	(((u) == FA_AUX_CORE_UNIT) ? TRUE : FALSE)
+
+#define	FA_NAPT(fai)		((fa_info_t *)(fai))->napt
+#define FA_NAPT_TPL_CMP(p, v6, sip, dip, proto, sp, dp) \
+	(!(((v6) ? memcmp(p->sip, sip, sizeof(p->sip) + sizeof(p->dip)) : \
+		(p->sip[0] ^ sip[0]) | (p->dip[0] ^ dip[0])) | \
+	((p->proto ^ proto) | \
+	(p->sp ^ sp) | \
+	(p->dp ^ dp))))
+
+#define FA_NAPT_SZ	256
+
+#define FA_NAPT_HASH(v6, sip, dip, sp, dp, proto) \
+({ \
+	uint32 sum; \
+	if (v6) { \
+		sum = sip[0] + sip[1] + sip[2] + sip[3] + \
+		dip[0] + dip[1] + dip[2] + dip[3] + \
+		sp + dp + proto; \
+	} else { \
+		sum = sip[0] + dip[0] + sp + dp + proto; \
+	} \
+	sum = ((sum >> 16) + (sum & 0xffff)); \
+	(((sum >> 8) + (sum & 0xff)) & (FA_NAPT_SZ - 1)); \
+})
+
+#define IF_NAME_ETH	"eth%d"
+
+typedef int (* print_buf_t)(void *buf, const char *f, ...);
+
+typedef struct {
+	print_buf_t		p;
+	void			*b;
+} print_hdl_t;
+
+typedef struct {
+	uint8			external;
+	uint8			remap_mac[ETHER_ADDR_LEN];
+} pool_entry_t;
+
+typedef struct {
+	uint8			l2_ftype;
+	uint8			tag_op;
+	uint16			vlan_tci;
+	uint8			nh_mac[ETHER_ADDR_LEN];
+} nhop_entry_t;
+
+typedef struct {
+	uint8			flist[CTF_MAX_NEXTHOP_TABLE_INDEX];	/* Free nh list */
+	uint8			free_idx;				/* current free entry */
+	uint16			ref[CTF_MAX_NEXTHOP_TABLE_INDEX];	/* No of napt references */
+} next_hop_t;
+
+typedef struct {
+	uint32			napt_idx;	/* Index to hash table */
+	uint32			hits;		/* hits counter */
+	uint8			action;		/* Overwrite bit-0: IP, bit-1 PORT */
+	uint8			tgt_dma;	/* on hit send to HOST:1 SWITCH:0 */
+} napt_flow_t;
+
+typedef struct fa_napt {
+	uint8			pool_idx;	/* Index to pool table */
+	uint8			nh_idx;		/* Index to next hop table (routed intf mac-addr) */
+	struct ether_addr	dhost;		/* Destination MAC address */
+	bool			v6;		/* IPv6 entry */
+	napt_flow_t		nfi;		/* NAPT flow info */
+
+	/* 5 tuple info */
+	struct fa_napt		*next;		/* Pointer to napt entry */
+	uint32			sip[IPADDR_U32_SZ];
+	uint32			dip[IPADDR_U32_SZ];
+	uint16			sp;
+	uint16			dp;
+	uint8			proto;
+} fa_napt_t;
+
+typedef struct fa_info {
+	fa_t			pub;
+	uint32			chiprev;	/* Chip rev, A0 ~ A3 */
+	si_t			*sih;		/* SiliconBackplane handle */
+	char			*vars;		/* nvram variables handle */
+	void			*et;		/* pointer to os-specific private state */
+	void			*robo;
+	bool			enabled;
+	void			*fadevid;	/* Ref to gmac connected to FA */
+	fa_napt_t		**napt;		/* NAPT connection cache table */
+	fa_napt_t		*ftable[CTF_MAX_FLOW_TABLE]; /* Indicate HW napt index used */
+	uint8			acc_mode;	/* Flow accelarator mode */
+	uint16			nflows;		/* Keep track of no o flfows in NAPT flow table */
+	next_hop_t		nhi;		/* Next hop info */
+	faregs_t		*regs;		/* FA/CTF register space address(virtual address) */
+
+	void			*faimp_dev;	/* Specific for AUX device */
+} fa_info_t;
+
+static fa_info_t *aux_dev = NULL;
+static fa_info_t *fa_dev = NULL;
+static void *fa_proc = NULL;
+
+/* Use SW hash by default */
+/* SW hash CCITT polynomial (0 5 12 16): X16+X12+X5 +1 */
+#ifdef BCMFA_HW_HASH
+#define HW_HASH()	1
+#else
+#define HW_HASH()	0
+#endif
+
+#define P_CCITT 0x1021
+static unsigned short crcccitt_tab[256];
+
+static void
+init_crcccitt_tab(void)
+{
+
+	int i, j;
+	unsigned short crc, c;
+
+	for (i = 0; i < 256; i++) {
+		crc = 0;
+		c = ((unsigned short) i) << 8;
+
+		for (j = 0; j < 8; j++) {
+
+			if ((crc ^ c) & 0x8000)
+				crc = (crc << 1) ^ P_CCITT;
+			else
+				crc = crc << 1;
+
+			c = c << 1;
+		}
+		crcccitt_tab[i] = crc;
+	}
+}
+
+static unsigned short
+update_crc_ccitt(unsigned short crc, char c)
+{
+	unsigned short tmp, short_c;
+
+	short_c  = 0x00ff & (unsigned short) c;
+
+	tmp = (crc >> 8) ^ short_c;
+	crc = (crc << 8) ^ crcccitt_tab[tmp];
+
+	return crc;
+
+}
+
+static unsigned short
+fa_crc_ccitt(ctf_ipc_t *ipc)
+{
+	int i;
+	unsigned short crc_ccitt = 0;
+	unsigned char istr[13];
+
+	memset(istr, 0, sizeof(istr));
+	memcpy(&istr[1], (unsigned char *)&ipc->tuple.sip[0], 4);
+	memcpy(&istr[5], (unsigned char *)&ipc->tuple.dip[0], 4);
+	memcpy(&istr[9], (unsigned char *)&ipc->tuple.sp, sizeof(ipc->tuple.sp));
+	memcpy(&istr[11], (unsigned char *)&ipc->tuple.dp, sizeof(ipc->tuple.dp));
+
+	/* LSH 1 + sip + dip , just do idx 0 ~ 7 */
+	for (i = 0; i < 8; i++)
+		istr[i] = (istr[i] << 1) | (istr[i+1] >> 7);
+
+	/* idx 8 */
+	istr[i] = istr[i] << 1;
+	if (ipc->tuple.proto == 6)
+		istr[i] |= 1;
+
+	for (i = 0; i < sizeof(istr); i++)
+		crc_ccitt = update_crc_ccitt(crc_ccitt, istr[i]);
+
+	return crc_ccitt;
+}
+
+static bool
+fa_corereg(fa_info_t *fai, uint coreunit)
+{
+	uint32 idx = si_coreidx(fai->sih);
+
+	/* GMAC-2 connect FA but FA regs fall in GMAC-3 corereg space so using GMAC-3 as base. */
+	if (coreunit == 2) {
+		si_setcore(fai->sih, GMAC_CORE_ID, coreunit);
+		fai->fadevid = (void *)si_addrspace(fai->sih, 0);
+		if ((fai->regs = si_setcore(fai->sih, GMAC_CORE_ID, 3)))
+			fai->regs = (faregs_t *) ((uint8 *)fai->regs + FA_BASE_OFFSET);
+
+		ET_ERROR(("%s: FA reg:%p, Fadev:%p\n", __FUNCTION__, fai->regs, fai->fadevid));
+
+		si_setcoreidx(fai->sih, idx);
+	}
+
+	return (fai->regs && fai->fadevid);
+}
+
+static void
+fa_clr_all_int(fa_info_t *fai)
+{
+	osl_t *osh = si_osh(fai->sih);
+	faregs_t *regs = fai->regs;
+
+	/* Disable receiving table init done and parse inclomplete errors. */
+	W_REG(osh, &regs->status_mask, 0);
+
+	/* Disable receiving pkts for L2/L3 pkt errors */
+	W_REG(osh, &regs->rcv_status_en, 0);
+
+	/* disable interrupts on all error HWQ overflow conditions */
+	W_REG(osh, &regs->error_mask, 0);
+}
+
+static int32
+fa_setmode(fa_info_t *fai, uint8 mode)
+{
+	int32 ret = BCME_OK;
+	uint32 val;
+	osl_t *osh = si_osh(fai->sih);
+	faregs_t *regs = fai->regs;
+
+	if (fai->acc_mode == mode)
+		goto out;
+
+	/* Clear mode bits */
+	val = R_REG(osh, &regs->control);
+	val &= ~(CTF_CTL_SW_ACC_MODE | CTF_CTL_BYPASS_CTF);
+	if (mode != CTF_FA_NORMAL)
+		val |= (mode == CTF_FA_BYPASS) ? CTF_CTL_BYPASS_CTF : CTF_CTL_SW_ACC_MODE;
+	val |= (CTF_CTL_DSBL_MAC_DA_CHECK | CTF_CTL_NAPT_FLOW_INIT |
+		CTF_CTL_NEXT_HOP_INIT | CTF_CTL_HWQ_INIT |
+		CTF_CTL_LAB_INIT | CTF_CTL_HB_INIT | CTF_CTL_CRC_OWRT);
+
+	W_REG(osh, &regs->control, val);
+
+	SPINWAIT(((R_REG(osh, &regs->status) & CTF_INTSTAT_INIT_DONE) != CTF_INTSTAT_INIT_DONE),
+		50000);
+
+	ASSERT((R_REG(osh, &regs->status) & CTF_INTSTAT_INIT_DONE) == CTF_INTSTAT_INIT_DONE);
+
+	if ((R_REG(osh, &regs->status) & CTF_INTSTAT_INIT_DONE) == CTF_INTSTAT_INIT_DONE)
+		fai->acc_mode = mode;
+	else {
+		ET_ERROR(("%s: failed fa_ctl(0x%x)!\n", __FUNCTION__, R_REG(osh, &regs->control)));
+		ret = BCME_ERROR;
+	}
+
+out:
+	return ret;
+}
+
+static void
+fa_reset_next_hop_tbl(fa_info_t *fai)
+{
+	uint8 i;
+
+	/* Init next hop free list */
+	memset(fai->nhi.ref, 0, sizeof(fai->nhi.ref));
+	for (i = 0; i < CTF_MAX_NEXTHOP_TABLE_INDEX; i++)
+		fai->nhi.flist[i] = i+1;
+
+	fai->nhi.free_idx = 0;
+}
+
+static int
+fa_read_pool_entry(fa_info_t *fai, uint32 *tbl, uint32 idx)
+{
+	int32 ret = BCME_OK;
+
+	CTF_FA_WAR777_ON(fai);
+
+	/* Select Pool table to read  */
+	SELECT_MACC_TABLE_RD(fai, CTF_MEMACC_TBL_NP, idx);
+
+	/* Read NP entry */
+	CTF_FA_MACC_RD(fai, tbl, 3);
+
+	/* Mem-access complete? */
+	SPINWAIT(((R_REG(si_osh(fai->sih), &fai->regs->dbg_status) &
+		CTF_DBG_MEM_ACC_BUSY)), 10000);
+
+	if (R_REG(si_osh(fai->sih), &fai->regs->dbg_status) & CTF_DBG_MEM_ACC_BUSY) {
+		ET_ERROR(("%s MEM ACC Busy for 10ms\n", __FUNCTION__));
+		ret = BCME_BUSY;
+		goto done;
+	}
+
+done:
+	CTF_FA_WAR777_OFF(fai);
+
+	return ret;
+}
+
+static int
+fa_read_nhop_entry(fa_info_t *fai, uint32 *tbl, uint32 idx)
+{
+	int32 ret = BCME_OK;
+
+	CTF_FA_WAR777_ON(fai);
+
+	/* Select Next hop table to read from  */
+	SELECT_MACC_TABLE_RD(fai, CTF_MEMACC_TBL_NH, idx);
+
+	/* Read NH entry */
+	CTF_FA_MACC_RD(fai, tbl, 3);
+
+	/* Mem-access complete? */
+	SPINWAIT(((R_REG(si_osh(fai->sih), &fai->regs->dbg_status) &
+		CTF_DBG_MEM_ACC_BUSY)), 10000);
+
+	if (R_REG(si_osh(fai->sih), &fai->regs->dbg_status) & CTF_DBG_MEM_ACC_BUSY) {
+		ET_ERROR(("%s MEM ACC Busy for 10ms\n", __FUNCTION__));
+		ret = BCME_BUSY;
+		goto done;
+	}
+
+done:
+	CTF_FA_WAR777_OFF(fai);
+
+	return ret;
+}
+
+static int
+fa_write_nhop_entry(fa_info_t *fai, uint32 *tbl, uint32 idx)
+{
+	int32 ret = BCME_OK;
+
+	CTF_FA_WAR777_ON(fai);
+
+	/* Select NH table to write  */
+	SELECT_MACC_TABLE_WR(fai, CTF_MEMACC_TBL_NH, idx);
+
+	/* Write NH entry */
+	CTF_FA_MACC_WR(fai, tbl, 3);
+
+	/* Mem-access complete? */
+	SPINWAIT(((R_REG(si_osh(fai->sih), &fai->regs->dbg_status) &
+		CTF_DBG_MEM_ACC_BUSY)), 10000);
+
+	if (R_REG(si_osh(fai->sih), &fai->regs->dbg_status) & CTF_DBG_MEM_ACC_BUSY) {
+		ET_ERROR(("%s MEM ACC Busy for 10ms\n", __FUNCTION__));
+		ret = BCME_BUSY;
+		goto done;
+	}
+
+done:
+	CTF_FA_WAR777_OFF(fai);
+
+	return ret;
+}
+
+/* Look for next hop etry matching to nh->nh_mac,
+ * if found update index in tb_info->nh_idx
+ * NOTE: It must be called under ETC_FA_LOCK protection
+ */
+static int32
+fa_find_nhop(fa_info_t *fai, fa_napt_t *tb_info, nhop_entry_t *nh)
+{
+	int i;
+	uint8 idx = CTF_MAX_NEXTHOP_TABLE_INDEX;
+	uint8 eaddr[ETHER_ADDR_LEN];
+	uint32 d[3];
+#ifdef BCMDBG
+	char eabuf[ETHER_ADDR_STR_LEN];
+#endif
+	int32 ret = BCME_NOTFOUND;
+	fa_napt_t *napt;
+
+	/* If exist use correcponding npi->nh_idx to verify in HW table (double check). */
+	for (i = 0; i < FA_NAPT_SZ; i++) {
+		napt = FA_NAPT(fai)[i];
+		while (napt != NULL) {
+			if (ether_cmp(napt->dhost.octet, nh->nh_mac) == 0) {
+				idx = napt->nh_idx;
+				goto found;
+			}
+
+			napt = napt->next;
+		}
+	}
+
+found:
+
+	if (idx == CTF_MAX_NEXTHOP_TABLE_INDEX)
+		idx = 0;
+
+	if (idx >= CTF_MAX_NEXTHOP_TABLE_INDEX) {
+		ET_ERROR(("%s NH MAC: %s found at invalid index %d\n", __FUNCTION__,
+			bcm_ether_ntoa((struct  ether_addr *)nh->nh_mac, eabuf), idx));
+		ASSERT(idx < CTF_MAX_NEXTHOP_TABLE_INDEX);
+	}
+
+	for (; idx < CTF_MAX_NEXTHOP_TABLE_INDEX; idx++) {
+		if (fa_read_nhop_entry(fai, d, idx) == BCME_BUSY) {
+			ET_ERROR(("%s Nhop read timeout!\n", __FUNCTION__));
+			ret = BCME_BUSY;
+			goto done;
+		}
+
+		/* Get DA from NH entry */
+		CTF_FA_GET_NH_DA(eaddr, d);
+
+		if (memcmp(nh->nh_mac, eaddr, ETHER_ADDR_LEN) == 0) {
+			tb_info->nh_idx = (idx & (CTF_MAX_NEXTHOP_TABLE_INDEX - 1));
+			fai->nhi.ref[tb_info->nh_idx]++;
+			ret = BCME_OK;
+			break;
+		}
+	}
+
+done:
+
+	return ret;
+}
+
+static int
+fa_add_nhop_entry(fa_info_t *fai, fa_napt_t *tb_info, nhop_entry_t *nh)
+{
+	int32 ret = BCME_OK;
+	uint32 d[3];
+
+	if (PEEKNEXT_NHIDX(&fai->nhi) == NHOP_FULL) {
+		ET_ERROR(("%s Out of next hop entries!\n", __FUNCTION__));
+		ret = BCME_BUSY;
+		goto done;
+	}
+
+	/* Look for existing pool entries */
+	ret = fa_find_nhop(fai, tb_info, nh);
+
+	if (ret == BCME_OK || ret == BCME_BUSY)
+		goto done;
+
+	/* Prepare NH entry */
+	CTF_FA_SET_NH_ENTRY(d, nh->nh_mac, nh->l2_ftype, nh->tag_op, HTOL16(nh->vlan_tci));
+
+	if ((ret = fa_write_nhop_entry(fai, d, PEEKNEXT_NHIDX(&fai->nhi))) == BCME_BUSY) {
+		ET_ERROR(("%s Nhop write timeout!\n", __FUNCTION__));
+		goto done;
+	}
+
+	tb_info->nh_idx = (GETNEXT_NHIDX(&fai->nhi) & (CTF_MAX_NEXTHOP_TABLE_INDEX - 1));
+	fai->nhi.ref[tb_info->nh_idx]++;
+
+done:
+	return ret;
+}
+
+static int
+fa_delete_nhop_entry(fa_info_t *fai, fa_napt_t *npi)
+{
+	int32 ret = BCME_OK;
+	uint32 d[3];
+
+	ASSERT(npi->nh_idx < CTF_MAX_NEXTHOP_TABLE_INDEX);
+
+	if ((fai->nhi.flist[npi->nh_idx] != 0) || (fai->nhi.ref[npi->nh_idx] == 0)) {
+		ET_ERROR(("%s unexpected idx:%d flist:%d ref:%d\n", __FUNCTION__,
+		npi->nh_idx, fai->nhi.flist[npi->nh_idx], fai->nhi.ref[npi->nh_idx]));
+		ASSERT((fai->nhi.flist[npi->nh_idx] == 0) && (fai->nhi.ref[npi->nh_idx] != 0));
+	}
+
+	if (fai->nhi.ref[npi->nh_idx])
+		fai->nhi.ref[npi->nh_idx]--;
+
+	if (!fai->nhi.ref[npi->nh_idx]) {
+		/* clear nhop entry */
+		memset(d, 0, sizeof(d));
+
+		if ((ret = fa_write_nhop_entry(fai, d, npi->nh_idx)) == BCME_BUSY) {
+			ET_ERROR(("%s Nhop write timeout!\n", __FUNCTION__));
+			goto done;
+		}
+
+		PUTNEXT_NHIDX(&fai->nhi, npi->nh_idx);
+	}
+	npi->nh_idx = CTF_MAX_NEXTHOP_TABLE_INDEX;
+
+done:
+	return ret;
+}
+
+/* Look for entry matching to pt->remap_mac in pool table,
+ * if found update index in tb_info->pool_idx
+ */
+static int32
+fa_find_pool(fa_info_t *fai, fa_napt_t *tb_info, pool_entry_t *pt)
+{
+	uint8 i;
+	uint8 eaddr[ETHER_ADDR_LEN];
+	uint32 d[2];
+	int32 ret = BCME_NOTFOUND;
+
+	for (i = 0; i < CTF_MAX_POOL_TABLE_INDEX; i++) {
+		/* select Pool table for read */
+		SELECT_MACC_TABLE_RD(fai, CTF_MEMACC_TBL_NP, i);
+		/* Read d0,d1 from NH table */
+		CTF_FA_MACC_RD(fai, d, sizeof(d)/sizeof(d[0]));
+		/* mem-access complete? */
+		SPINWAIT(((R_REG(si_osh(fai->sih), &fai->regs->dbg_status) &
+			CTF_DBG_MEM_ACC_BUSY)), 10000);
+
+		if (R_REG(si_osh(fai->sih), &fai->regs->dbg_status) & CTF_DBG_MEM_ACC_BUSY) {
+			ET_ERROR(("%s MEM ACC Busy for 10ms\n", __FUNCTION__));
+			ret = BCME_BUSY;
+			goto done;
+		}
+
+		/* Get DA from NH entry */
+		CTF_FA_GET_NP_SA(eaddr, d);
+
+		if ((memcmp(pt->remap_mac, eaddr, ETHER_ADDR_LEN) == 0) &&
+			((d[0] & 0x1) == pt->external)) {
+			tb_info->pool_idx = (i & (CTF_MAX_POOL_TABLE_INDEX - 1));
+			ret = BCME_OK;
+			break;
+		}
+	}
+done:
+
+	return ret;
+}
+
+static int
+fa_add_pool_entry(fa_info_t *fai, fa_napt_t *tb_info, pool_entry_t *pe)
+{
+	int32 ret = BCME_OK;
+	uint32 d[2];
+
+	CTF_FA_WAR777_ON(fai);
+
+	/* Look for existing pool entries */
+	ret = fa_find_pool(fai, tb_info, pe);
+
+	if (ret == BCME_OK || ret == BCME_BUSY)
+		goto done;
+
+	/* For now expecting only 2 entries, one each direction,
+	 * Using ext/int as index.
+	 */
+	SELECT_MACC_TABLE_WR(fai, CTF_MEMACC_TBL_NP, pe->external);
+
+	/* Prepare NH entry */
+	CTF_FA_SET_NP_ENTRY(d, pe->remap_mac, pe->external);
+
+	/* Write NH entry */
+	CTF_FA_MACC_WR(fai, d, sizeof(d)/sizeof(d[0]));
+
+	/* mem-access complete? */
+	SPINWAIT(((R_REG(si_osh(fai->sih), &fai->regs->dbg_status) &
+		CTF_DBG_MEM_ACC_BUSY)), 10000);
+
+	if (R_REG(si_osh(fai->sih), &fai->regs->dbg_status) & CTF_DBG_MEM_ACC_BUSY) {
+		ET_ERROR(("%s MEM ACC Busy for 10ms\n", __FUNCTION__));
+		ret = BCME_BUSY;
+		goto done;
+	}
+	tb_info->pool_idx = pe->external;
+
+done:
+	CTF_FA_WAR777_OFF(fai);
+
+	return ret;
+}
+
+static int
+fa_write_napt_entry(fa_info_t *fai, uint32 *tbl, uint32 idx)
+{
+	int32 ret = BCME_OK;
+
+	CTF_FA_WAR777_ON(fai);
+
+	/* select napt table to write  */
+	SELECT_MACC_TABLE_WR(fai, CTF_MEMACC_TBL_NF, idx);
+
+	/* Write napt entry */
+	CTF_FA_MACC_WR(fai, tbl, CTF_DATA_SIZE);
+
+	/* mem-access complete? */
+	SPINWAIT(((R_REG(si_osh(fai->sih), &fai->regs->dbg_status) &
+		CTF_DBG_MEM_ACC_BUSY)), 10000);
+
+	if (R_REG(si_osh(fai->sih), &fai->regs->dbg_status) & CTF_DBG_MEM_ACC_BUSY) {
+		ET_ERROR(("%s MEM ACC Busy for 10ms\n", __FUNCTION__));
+		ret = BCME_BUSY;
+		goto done;
+	}
+
+done:
+	CTF_FA_WAR777_OFF(fai);
+
+	return ret;
+}
+
+static int
+fa_read_napt_entry(fa_info_t *fai, uint32 *tbl, uint32 idx)
+{
+	int32 ret = BCME_OK;
+
+	CTF_FA_WAR777_ON(fai);
+
+	/* select napt table to write  */
+	SELECT_MACC_TABLE_RD(fai, CTF_MEMACC_TBL_NF, idx);
+
+	/* Read napt entry */
+	CTF_FA_MACC_RD(fai, tbl, CTF_DATA_SIZE);
+
+	/* mem-access complete? */
+	SPINWAIT(((R_REG(si_osh(fai->sih), &fai->regs->dbg_status) &
+		CTF_DBG_MEM_ACC_BUSY)), 10000);
+
+	if (R_REG(si_osh(fai->sih), &fai->regs->dbg_status) & CTF_DBG_MEM_ACC_BUSY) {
+		ET_ERROR(("%s MEM ACC Busy for 10ms\n", __FUNCTION__));
+		ret = BCME_BUSY;
+		goto done;
+	}
+
+done:
+	CTF_FA_WAR777_OFF(fai);
+
+	return ret;
+}
+
+static void
+fa_napt_prep_ipv4_word(fa_info_t *fai, fa_napt_t *napt, ctf_ipc_t *ipc, uint32 *tbl)
+{
+	memset(tbl, 0, sizeof(uint32) * CTF_DATA_SIZE);
+
+	tbl[1] = (napt->nfi.action << 3) | (napt->nfi.tgt_dma << 5) | (napt->pool_idx << 6) |
+		(napt->nh_idx << 8) | ((NTOH32(ipc->nat.ip) & 0x1FFFF) << 15);
+	tbl[2] = ((NTOH32(ipc->nat.ip) & 0xFFFE0000) >> 17) | (NTOH16(ipc->nat.port) << 15) |
+		((NTOH16(ipc->tuple.dp) & 0x1) << 31);
+	tbl[3] = ((NTOH16(ipc->tuple.dp) & 0xFFFE) >> 1) | (NTOH16(ipc->tuple.sp) << 15) |
+		((ipc->tuple.proto == 6) << 31);
+	tbl[4] = NTOH32(ipc->tuple.dip[0]);
+	tbl[5] = NTOH32(ipc->tuple.sip[0]);
+	/* LAN->WAN (INTERNAL), WAN->LAN(EXTERNAL), this is reverse of
+	 * external entry we populate in pool entry
+	 */
+	tbl[6] = ((ipc->action & CTF_ACTION_SNAT) ? CTF_NP_INTERNAL: CTF_NP_EXTERNAL) | (1 << 20);
+	/* Set ipv4_entry=1 */
+	tbl[7] = (1 << 31);
+}
+
+
+/* NOTE: It must be called under ETC_FA_LOCK protection */
+static int32
+_fa_napt_del(fa_info_t *fai, fa_napt_t *napt)
+{
+	int32 ret = BCME_OK;
+	uint32 tbl[CTF_DATA_SIZE];
+	uint8 vidx;
+
+	if (!fai || !napt)
+		return BCME_ERROR;
+
+	/* Fetch napt flow entry, ASSERT its valid
+	 * If valid, mark valid=0 and write the entry back.
+	 * Check the ref count on related nhopt entry, ifi
+	 * its 1 then delete nhop entry as well.
+	 */
+	if ((ret = fa_read_napt_entry(fai, tbl, napt->nfi.napt_idx)) == BCME_BUSY) {
+		ET_ERROR(("%s Read napt flow stuck!\n", __FUNCTION__));
+		goto done;
+	}
+
+	vidx = (napt->v6) ? 7 : 6;
+	if (!(tbl[vidx] & (1 << 20))) {
+		ET_ERROR(("%s Deleting invalid entry from NAPT flow naptidx:%d"
+			" tbl[%d]:0x%x\n", __FUNCTION__, napt->nfi.napt_idx, vidx, tbl[vidx]));
+		goto done;
+	}
+
+	/* Mark invalid */
+	tbl[vidx] &= ~(1 << 20);
+
+	if ((ret = fa_write_napt_entry(fai, tbl, napt->nfi.napt_idx)) == BCME_BUSY) {
+		ET_ERROR(("%s Write napt flow stuck!\n", __FUNCTION__));
+		goto done;
+	}
+
+	ET_TRACE(("%s NAPT entry deleted for hidx:%d\n", __FUNCTION__, napt->nfi.napt_idx));
+	fa_delete_nhop_entry(fai, napt);
+
+done:
+
+	return ret;
+}
+
+static int32
+fa_down(fa_info_t *fai)
+{
+	int i;
+	fa_napt_t *napt, *next;
+	int32 ret = BCME_OK;
+	osl_t *osh = si_osh(fai->sih);
+	faregs_t *regs = fai->regs;
+
+	if (fai->acc_mode == CTF_FA_BYPASS) {
+		ET_TRACE(("%s: Already down!\n", __FUNCTION__));
+		goto done;
+	}
+
+	/* Set to BYPASS mode */
+	if ((ret = fa_setmode(fai, CTF_FA_BYPASS)) != BCME_OK)
+		goto done;
+
+	/* In BYPASS mode disable BCM HDR in FA, but make sure on
+	 * ROBO switch BRCM_HDR_CTL(page:0x2, Off:0x3) clear
+	 * related bit for IMP port.
+	 */
+	W_REG(osh, &regs->bcm_hdr_ctl, 0);
+
+	/* clear L2 skip control */
+	W_REG(osh, &regs->l2_skip_ctl, 0);
+
+	/* Init L3 NAPT ctl */
+	W_REG(osh, &regs->l3_napt_ctl, 0);
+
+	/* No IPV4 checksum */
+	W_REG(osh, &regs->l3_ipv4_type, 0);
+
+	/* Flush all FA-ipc entries */
+	if (fai->nflows) {
+		ETC_FA_LOCK(fai);
+		for (i = 0; i < FA_NAPT_SZ; i++) {
+			napt = FA_NAPT(fai)[i];
+			while (napt != NULL) {
+				_fa_napt_del(fai, napt);
+				fai->nflows--;
+
+				next = napt->next;
+				MFREE(si_osh(fai->sih), napt, sizeof(fa_napt_t));
+				napt = next;
+			}
+			FA_NAPT(fai)[i] = NULL;
+		}
+		ETC_FA_UNLOCK(fai);
+	}
+
+	fai->pub.flags &= ~(FA_BCM_HDR_RX | FA_BCM_HDR_TX);
+
+	robo_fa_enable(fai->robo, FALSE, FALSE);
+
+done:
+	return ret;
+}
+
+static int32
+fa_up(fa_info_t *fai, uint8 mode)
+{
+	uint32 val;
+	int32 ret = BCME_OK;
+	osl_t *osh = si_osh(fai->sih);
+	faregs_t *regs = fai->regs;
+
+	if (fai->acc_mode == mode) {
+		ET_TRACE(("%s: Already in same mode !\n", __FUNCTION__));
+		goto done;
+	}
+
+	if (mode == CTF_FA_BYPASS) {
+		fa_down(fai);
+		goto done;
+	}
+
+	/* For now allow only Normal-Mode, SW-Accel-mode(TBD) */
+	if (mode == CTF_FA_SW_ACC) {
+		ET_ERROR(("%s: SW accelerated mode not supported!\n", __FUNCTION__));
+		ret = BCME_BADARG;
+		goto done;
+	}
+
+	/* Enable FA mode and re-init tables */
+	if ((ret = fa_setmode(fai, mode)) != BCME_OK)
+		goto done;
+
+	fa_clr_all_int(fai);
+
+	if (HW_HASH()) {
+		/* Init BRCM hdr control */
+		val = (CTF_BRCM_HDR_PARSE_IGN_EN | CTF_BRCM_HDR_HW_EN |
+			CTF_BRCM_HDR_SW_RX_EN | CTF_BRCM_HDR_SW_TX_EN);
+		W_REG(osh, &regs->bcm_hdr_ctl, val);
+
+		fai->pub.flags |= (FA_BCM_HDR_RX | FA_BCM_HDR_TX);
+	}
+	else {
+		/* Init CRC CCITT table for SW hash */
+		init_crcccitt_tab();
+	}
+
+	robo_fa_enable(fai->robo, TRUE, HW_HASH());
+
+	/* Init L2 skip control */
+	val = CTF_L2SKIP_ET_TO_SNAP_CONV;
+	W_REG(osh, &regs->l2_skip_ctl, val);
+
+	/* Init L3 NAPT ctl */
+	val = R_REG(osh, &regs->l3_napt_ctl);
+	val &= ~(CTFCTL_L3NAPT_HITS_CLR_ON_RD_EN | CTFCTL_L3NAPT_TIMESTAMP);
+	if (HW_HASH()) {
+		val |= (CTFCTL_L3NAPT_HASH_SEL | htons(0x4321));
+	}
+	W_REG(osh, &regs->l3_napt_ctl, val);
+
+	/* Enable IPV4 checksum */
+	val = R_REG(osh, &regs->l3_ipv4_type);
+	val |= CTF_L3_IPV4_CKSUM_EN;
+	W_REG(osh, &regs->l3_ipv4_type, val);
+
+	fa_reset_next_hop_tbl(fai);
+
+done:
+	return ret;
+}
+
+static int
+fa_dump_nf_entry(fa_info_t *fai, uint32 napt_idx, print_hdl_t *pr)
+{
+	uint32 tbl[CTF_DATA_SIZE];
+	uint32 tbl1[CTF_DATA_SIZE];
+	bool	valid_ipv6, v4;
+	print_buf_t prnt;
+	void	*b;
+	ASSERT(pr && pr->p && pr->b);
+
+	prnt = pr->p;
+	b = pr->b;
+
+	fa_read_napt_entry(fai, tbl, napt_idx);
+
+	v4 = (tbl[7] & (1 << 31));
+	valid_ipv6 = v4 ? FALSE:(tbl[7] & (1 << 20));
+
+	prnt(b, "%-4.03x ", napt_idx);
+	if (!valid_ipv6) {
+		prnt(b, "%-35.08x %-35.08x ", LTOH32(tbl[5]), LTOH32(tbl[4]));
+	} else {
+		napt_idx++;
+		fa_read_napt_entry(fai, tbl1, napt_idx);
+		prnt(b, "%08x.%08x.%08x.%08x ", tbl[7], tbl[6], tbl[5], tbl[4]);
+		prnt(b, "%08x.%08x.%08x.%08x ", tbl[3], tbl[2], tbl[1], tbl[0]);
+	}
+	prnt(b, "%-4s ", (tbl[3] >> 31) ? "tcp":"udp");
+	prnt(b, "%-5.04x ", (LTOH16(tbl[3]) >> 15) & 0xFFFF);
+	prnt(b, "%-5.04x ", ((LTOH16(tbl[3]) & 0x7FFF) << 1) | (LTOH16(tbl[2]) >> 31));
+	prnt(b, "%-3.01x ", CTF_FA_MACC_DATA0_TS(tbl));
+	prnt(b, "%08x ", ((LTOH16(tbl[1]) & 0x7) << 29) | (LTOH16(tbl[0]) >> 3));
+	prnt(b, "%-4s ", (tbl[6] & CTF_NP_EXTERNAL) ? "2lan":"2wan");
+	prnt(b, "%-5.04x ", (LTOH16(tbl[2]) >> 15) & 0xFFFF);
+
+	if (valid_ipv6) {
+		uint32 ipv6[4];
+		ipv6[0] = ((tbl[2] & 0xEFFF) | (tbl[1] >> 15));
+		ipv6[1] = ((tbl[3] & 0xEFFF) | (tbl[2] >> 15));
+		ipv6[2] = ((tbl[4] & 0xEFFF) | (tbl[3] >> 15));
+		ipv6[3] = ((tbl[5] & 0xEFFF) | (tbl[4] >> 15));
+		prnt(b, "%08x.%08x.%08x.%08x ", ipv6[3], ipv6[2], ipv6[1], ipv6[0]);
+	} else {
+		prnt(b, "%-35.08x ", ((LTOH32(tbl[2]) & 0x7FFF) << 17) | (LTOH32(tbl[1]) >> 15));
+	}
+	prnt(b, "%-5.01x ", (v4 ? ((tbl[6] >> 20) & 1):((tbl[7] >> 20) & 1)));
+	prnt(b, "%-4.01x ", v4);
+	prnt(b, "%-4.02x ", (tbl[1] >> 8) & 0x7F);
+	prnt(b, "%-4.01x ", (tbl[1] >> 6) & 0x3);
+	prnt(b, "%-3.01x ", (tbl[1] >> 5) & 0x1);
+	prnt(b, "%x\n", (tbl[1] >> 3) & 0x3);
+
+	return napt_idx;
+}
+
+static void
+fa_dump_nh_entry(fa_info_t *fai, uint32 nhidx, print_hdl_t *pr)
+{
+	uint32 tbl[CTF_DATA_SIZE];
+	uint8 eaddr[ETHER_ADDR_LEN];
+	char eabuf[ETHER_ADDR_STR_LEN];
+	print_buf_t prnt = pr->p;
+	void *b = pr->b;
+
+	fa_read_nhop_entry(fai, tbl, nhidx);
+
+	CTF_FA_GET_NH_DA(eaddr, tbl);
+	prnt(b, "%-5.02x ", nhidx);
+	prnt(b, "%-17s ", bcm_ether_ntoa((struct  ether_addr *)eaddr, eabuf));
+	prnt(b, "%-8.04x ",  (LTOH16(tbl[0]) >> 3) & 0xFFFF);
+	prnt(b, "%-6.01x ", (tbl[0] >> 1) & 0x3);
+	prnt(b, "%d\n", tbl[0] & 0x1);
+}
+
+static void
+fa_dump_np_entry(fa_info_t *fai, uint32 pool_idx, print_hdl_t *pr)
+{
+	uint32 tbl[CTF_DATA_SIZE];
+	uint8 eaddr[ETHER_ADDR_LEN];
+	char eabuf[ETHER_ADDR_STR_LEN];
+	print_buf_t prnt = pr->p;
+	void *b = pr->b;
+
+	fa_read_pool_entry(fai, tbl, pool_idx);
+
+	CTF_FA_GET_NP_SA(eaddr, tbl);
+	prnt(b, "%-8.01x ", pool_idx);
+	prnt(b, "%-17s ", bcm_ether_ntoa((struct  ether_addr *)eaddr, eabuf));
+	prnt(b, "%d\n", (tbl[0] & 0x1));
+}
+
+static void
+fa_dump_entries(fa_info_t *fai, uint8 opt, print_buf_t prnt, void *b)
+{
+	int i;
+	print_hdl_t pr = {prnt, b};
+	fa_napt_t *napt;
+
+	switch (opt) {
+	case CTF_FA_DUMP_ALL_NF:
+	{
+		prnt(b, "\n===== FLOW TABLE DUMP ======\n");
+		PRINT_FLOW_TABLE_HDR(prnt, b);
+		for (i = 0; i < CTF_MAX_FLOW_TABLE; i++)
+			i = fa_dump_nf_entry(fai, i, &pr);
+
+		break;
+	}
+	case CTF_FA_DUMP_ALL_NH:
+	{
+		prnt(b, "\n===== NEXT HOP TABLE DUMP ======\n");
+		PRINT_NHOP_TABLE_HDR(prnt, b);
+		for (i = 0; i < CTF_MAX_NEXTHOP_TABLE_INDEX; i++)
+			fa_dump_nh_entry(fai, i, &pr);
+
+		break;
+	}
+	case CTF_FA_DUMP_ALL_NP:
+	{
+		prnt(b, "\n===== POOL TABLE DUMP ======\n");
+		PRINT_POOL_TABLE_HDR(prnt, b);
+		for (i = 0; i < CTF_MAX_POOL_TABLE_INDEX; i++)
+			fa_dump_np_entry(fai, i, &pr);
+
+		break;
+	}
+	case CTF_FA_DUMP_VALID_NF:
+	case CTF_FA_DUMP_VALID_NH:
+	case CTF_FA_DUMP_VALID_NP:
+	{
+		/* next hop idx 0~127, pool idx 0~3 */
+		int8 valid_idx[CTF_MAX_NEXTHOP_TABLE_INDEX] = { -1 };
+
+		if (opt == CTF_FA_DUMP_VALID_NF) {
+			prnt(b, "\n===== FLOW TABLE VALID ENTRIES ======\n");
+			PRINT_FLOW_TABLE_HDR(prnt, b);
+		} else if (opt == CTF_FA_DUMP_VALID_NH) {
+			prnt(b, "\n===== NEXT HOP TABLE VALID ENTRIES ======\n");
+			PRINT_NHOP_TABLE_HDR(prnt, b);
+		} else if (opt == CTF_FA_DUMP_VALID_NP) {
+			prnt(b, "\n===== POOL TABLE VALID ENTRIES ======\n");
+			PRINT_POOL_TABLE_HDR(prnt, b);
+		}
+
+		ETC_FA_LOCK(fai);
+
+		memset(valid_idx, -1, sizeof(valid_idx));
+		for (i = 0; i < FA_NAPT_SZ; i++) {
+			napt = FA_NAPT(fai)[i];
+			while (napt != NULL) {
+				switch (opt) {
+				case CTF_FA_DUMP_VALID_NF:
+					fa_dump_nf_entry(fai, napt->nfi.napt_idx, &pr);
+					break;
+				case CTF_FA_DUMP_VALID_NH:
+					if (valid_idx[napt->nh_idx] == -1) {
+						fa_dump_nh_entry(fai, napt->nh_idx, &pr);
+						valid_idx[napt->nh_idx] = napt->nh_idx;
+					}
+					break;
+				case CTF_FA_DUMP_VALID_NP:
+					if (valid_idx[napt->pool_idx] == -1) {
+						fa_dump_np_entry(fai, napt->pool_idx, &pr);
+						valid_idx[napt->pool_idx] = napt->pool_idx;
+					}
+					break;
+				default:
+					ASSERT(0);
+					break;
+				}
+
+				napt = napt->next;
+			}
+		}
+
+		ETC_FA_UNLOCK(fai);
+
+		break;
+	}
+	default:
+		ET_ERROR(("%s Unexpection option\n", __FUNCTION__));
+		break;
+	}
+}
+
+#ifdef BCMDBG
+struct fareg_desc {
+	uint8 *fname;
+	uint8 *reg_name;
+	uint32 reg_off;
+};
+
+static struct fareg_desc fareg[] = {
+	{"control", "CTF_CONTROL", OFFSETOF(faregs_t, control)},
+	{"mem_acc_ctl", "CTF_MEM_ACC_CONTROL", OFFSETOF(faregs_t, mem_acc_ctl)},
+	{"bcm_hdr_ctl", "CTF_BRCM_HDR_CONTROL", OFFSETOF(faregs_t, bcm_hdr_ctl)},
+	{"l2_skip_ctl", "CTF_L2_SKIP_CONTROL", OFFSETOF(faregs_t, l2_skip_ctl)},
+	{"l2_tag", "CTF_L2_TAG_TYPE", OFFSETOF(faregs_t, l2_tag)},
+	{"l2_llc_max_len", "CTF_L2_LLC_MAX_LENGTH", OFFSETOF(faregs_t, l2_llc_max_len)},
+	{"l2_snap_typelo", "CTF_L2_LLC_SNAP_TYPE_LO", OFFSETOF(faregs_t, l2_snap_typelo)},
+	{"l2_snap_typehi", "CTF_L2_LLC_SNAP_TYPE_HI", OFFSETOF(faregs_t, l2_snap_typehi)},
+	{"l2_ethtype", "CTF_ETHERTYPE", OFFSETOF(faregs_t, l2_ethtype)},
+	{"l3_ipv6_type", "CTF_L3_IPV6_TYPE", OFFSETOF(faregs_t, l3_ipv6_type)},
+	{"l3_ipv4_type", "CTF_L3_IPV4_TYPE", OFFSETOF(faregs_t, l3_ipv4_type)},
+	{"l3_napt_ctl", "CTF_L3_NAPT_CONTROL", OFFSETOF(faregs_t, l3_napt_ctl)},
+	{"status", "CTF_STATUS", OFFSETOF(faregs_t, status)},
+	{"status_mask", "CTF_STATUS_MASK", OFFSETOF(faregs_t, status_mask)},
+	{"rcv_status_en", "CTF_RECV_STATUS_EN", OFFSETOF(faregs_t, rcv_status_en)},
+	{"error", "CTF_ERROR", OFFSETOF(faregs_t, error)},
+	{"error_mask", "CTF_ERR_MASK", OFFSETOF(faregs_t, error_mask)},
+	{"dbg_ctl", "CTF_DBG_CONTROL", OFFSETOF(faregs_t, dbg_ctl)},
+	{"dbg_status", "CTF_DBG_STATUS", OFFSETOF(faregs_t, dbg_status)},
+	{"mem_dbg", "CTF_MEM_DBG", OFFSETOF(faregs_t, mem_dbg)},
+	{"ecc_dbg", "CTF_ECC_DBG", OFFSETOF(faregs_t, ecc_dbg)},
+	{"ecc_error", "CTF_ECC_ERROR", OFFSETOF(faregs_t, ecc_error)},
+	{"ecc_error_mask", "CTF_ECC_ERR_MASK", OFFSETOF(faregs_t, ecc_error_mask)},
+	{"hwq_max_depth", "CTF_HWQ_MAX_DEPTH", OFFSETOF(faregs_t, hwq_max_depth)},
+	{"lab_max_depth", "CTF_LAB_MAX_DEPTH", OFFSETOF(faregs_t, lab_max_depth)},
+	{"stats", "CTF_STATS", OFFSETOF(faregs_t, stats)},
+	{"eccst", "CTF_ECC_STATS", OFFSETOF(faregs_t, eccst)},
+	{"m_accdata", "CTF_MEM_ACC_DATA", OFFSETOF(faregs_t, m_accdata)},
+	{"all", "ALL", 0xFFFF}
+};
+#endif /* BCMDBG */
+
+static uint32
+fa_chip_rev(si_t *sih)
+{
+	uint32 rev = 0;
+
+	if (BCM4707_CHIP(CHIPID(sih->chip))) {
+		uint32 *srab_base;
+
+		/* Get chip revision */
+		srab_base = (uint32 *)REG_MAP(CHIPCB_SRAB_BASE, SI_CORE_SIZE);
+		W_REG(si_osh(sih),
+			(uint32 *)((uint32)srab_base + CHIPCB_SRAB_CMDSTAT_OFFSET), 0x02400001);
+		rev = R_REG(si_osh(sih),
+			(uint32 *)((uint32)srab_base + CHIPCB_SRAB_RDL_OFFSET)) & 0xff;
+		REG_UNMAP(srab_base);
+	}
+
+	return rev;
+}
+
+static fa_napt_t *
+fa_napt_lkup_ll(fa_info_t *fai, bool v6, uint32 *sip, uint32 *dip, uint8 proto,
+	uint16 sp, uint16 dp)
+{
+	uint32 hash;
+	fa_napt_t *napt;
+
+	hash = FA_NAPT_HASH(v6, sip, dip, proto, sp, dp);
+
+	/* IP cache lookup */
+	napt = FA_NAPT(fai)[hash];
+	while (napt != NULL) {
+		if (FA_NAPT_TPL_CMP(napt, v6, sip, dip, proto, sp, dp))
+			return (napt);
+		napt = napt->next;
+	}
+
+	return (NULL);
+}
+
+uint
+fa_core2unit(si_t *sih, uint coreunit)
+{
+	int unit = coreunit;
+	bool fa_capable = FA_CAPABLE(fa_chip_rev(sih), sih->chip);
+
+	if (!FA_ON_MODE_VALID() || !fa_capable)
+		goto done;
+
+	if (coreunit == FA_FA_CORE_UNIT)
+		unit = FA_FA_ENET_UNIT;
+	else if (coreunit == FA_AUX_CORE_UNIT)
+		unit = FA_AUX_ENET_UNIT;
+
+done:
+	return unit;
+}
+
+static uint
+fa_unit2core(uint unit)
+{
+	int coreunit = unit;
+
+	if (unit == FA_FA_ENET_UNIT)
+		coreunit = FA_FA_CORE_UNIT;
+	else if (unit == FA_AUX_ENET_UNIT)
+		coreunit = FA_AUX_CORE_UNIT;
+
+	return coreunit;
+}
+
+fa_t *
+fa_attach(si_t *sih, void *et, char *vars, uint coreunit, void *robo)
+{
+	fa_info_t *fai = NULL;
+	bool fa_capable = FA_CAPABLE(fa_chip_rev(sih), sih->chip);
+
+	/* By pass fa attach if FA configuration is not enabled or invalid */
+	if (!FA_ON_MODE_VALID() || !fa_capable)
+		return NULL;
+
+	/* Do fa_attach for:
+	 * Normal mode: Both Aux and FA device
+	 * Bypass mode: Only FA device
+	 * fa_probe has filter it for us.
+	 */
+	if (!FA_FA_CORE(coreunit) && !FA_AUX_CORE(coreunit))
+		return NULL;
+
+	/* Allocate private info structure */
+	if ((fai = MALLOC(si_osh(sih), sizeof(fa_info_t))) == NULL) {
+		ET_ERROR(("%s: out of memory, malloced %d bytes", __FUNCTION__,
+		          MALLOCED(si_osh(sih))));
+		return NULL;
+	}
+	bzero((char *)fai, sizeof(fa_info_t));
+
+	fai->et = et;
+	fai->sih = sih;
+	fai->vars = vars;
+	fai->chiprev = fa_chip_rev(sih);
+	fai->robo = robo;
+
+	if (FA_AUX_CORE(coreunit)) {
+		ASSERT(aux_dev == NULL);
+
+		aux_dev = fai;
+		fai->pub.flags |= FA_AUX_DEV;
+
+		if (fa_dev)
+			fai->faimp_dev = et_fa_get_fa_dev(fa_dev->et);
+
+		robo_fa_aux_init(fai->robo);
+
+		goto aux_done;
+	}
+
+	/* Create the FA proc for user application */
+	if (FA_FA_CORE(coreunit))
+		fa_proc = et_fa_fs_create();
+
+	if (!fa_corereg(fai, coreunit)) {
+		MFREE(si_osh(sih), fai, sizeof(fa_info_t));
+		ET_ERROR(("%s: FA regs dev not found\n", __FUNCTION__));
+		return NULL;
+	}
+
+	/* A2 chipid need to enable this WAR selectively. */
+	if ((BCM4707_CHIP(CHIPID(sih->chip)) && fai->chiprev == 2) &&
+		(CHIPID(sih->chip) != BCM47094_CHIP_ID)) {
+			fai->pub.flags |= FA_777WAR_ENABLED;
+			ET_ERROR(("%s: Enabling FA WAR CHIPID(0x%x) CHIPREV(0x%x)\n",
+				__FUNCTION__, CHIPID(sih->chip), CHIPREV(sih->chiprev)));
+	}
+
+	if ((fai->napt = MALLOC(si_osh(sih), (FA_NAPT_SZ * sizeof(fa_napt_t *)))) == NULL) {
+			ET_ERROR(("%s: napt malloc failed\n", __FUNCTION__));
+			MFREE(si_osh(fai->sih), fai, sizeof(fa_info_t));
+			return NULL;
+	}
+	bzero((char *)fai->napt, (FA_NAPT_SZ * sizeof(fa_napt_t *)));
+
+	ETC_FA_LOCK_INIT(fai);
+
+	ASSERT(fa_dev == NULL);
+
+	fa_dev = fai;
+	fai->pub.flags |= FA_FA_DEV;
+	et_fa_set_dev_on(fai->et);
+
+	if (aux_dev) {
+		aux_dev->faimp_dev = et_fa_get_fa_dev(fa_dev->et);
+
+		/* Do it again otherwise robo_attach for FA interface will disable it */
+		robo_fa_aux_init(fai->robo);
+	}
+
+aux_done:
+	return (&fai->pub);
+}
+
+void
+fa_detach(fa_t *fa)
+{
+	fa_info_t *fai = (fa_info_t *)fa;
+
+	if (fa_proc) {
+		et_fa_fs_clean();
+		fa_proc = NULL;
+	}
+
+	if (fa == NULL)
+		return;
+
+	if (FA_IS_FA_DEV(fa))
+		fa_down(fai);
+
+	if (fai->napt)
+		MFREE(si_osh(fai->sih), fai->napt, (FA_NAPT_SZ * sizeof(fa_napt_t *)));
+
+	MFREE(si_osh(fai->sih), fai, sizeof(fa_info_t));
+}
+
+/*
+ * Enable fa function on this interface.
+ */
+int
+fa_enable_device(fa_t *fa)
+{
+	fa_info_t *fai = (fa_info_t *)fa;
+
+	if (FA_IS_AUX_DEV(fa))
+		return 0;
+
+	fa_up(fai, getintvar(fai->vars, "ctf_fa_mode"));
+
+	/* Update the state to enabled/disabled */
+	fai->enabled = TRUE;
+
+	return 0;
+}
+
+void *
+fa_process_tx(fa_t *fa, void *p)
+{
+	fa_info_t *fai = (fa_info_t *)fa;
+	osl_t *osh = si_osh(fai->sih);
+
+	/* Validate the packet pointer */
+	if (p == NULL)
+		return NULL;
+
+	BCM_REFERENCE(osh);
+
+	if (PKTHEADROOM(osh, p) < 4) {
+		void *tmp_p = p;
+		p = PKTEXPHEADROOM(osh, p, 4);
+		/* To free original one and check the new one */
+		PKTFREE(osh, tmp_p, TRUE);
+		if (p == NULL) {
+			ET_ERROR(("%s: Out of memory while adjusting headroom\n", __FUNCTION__));
+			return NULL;
+		}
+	}
+
+	/* For now always opcode 0x0 */
+	PKTPUSH(osh, p, 4);
+	memset(PKTDATA(osh, p), 0, 4);
+	if (PKTLEN(osh, p) < 68)
+		PKTSETLEN(osh, p, 68);
+
+	return p;
+}
+
+uint32 BCMFASTPATH
+fa_get_nid_rx(osl_t *osh, void *p, int bhdroff)
+{
+	bcm_hdr_t bhdr;
+	uint32 word;
+	uint32 nid;
+
+	word = *((uint32 *)(PKTDATA(osh, p) + bhdroff));
+	bhdr.word = NTOH32(word);
+
+	ASSERT(bhdr.oc10.op_code == 0x2);
+
+	nid = (bhdr.oc10.napt_flow_id * CTF_MAX_BUCKET_INDEX)
+		  + bhdr.oc10.bkt_id;
+
+	if (bhdr.oc10.all_bkts_full) {
+		ET_ERROR(("%s All bkts full, leave to SW CTF\n", __FUNCTION__));
+		nid = BCM_FA_INVALID_IDX_VAL;
+	}
+	return nid;
+}
+
+void
+fa_process_rx(fa_t *fa, void *p)
+{
+	uint32 nid;
+	osl_t * osh;
+	fa_info_t *fai = (fa_info_t *)fa;
+
+	BCM_REFERENCE(fai);
+
+	if (FA_IS_AUX_DEV(fa)) {
+		PKTSETFADEV(p, fai->faimp_dev);
+		PKTSETFAAUX(p);
+		PKTSETFAHIDX(p, BCM_FA_INVALID_IDX_VAL);
+		return;
+	}
+
+	osh = si_osh(fai->sih);
+	nid = fa_get_nid_rx(osh, p, 0); /* hwrxhdr is already stripped */
+	PKTSETFAHIDX(p, nid);
+
+	PKTPULL(osh, p, 4);
+}
+
+int32
+fa_napt_add(fa_t *fa, ctf_ipc_t *ipc, bool v6)
+{
+	uint32 *sip, *dip;
+	uint16 sp, dp;
+	uint8 proto;
+
+	uint32 hash, napt_idx;
+	int32 ret = BCME_OK;
+	nhop_entry_t nh;
+	pool_entry_t pe;
+	fa_napt_t *napt = NULL;
+	uint32 tbl[CTF_DATA_SIZE];
+	fa_info_t *fai = (fa_info_t *)fa;
+	unsigned short crc_hash;
+	int i;
+
+	/* Are both TX/RX FA capable */
+	if (!et_fa_dev_on(ipc->txif) || !et_fa_dev_on(ipc->rxif))
+		return BCME_ERROR;
+
+	if (v6)
+		return BCME_ERROR;
+
+#ifdef RGMII_BCM_FA
+	/* currently not supported for PPP */
+	if (ipc->ppp_ifp)
+		return BCME_ERROR;
+#endif
+
+	sip = ipc->tuple.sip;
+	dip = ipc->tuple.dip;
+	proto = ipc->tuple.proto;
+	sp = ipc->tuple.sp;
+	dp = ipc->tuple.dp;
+
+	ETC_FA_LOCK(fai);
+
+	if (HW_HASH()) {
+		napt_idx = PKTGETFAHIDX(ipc->pkt);
+		if (napt_idx == BCM_FA_INVALID_IDX_VAL) {
+			ET_TRACE(("%s Invalid hash and bkt idx!\n", __FUNCTION__));
+			ret = BCME_ERROR;
+			goto err;
+		}
+	}
+	else {
+		/* Only take the low 8-bit address */
+		crc_hash = fa_crc_ccitt(ipc) & 0xff;
+		/* Check if we have enough bucket */
+		for (i = 0; i < CTF_MAX_BUCKET_INDEX; i++) {
+			napt_idx = crc_hash * CTF_MAX_BUCKET_INDEX + i;
+			if (!fai->ftable[napt_idx])
+				break;
+		}
+
+		if (i == CTF_MAX_BUCKET_INDEX) {
+			/* Bucket full */
+			ET_TRACE(("%s All bkts full, leave to SW CTF\n", __FUNCTION__));
+			ret = BCME_ERROR;
+			goto err;
+		}
+	}
+
+	ASSERT(napt_idx < CTF_MAX_FLOW_TABLE);
+
+	if (fai->ftable[napt_idx]) {
+		ET_TRACE(("%s flow table index %d has been used!\n", __FUNCTION__, napt_idx));
+		ret = BCME_ERROR;
+		goto err;
+	}
+
+	if (fa_napt_lkup_ll(fai, v6, sip, dip, proto, sp, dp) != NULL) {
+		ET_TRACE(("%s: Adding duplicate entry\n", __FUNCTION__));
+		ret = BCME_ERROR;
+		goto err;
+	}
+
+	if ((napt = MALLOC(si_osh(fai->sih), sizeof(fa_napt_t))) == NULL) {
+		ET_ERROR(("%s: out of memory, malloced %d bytes", __FUNCTION__,
+		          MALLOCED(si_osh(fai->sih))));
+		ret = BCME_ERROR;
+		goto err;
+	}
+	bzero((char *)napt, sizeof(fa_napt_t));
+
+	napt->nfi.napt_idx = napt_idx;
+	memcpy(napt->dhost.octet, ipc->dhost.octet, ETH_ALEN);
+
+	/* Next hop settings */
+	nh.l2_ftype = 0;
+	nh.tag_op = (ipc->action & CTF_ACTION_TAG) ? CTF_NH_OP_CTAG : CTF_NH_OP_NOTAG;
+	/* For now deriving vlan prio from ip_tos
+	 * should be ok, as our switch has fixmap from tos -> VLAN_PCP
+	 */
+	nh.vlan_tci = (((ipc->tos >> IPV4_TOS_PREC_SHIFT) & VLAN_PRI_MASK) << VLAN_PRI_SHIFT);
+	nh.vlan_tci |= ipc->vid & VLAN_VID_MASK;
+	ether_copy(ipc->dhost.octet, nh.nh_mac);
+
+	/* Decide direction in pool entry, at this point all we know is it
+	 * should be reverse of whats is in corresponding flow entry.
+	 */
+	pe.external = (ipc->action & CTF_ACTION_SNAT) ? CTF_NP_EXTERNAL : CTF_NP_INTERNAL;
+	ether_copy(ipc->shost.octet, pe.remap_mac);
+
+	/* Add(or get if already present) next-hop and pool table entries */
+	if (((ret = fa_add_nhop_entry(fai, napt, &nh)) == BCME_BUSY) ||
+		((ret = fa_add_pool_entry(fai, napt, &pe)) == BCME_BUSY))
+		goto err;
+
+	napt->nfi.action = CTF_NAPT_OVRW_IP;
+	if (((ipc->action & CTF_ACTION_SNAT) && (ipc->tuple.sp != ipc->nat.port)) ||
+	    ((ipc->action & CTF_ACTION_DNAT) && (ipc->tuple.dp != ipc->nat.port)))
+		napt->nfi.action |= CTF_NAPT_OVRW_PORT;
+	napt->nfi.tgt_dma = 0;
+
+	/* Add Napt entry if not exist */
+	if (!v6) {
+		/* prepare napt ipv4 entry */
+		fa_napt_prep_ipv4_word(fai, napt, ipc, tbl);
+	} else {
+		/* For now IPV6 NAT is not supported in SW CTF as well,
+		 * might not be required, so disabling this part untill
+		 * we find need to enable, and ofcourse make required changes
+		 * in SW CTF to save NAT IPV6 IP.
+		 */
+		ET_ERROR(("%s Ignore NAPT entry add for IPV6\n", __FUNCTION__));
+		ret = BCME_ERROR;
+		goto err;
+	}
+
+	ET_TRACE(("%s NAPT entry add for napt idx:%d\n", __FUNCTION__, napt->nfi.napt_idx));
+	if ((ret = fa_write_napt_entry(fai, tbl, napt->nfi.napt_idx)) == BCME_BUSY)
+		goto err;
+
+	/* Save 5 tuple info */
+	memcpy(napt->sip, ipc->tuple.sip, sizeof(napt->sip));
+	memcpy(napt->dip, ipc->tuple.dip, sizeof(napt->dip));
+	napt->sp = ipc->tuple.sp;
+	napt->dp = ipc->tuple.dp;
+	napt->proto = ipc->tuple.proto;
+	napt->v6 = v6;
+
+	hash = FA_NAPT_HASH(v6, sip, dip, proto, sp, dp);
+	napt->next = FA_NAPT(fai)[hash];
+	FA_NAPT(fai)[hash] = napt;
+
+	fai->ftable[napt_idx] = napt;
+	fai->nflows++;
+
+err:
+
+	if (ret != BCME_OK && napt)
+		MFREE(si_osh(fai->sih), napt, sizeof(fa_napt_t));
+
+	ETC_FA_UNLOCK(fai);
+
+	return ret;
+}
+
+int32
+fa_napt_del(fa_t *fa, ctf_ipc_t *ipc, bool v6)
+{
+	uint32 *sip, *dip;
+	uint16 sp, dp;
+	uint8 proto;
+
+	uint32 hash;
+	fa_napt_t *napt, *prev = NULL;
+	int32 ret = BCME_OK;
+	fa_info_t *fai = (fa_info_t *)fa;
+
+	sip = ipc->tuple.sip;
+	dip = ipc->tuple.dip;
+	proto = ipc->tuple.proto;
+	sp = ipc->tuple.sp;
+	dp = ipc->tuple.dp;
+
+	hash = FA_NAPT_HASH(v6, sip, dip, proto, sp, dp);
+
+	ETC_FA_LOCK(fai);
+
+	napt = FA_NAPT(fai)[hash];
+
+	/* Keep track of prev pointer for deletion */
+	while (napt != NULL) {
+		if (!FA_NAPT_TPL_CMP(napt, v6, sip, dip, proto, sp, dp)) {
+			prev = napt;
+			napt = napt->next;
+			continue;
+		}
+
+		/* Remove the entry from hash list */
+		if (prev != NULL)
+			prev->next = napt->next;
+		else
+			FA_NAPT(fai)[hash] = napt->next;
+
+		ASSERT(napt->v6 == v6);
+
+		ret = _fa_napt_del(fai, napt);
+
+		fai->ftable[napt->nfi.napt_idx] = NULL;
+		fai->nflows--;
+
+		break;
+	}
+
+	if (napt)
+		MFREE(si_osh(fai->sih), napt, sizeof(fa_napt_t));
+
+	ETC_FA_UNLOCK(fai);
+
+	return ret;
+}
+
+void
+fa_conntrack(fa_t *fa, ctf_ipc_t *ipc, bool v6)
+{
+	uint32 *sip, *dip;
+	uint16 sp, dp;
+	uint8 proto;
+	fa_info_t *fai = (fa_info_t *)fa;
+
+	if (!PKTISFAAUX(ipc->pkt))
+		return;
+
+	sip = ipc->tuple.sip;
+	dip = ipc->tuple.dip;
+	proto = ipc->tuple.proto;
+	sp = ipc->tuple.sp;
+	dp = ipc->tuple.dp;
+
+	ETC_FA_LOCK(fai);
+
+	if (fa_napt_lkup_ll(fai, v6, sip, dip, proto, sp, dp) == NULL) {
+		/* Notify to free it because no fast path found */
+		PKTSETFAFREED(ipc->pkt);
+	}
+
+	ETC_FA_UNLOCK(fai);
+}
+
+void
+fa_napt_live(fa_t *fa, ctf_ipc_t *ipc, bool v6)
+{
+	uint32 *sip, *dip;
+	uint16 sp, dp;
+	uint8 proto;
+
+	uint32 hits;
+	uint32 tbl[CTF_DATA_SIZE];
+	fa_napt_t *napt;
+	fa_info_t *fai = (fa_info_t *)fa;
+
+	/* No need to update if SW CTF say it's alive */
+	if (ipc->live > 0)
+		return;
+
+	sip = ipc->tuple.sip;
+	dip = ipc->tuple.dip;
+	proto = ipc->tuple.proto;
+	sp = ipc->tuple.sp;
+	dp = ipc->tuple.dp;
+
+	ETC_FA_LOCK(fai);
+
+	if ((napt = fa_napt_lkup_ll(fai, v6, sip, dip, proto, sp, dp)) == NULL)
+		goto err;
+
+	if (fa_read_napt_entry(fai, tbl, napt->nfi.napt_idx) != BCME_OK) {
+		ET_ERROR(("%s: FA HW IPC not found\n", __FUNCTION__));
+		goto err;
+	}
+
+	/* update the hits counter */
+	hits = ((LTOH16(tbl[1]) & 0x7) << 29 | LTOH16(tbl[0]) >> 3);
+	if (napt->nfi.hits != hits) {
+		napt->nfi.hits = hits;
+		ipc->live = 1;
+	}
+err:
+
+	ETC_FA_UNLOCK(fai);
+}
+
+void
+fa_et_up(fa_t *fa)
+{
+	fa_info_t *fai = (fa_info_t *)fa;
+
+	if (!FA_IS_FA_DEV(fa))
+		return;
+
+	/* Enable AUX and et_up */
+	if (aux_dev) {
+		robo_fa_aux_enable(fai->robo, TRUE);
+		et_up(aux_dev->et);
+	}
+}
+
+void
+fa_et_down(fa_t *fa)
+{
+	fa_info_t *fai = (fa_info_t *)fa;
+
+	if (!FA_IS_FA_DEV(fa))
+		return;
+
+	/* Just disable AUX, FA interface GMAC reset disable FA function */
+	if (aux_dev)
+		robo_fa_aux_enable(fai->robo, FALSE);
+}
+
+void
+fa_set_aux_unit(si_t *sih, uint unit)
+{
+	bool fa_capable = FA_CAPABLE(fa_chip_rev(sih), sih->chip);
+
+	if (!fa_capable || (aux_unit != -1) || (unit == FA_FA_CORE_UNIT))
+		return;
+
+	aux_unit = unit;
+}
+
+char *
+fa_get_macaddr(si_t *sih, char *vars, uint unit)
+{
+	char *mac, name[128];
+	uint nvram_etunit = unit;
+	uint coreunit = fa_unit2core(unit);
+	bool fa_capable = FA_CAPABLE(fa_chip_rev(sih), sih->chip);
+
+	if (FA_ON_MODE_VALID() && fa_capable && FA_AUX_CORE(coreunit) &&
+	    getintvar(NULL, "ctf_fa_mode") == CTF_FA_NORMAL)
+		nvram_etunit = FA_FA_ENET_UNIT;
+
+	sprintf(name, "et%dmacaddr", nvram_etunit);
+	mac = getvar(vars, name);
+	if (mac == NULL) {
+		ET_ERROR(("et%d: et%dmacaddr not found, ignore it\n", unit, nvram_etunit));
+	}
+
+	return mac;
+}
+
+void
+fa_set_name(fa_t *fa, char *name)
+{
+	/* The ethernet network interface uses "eth%d" by default.
+	 * Replace the original value "eth%d" with "aux%d" for AUX device.
+	 */
+	if (FA_IS_AUX_DEV(fa)) {
+		if (strlen(name) == strlen(IF_NAME_ETH)) {
+			memcpy(name, "aux", 3);
+		} else {
+			ET_ERROR(("%s Unknown ethernet interface (%s)\n", __FUNCTION__, name));
+			ASSERT(0);
+		}
+	}
+}
+
+int
+fa_read_proc(char *buffer, char **start, off_t offset, int length, int *eof, void *data)
+{
+	int len;
+
+	if (offset > 0) {
+		*eof = 1;
+		return 0;
+	}
+
+	/* Give the processed buffer back to userland */
+	if (!length) {
+		ET_ERROR(("%s: Not enough return buf space\n", __FUNCTION__));
+		return 0;
+	}
+
+	len = sprintf(buffer, "%d\n", 1);
+	return len;
+}
+
+void
+fa_dump(fa_t *fa, struct bcmstrbuf *b, bool all)
+{
+	uint8 NF = all ? CTF_FA_DUMP_ALL_NF : CTF_FA_DUMP_VALID_NF;
+	uint8 NH = all ? CTF_FA_DUMP_ALL_NH : CTF_FA_DUMP_VALID_NH;
+	uint8 NP = all ? CTF_FA_DUMP_ALL_NP : CTF_FA_DUMP_VALID_NP;
+	fa_info_t *fai = (fa_info_t *)fa;
+
+	if (!fai || !b || FA_IS_AUX_DEV(fa))
+		return;
+
+	if (fai->acc_mode != CTF_FA_NORMAL) {
+		bcm_bprintf(b, "Not in FA Normal mode!\n");
+		return;
+	}
+
+	bcm_bprintf(b, "Number of flows: %d entries\n", fai->nflows);
+
+	fa_dump_entries(fai, NF, (print_buf_t) bcm_bprintf, b);
+	fa_dump_entries(fai, NH, (print_buf_t) bcm_bprintf, b);
+	fa_dump_entries(fai, NP, (print_buf_t) bcm_bprintf, b);
+}
+
+void
+fa_regs_show(fa_t *fa, struct bcmstrbuf *b)
+{
+#ifdef BCMDBG
+	osl_t *osh;
+	uint32 val, *reg;
+	int i, nregs = sizeof(fareg)/sizeof(fareg[0]);
+	fa_info_t *fai = (fa_info_t *)fa;
+
+	if (!fai || !b || FA_IS_AUX_DEV(fa))
+		return;
+
+	osh = si_osh(fai->sih);
+
+	bcm_bprintf(b, "\nFA regs dump\n");
+
+	bcm_bprintf(b, "Chip rev %d\n", fai->chiprev);
+	bcm_bprintf(b, "Accelerator mode: %s\n",
+		(fai->acc_mode == CTF_FA_BYPASS) ? "BYPASS" :
+		(fai->acc_mode == CTF_FA_NORMAL) ? "NORMAL" :
+		(fai->acc_mode == CTF_FA_SW_ACC) ? "SW" : "UNKNOWN");
+	bcm_bprintf(b, "Hash mode: %s\n", HW_HASH() ? "HW" : "SW");
+
+	/* reg dump */
+	for (i = 0; i < (nregs -4); i++) {
+		reg = (uint32 *)((unsigned long)(fai->regs) + fareg[i].reg_off);
+		bcm_bprintf(b, "%s(0x%p):0x%08x\n", fareg[i].reg_name, reg, R_REG(osh, reg));
+	}
+
+	/* statistic dump */
+	reg = (uint32 *)((unsigned long)(fai->regs) + OFFSETOF(faregs_t, stats));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "HITS", &reg[0], R_REG(osh, &reg[0]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "MISS", &reg[1], R_REG(osh, &reg[1]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "SNAP_FAIL", &reg[2], R_REG(osh, &reg[2]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "ETYPE_FAIL", &reg[3], R_REG(osh, &reg[3]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "VER_FAIL", &reg[4], R_REG(osh, &reg[4]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "FRAG_FAIL", &reg[5], R_REG(osh, &reg[5]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "PROTO_EXT_FAIL", &reg[6], R_REG(osh, &reg[6]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "V4_CSUM_FAIL", &reg[7], R_REG(osh, &reg[7]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "V4_OPTION_FAIL", &reg[8], R_REG(osh, &reg[8]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "V4_HDR_LEN_FAIL", &reg[9], R_REG(osh, &reg[9]));
+
+	reg = (uint32 *)((unsigned long)(fai->regs) + OFFSETOF(faregs_t, eccst));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "ECC_NAPT_FLOW_STAT", &reg[0], R_REG(osh, &reg[0]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "ECC_NEXT_HOP_STAT", &reg[1], R_REG(osh, &reg[1]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "ECC_HWQ_STAT", &reg[2], R_REG(osh, &reg[2]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "ECC_LAB_STAT", &reg[3], R_REG(osh, &reg[3]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "ECC_HB_STAT", &reg[4], R_REG(osh, &reg[4]));
+
+	reg = (uint32 *)((unsigned long)(fai->regs) + OFFSETOF(faregs_t, m_accdata));
+	CTF_FA_WAR777_ON(fai);
+	val = R_REG(osh, reg);
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "MEM_ACC_DATA7", &reg[7], R_REG(osh, &reg[7]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "MEM_ACC_DATA6", &reg[6], R_REG(osh, &reg[6]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "MEM_ACC_DATA5", &reg[5], R_REG(osh, &reg[5]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "MEM_ACC_DATA4", &reg[4], R_REG(osh, &reg[4]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "MEM_ACC_DATA3", &reg[3], R_REG(osh, &reg[3]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "MEM_ACC_DATA2", &reg[2], R_REG(osh, &reg[2]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "MEM_ACC_DATA1", &reg[1], R_REG(osh, &reg[1]));
+	bcm_bprintf(b, "%s(0x%p):0x%08x\n", "MEM_ACC_DATA0", &reg[0], R_REG(osh, &reg[0]));
+	CTF_FA_WAR777_OFF(fai);
+#endif /* BCMDBG */
+}
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_fa.h b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_fa.h
new file mode 100755
index 0000000000..2a07507b6a
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/etc_fa.h
@@ -0,0 +1,113 @@
+/*
+ * Flow Accelerator setup functions
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: $
+ */
+
+#ifndef _ETC_FA_H_
+#define _ETC_FA_H_
+
+#include <bcmutils.h>
+#include <siutils.h>
+#include <proto/bcmip.h>
+#include <proto/ethernet.h>
+#include <proto/vlan.h>
+#include <ctf/hndctf.h>
+
+typedef struct {
+	union {
+#ifdef BIG_ENDIAN
+		struct {
+			uint32_t	op_code		:3; /* 31:29 */
+			uint32_t	reserved	:5; /* 28:24 */
+			uint32_t	cl_id		:8; /* 23:16 */
+			uint32_t	reason_code	:8; /* 15:8  */
+			uint32_t	tc		:3; /* 7:5   */
+			uint32_t	src_pid		:5; /* 4:0   */
+		} oc0;
+		struct {
+			uint32_t	op_code		:3; /* 31:29 */
+			uint32_t	reserved	:2; /* 28:27 */
+			uint32_t	all_bkts_full	:1; /* 26    */
+			uint32_t	bkt_id		:2; /* 25:24 */
+			uint32_t	napt_flow_id	:8; /* 23:16 */
+			uint32_t	hdr_chk_result	:8; /* 15:8  */
+			uint32_t	tc		:3; /* 7:5   */
+			uint32_t	src_pid		:5; /* 4:0   */
+		} oc10;
+#else
+		struct {
+			uint32_t	src_pid		:5; /* 4:0   */
+			uint32_t	tc		:3; /* 7:5   */
+			uint32_t	reason_code	:8; /* 15:8  */
+			uint32_t	cl_id		:8; /* 23:16 */
+			uint32_t	reserved	:5; /* 28:24 */
+			uint32_t	op_code		:3; /* 31:29 */
+		} oc0;
+		struct {
+			uint32_t	src_pid		:5; /* 4:0   */
+			uint32_t	tc		:3; /* 7:5   */
+			uint32_t	hdr_chk_result	:8; /* 15:8  */
+			uint32_t	napt_flow_id	:8; /* 23:16 */
+			uint32_t	bkt_id		:2; /* 25:24 */
+			uint32_t	all_bkts_full	:1; /* 26    */
+			uint32_t	reserved	:2; /* 28:27 */
+			uint32_t	op_code		:3; /* 31:29 */
+		} oc10;
+#endif /* BIG_ENDIAN */
+		uint32_t word;
+	};
+} bcm_hdr_t;
+
+#define FA_777WAR_ENABLED	0x01
+#define FA_BCM_HDR_RX		0x02
+#define FA_BCM_HDR_TX		0x04
+#define FA_FA_DEV		0x08
+#define FA_AUX_DEV		0x10
+
+#define FA_TX_BCM_HDR(fa)	((fa) && ((fa)->flags & FA_BCM_HDR_TX))
+#define FA_RX_BCM_HDR(fa)	((fa) && ((fa)->flags & FA_BCM_HDR_RX))
+#define FA_IS_FA_DEV(fa)	((fa) && ((fa)->flags & FA_FA_DEV))
+#define FA_IS_AUX_DEV(fa)	((fa) && ((fa)->flags & FA_AUX_DEV))
+
+#define FA_CTF_CAPABLE_DEV(fa)	!FA_IS_AUX_DEV(fa)
+
+typedef struct fa_pub {
+	uint32	flags;
+} fa_t;
+
+extern fa_t *fa_attach(si_t *sih, void *et, char *vars, uint coreunit, void *robo);
+extern void fa_detach(fa_t *fa);
+extern int fa_enable_device(fa_t *fa);
+extern void *fa_process_tx(fa_t *fa, void *p);
+extern void fa_process_rx(fa_t *fa, void *p);
+extern uint32 fa_get_nid_rx(osl_t *osh, void *p, int bhdroff);
+extern int32 fa_napt_add(fa_t *fa, ctf_ipc_t *ipc, bool v6);
+extern int32 fa_napt_del(fa_t *fa, ctf_ipc_t *ipc, bool v6);
+extern void fa_napt_live(fa_t *fa, ctf_ipc_t *ipc, bool v6);
+extern void fa_conntrack(fa_t *fa, ctf_ipc_t *ipc, bool v6);
+extern void fa_et_up(fa_t *fa);
+extern void fa_et_down(fa_t *fa);
+extern void fa_set_name(fa_t *fa, char *name);
+extern void fa_set_aux_unit(si_t *sih, uint unit);
+extern char *fa_get_macaddr(si_t *sih, char *vars, uint unit);
+extern int fa_read_proc(char *buffer, char **start, off_t offset, int length,
+	int *eof, void *data);
+extern void fa_dump(fa_t *fai, struct bcmstrbuf *b, bool all);
+extern void fa_regs_show(fa_t *fai, struct bcmstrbuf *b);
+extern uint fa_core2unit(si_t *sih, uint coreunit);
+
+#endif /* _ETC_FA_H_ */
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/etcgmac.c b/release/src-rt-7.14.114.x/src/et/cfe/sys/etcgmac.c
new file mode 100644
index 0000000000..3a8b61e5b5
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/etcgmac.c
@@ -0,0 +1,2264 @@
+/*
+ * Broadcom Gigabit Ethernet MAC (Unimac) core.
+ *
+ * This file implements the chip-specific routines for the GMAC core.
+ *
+ * Copyright (C) 2015, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: etcgmac.c 523524 2014-12-31 02:48:08Z $
+ */
+
+#include <et_cfg.h>
+#include <typedefs.h>
+#include <osl.h>
+#include <bcmdefs.h>
+#include <bcmendian.h>
+#include <bcmutils.h>
+#include <bcmdevs.h>
+#include <bcmenetphy.h>
+#include <proto/ethernet.h>
+#include <proto/802.1d.h>
+#include <siutils.h>
+#include <sbhnddma.h>
+#include <sbchipc.h>
+#include <hnddma.h>
+#include <et_dbg.h>
+#include <hndsoc.h>
+#include <hndpmu.h>
+#include <bcmgmacmib.h>
+#include <gmac_common.h>
+#include <gmac_core.h>
+#include <et_export.h>		/* for et_phyxx() routines */
+#include <etcgmac.h>
+#include <bcmenetrxh.h>
+#include <bcmgmacrxh.h>
+
+#ifdef ETROBO
+#include <bcmrobo.h>
+#endif /* ETROBO */
+#ifdef ETADM
+#include <etc_adm.h>
+#endif /* ETADM */
+#ifdef ETFA
+#include <etc_fa.h>
+#endif /* ETFA */
+#include <hndfwd.h> /* BCM_GMAC3 */
+
+
+struct bcmgmac;	/* forward declaration */
+#define ch_t	struct bcmgmac
+#include <etc.h>
+
+#define GMAC_NS_COREREV(rev) ((rev == 4) || (rev == 5) || (rev == 7))
+
+/* private chip state */
+struct bcmgmac {
+	void 		*et;		/* pointer to et private state */
+	etc_info_t	*etc;		/* pointer to etc public state */
+
+	gmac_commonregs_t *regscomm; /* pointer to GMAC COMMON registers */
+	gmacregs_t	*regs;		/* pointer to chip registers */
+	osl_t 		*osh;		/* os handle */
+
+	void 		*etphy;		/* pointer to et for shared mdc/mdio contortion */
+
+	uint32		intstatus;	/* saved interrupt condition bits */
+	uint32		intmask;	/* current software interrupt mask */
+	uint32		def_intmask;	/* default interrupt mask */
+
+	hnddma_t	*di[NUMTXQ];	/* dma engine software state */
+
+	bool		mibgood;	/* true once mib registers have been cleared */
+	gmacmib_t	mib;		/* mib statistic counters */
+	si_t 		*sih;		/* si utils handle */
+
+	char		*vars;		/* sprom name=value */
+	uint		vars_size;
+
+	void		*adm;		/* optional admtek private data */
+	mcfilter_t	mf;		/* multicast filter */
+};
+
+/* local prototypes */
+static bool chipid(uint vendor, uint device);
+static void *chipattach(etc_info_t *etc, void *osh, void *regsva);
+static void chipdetach(ch_t *ch);
+static void chipreset(ch_t *ch);
+static void chipinit(ch_t *ch, uint options);
+static bool chiptx(ch_t *ch, void *p);
+static void *chiprx(ch_t *ch);
+static int  chiprxquota(ch_t *ch, int quota, void **rxpkts);
+static void chiprxlazy(ch_t *ch);
+static void chiprxfill(ch_t *ch);
+static int chipgetintrevents(ch_t *ch, bool in_isr);
+static bool chiperrors(ch_t *ch);
+static bool chipdmaerrors(ch_t *ch);
+static void chipintrson(ch_t *ch);
+static void chipintrsoff(ch_t *ch);
+static void chiptxreclaim(ch_t *ch, bool all);
+static void chiprxreclaim(ch_t *ch);
+static uint chipactiverxbuf(ch_t *ch);
+static void chipstatsupd(ch_t *ch);
+static void chipdumpmib(ch_t *ch, struct bcmstrbuf *b, bool clear);
+static void chipenablepme(ch_t *ch);
+static void chipdisablepme(ch_t *ch);
+static void chipconfigtimer(ch_t *ch, uint microsecs);
+static void chipphyreset(ch_t *ch, uint phyaddr);
+static uint16 chipphyrd(ch_t *ch, uint phyaddr, uint reg);
+static void chipphywr(ch_t *ch, uint phyaddr, uint reg, uint16 v);
+static uint chipmacrd(ch_t *ch, uint reg);
+static void chipmacwr(ch_t *ch, uint reg, uint val);
+static void chipdump(ch_t *ch, struct bcmstrbuf *b);
+static void chiplongname(ch_t *ch, char *buf, uint bufsize);
+static void chipduplexupd(ch_t *ch);
+
+static void chipphyinit(ch_t *ch, uint phyaddr);
+static void chipphyor(ch_t *ch, uint phyaddr, uint reg, uint16 v);
+static void chipphyforce(ch_t *ch, uint phyaddr);
+static void chipphyadvertise(ch_t *ch, uint phyaddr);
+#ifdef BCMDBG
+static void chipdumpregs(ch_t *ch, gmacregs_t *regs, struct bcmstrbuf *b);
+#endif /* BCMDBG */
+static void chipunitmap(uint coreunit, uint *unit);
+static void gmac_mf_cleanup(ch_t *ch);
+static int gmac_speed(ch_t *ch, uint32 speed);
+static void gmac_miiconfig(ch_t *ch);
+
+struct chops bcmgmac_et_chops = {
+	chipid,
+	chipattach,
+	chipdetach,
+	chipreset,
+	chipinit,
+	chiptx,
+	chiprx,
+	chiprxquota,
+	chiprxlazy,
+	chiprxfill,
+	chipgetintrevents,
+	chiperrors,
+	chipdmaerrors,
+	chipintrson,
+	chipintrsoff,
+	chiptxreclaim,
+	chiprxreclaim,
+	chipstatsupd,
+	chipdumpmib,
+	chipenablepme,
+	chipdisablepme,
+	chipconfigtimer,
+	chipphyreset,
+	chipphyrd,
+	chipphywr,
+	chipmacrd,
+	chipmacwr,
+	chipdump,
+	chiplongname,
+	chipduplexupd,
+	chipunitmap,
+	chipactiverxbuf
+};
+
+static uint devices[] = {
+	BCM47XX_GMAC_ID,
+	BCM4716_CHIP_ID,
+	BCM4748_CHIP_ID,
+	0x0000
+};
+
+static bool
+chipid(uint vendor, uint device)
+{
+	int i;
+
+	if (vendor != VENDOR_BROADCOM)
+		return (FALSE);
+
+	for (i = 0; devices[i]; i++) {
+		if (device == devices[i])
+			return (TRUE);
+	}
+
+	return (FALSE);
+}
+
+static void *
+chipattach(etc_info_t *etc, void *osh, void *regsva)
+{
+	ch_t *ch;
+	gmacregs_t *regs;
+	uint i;
+	char name[16];
+	char *var;
+	uint boardflags, boardtype, reset;
+	uint32 flagbits = 0;
+
+	ET_TRACE(("et%d: chipattach: regsva 0x%lx\n", etc->unit, (ulong)regsva));
+
+	if ((ch = (ch_t *)MALLOC(osh, sizeof(ch_t))) == NULL) {
+		ET_ERROR(("et%d: chipattach: out of memory, malloced %d bytes\n", etc->unit,
+		          MALLOCED(osh)));
+		return (NULL);
+	}
+	bzero((char *)ch, sizeof(ch_t));
+
+	ch->etc = etc;
+	ch->et = etc->et;
+	ch->osh = osh;
+
+	/* store the pointer to the sw mib */
+	etc->mib = (void *)&ch->mib;
+
+	/* get si handle */
+	if ((ch->sih = si_attach(etc->deviceid, ch->osh, regsva, PCI_BUS, NULL, &ch->vars,
+	                         &ch->vars_size)) == NULL) {
+		ET_ERROR(("et%d: chipattach: si_attach error\n", etc->unit));
+		goto fail;
+	}
+
+	if (si_corerev(ch->sih) == GMAC_4706B0_CORE_REV) {
+		etc->corerev = GMAC_4706B0_CORE_REV;
+		if ((ch->regscomm = (gmac_commonregs_t *)si_setcore(ch->sih,
+		    GMAC_COMMON_4706_CORE_ID, 0)) == NULL) {
+			ET_ERROR(("et%d: chipattach: Could not setcore to GMAC common\n",
+				etc->unit));
+			goto fail;
+		}
+	}
+
+	if ((regs = (gmacregs_t *)si_setcore(ch->sih, GMAC_CORE_ID, etc->coreunit)) == NULL) {
+		ET_ERROR(("et%d: chipattach: Could not setcore to GMAC\n", etc->unit));
+		goto fail;
+	}
+	if (etc->corerev != GMAC_4706B0_CORE_REV)
+		etc->corerev = si_corerev(ch->sih);
+
+	ch->regs = regs;
+	etc->chip = ch->sih->chip;
+	etc->chiprev = ch->sih->chiprev;
+	etc->chippkg = ch->sih->chippkg;
+	etc->coreid = si_coreid(ch->sih);
+	etc->nicmode = !(ch->sih->bustype == SI_BUS);
+	etc->gmac_fwd = FALSE;  /* BCM_GMAC3 */
+	etc->boardflags = getintvar(ch->vars, "boardflags");
+
+	boardflags = etc->boardflags;
+	boardtype = ch->sih->boardtype;
+
+	/* Backplane clock ticks per microsecs: used by gptimer, intrecvlazy */
+	etc->bp_ticks_usec = si_clock(ch->sih) / 1000000;
+
+#ifdef PKTC
+	etc->pktc = (getintvar(ch->vars, "pktc_disable") == 0) &&
+		(getintvar(ch->vars, "ctf_disable") == 0);
+#endif
+
+	/* get our local ether addr */
+#ifdef ETFA
+	var = fa_get_macaddr(ch->sih, ch->vars, etc->unit);
+#else
+	sprintf(name, "et%dmacaddr", etc->unit);
+	var = getvar(ch->vars, name);
+#endif /* ETFA */
+	if (var == NULL) {
+		ET_ERROR(("et%d: chipattach: getvar(%s) not found\n", etc->unit, name));
+		goto fail;
+	}
+	bcm_ether_atoe(var, &etc->perm_etheraddr);
+
+#if defined(BCM_GMAC3)
+	/*
+	 * Select GMAC mode of operation:
+	 * If a valid MAC address is present, it operates as an Ethernet Network
+	 * interface, otherwise it operates as a forwarding GMAC interface.
+	 */
+	if (ETHER_ISNULLADDR(&etc->perm_etheraddr)) {
+		etc->gmac_fwd = TRUE;
+	}
+#else  /* ! BCM_GMAC3 */
+	if (ETHER_ISNULLADDR(&etc->perm_etheraddr)) {
+		ET_ERROR(("et%d: chipattach: invalid format: %s=%s\n", etc->unit, name, var));
+		goto fail;
+	}
+#endif /* ! BCM_GMAC3 */
+
+	bcopy((char *)&etc->perm_etheraddr, (char *)&etc->cur_etheraddr, ETHER_ADDR_LEN);
+
+	/*
+	 * Too much can go wrong in scanning MDC/MDIO playing "whos my phy?" .
+	 * Instead, explicitly require the environment var "et<unit>phyaddr=<val>".
+	 */
+	if (BCM4707_CHIP(CHIPID(ch->sih->chip))) {
+		etc->phyaddr = EPHY_NOREG;
+	}
+	else {
+		sprintf(name, "et%dphyaddr", etc->unit);
+		var = getvar(ch->vars, name);
+		if (var == NULL) {
+			ET_ERROR(("et%d: chipattach: getvar(%s) not found\n", etc->unit, name));
+			goto fail;
+		}
+		etc->phyaddr = bcm_atoi(var) & EPHY_MASK;
+	}
+
+	/* nvram says no phy is present */
+	if (etc->phyaddr == EPHY_NONE) {
+		ET_ERROR(("et%d: chipattach: phy not present\n", etc->unit));
+		goto fail;
+	}
+
+	/* configure pci core */
+	si_pci_setup(ch->sih, (1 << si_coreidx(ch->sih)));
+
+	/* Northstar, take all GMAC cores out of reset */
+	if (BCM4707_CHIP(CHIPID(ch->sih->chip))) {
+		int ns_gmac;
+		for (ns_gmac = 0; ns_gmac < MAX_GMAC_CORES_4707; ns_gmac++) {
+			/* As northstar requirement, we have to reset all GAMCs before
+			 * accessing them. et_probe() call pci_enable_device() for etx
+			 * and do si_core_reset for GAMCx only.	 Then the other three
+			 * GAMCs didn't reset.  We do it here.
+			 */
+			si_setcore(ch->sih, GMAC_CORE_ID, ns_gmac);
+			if (!si_iscoreup(ch->sih)) {
+				ET_TRACE(("et%d: reset GMAC[%d] core\n", etc->unit, ns_gmac));
+				si_core_reset(ch->sih, flagbits, 0);
+			}
+		}
+		si_setcore(ch->sih, GMAC_CORE_ID, etc->coreunit);
+	}
+	/* reset the gmac core */
+	chipreset(ch);
+
+	/* dma attach */
+	sprintf(name, "etc%d", etc->coreunit);
+
+	/* allocate dma resources for txqs */
+	/* TX: TC_BK, RX: RX_Q0 */
+	ch->di[0] = dma_attach(osh, name, ch->sih,
+	                       DMAREG(ch, DMA_TX, TX_Q0),
+	                       DMAREG(ch, DMA_RX, RX_Q0),
+	                       NTXD, NRXD, RXBUFSZ, -1, NRXBUFPOST, HWRXOFF,
+	                       &et_msg_level);
+
+	/* TX: TC_BE, RX: UNUSED */
+	ch->di[1] = dma_attach(osh, name, ch->sih,
+	                       DMAREG(ch, DMA_TX, TX_Q1),
+	                       NULL /* rxq unused */,
+	                       NTXD, 0, 0, -1, 0, 0, &et_msg_level);
+
+	/* TX: TC_CL, RX: UNUSED */
+	ch->di[2] = dma_attach(osh, name, ch->sih,
+	                       DMAREG(ch, DMA_TX, TX_Q2),
+	                       NULL /* rxq unused */,
+	                       NTXD, 0, 0, -1, 0, 0, &et_msg_level);
+
+	/* TX: TC_VO, RX: UNUSED */
+	ch->di[3] = dma_attach(osh, name, ch->sih,
+	                       DMAREG(ch, DMA_TX, TX_Q3),
+	                       NULL /* rxq unused */,
+	                       NTXD, 0, 0, -1, 0, 0, &et_msg_level);
+
+	for (i = 0; i < NUMTXQ; i++)
+		if (ch->di[i] == NULL) {
+			ET_ERROR(("et%d: chipattach: dma_attach failed\n", etc->unit));
+			goto fail;
+		}
+
+	for (i = 0; i < NUMTXQ; i++)
+		if (ch->di[i] != NULL)
+			etc->txavail[i] = (uint *)&ch->di[i]->txavail;
+
+#ifndef _CFE_
+	/* override dma parameters, corerev 4 dma channel 1,2 and 3 default burstlen is 0. */
+	/* corerev 4,5: NS Ax; corerev 6: BCM43909 no HW prefetch; corerev 7: NS B0 */
+	if (etc->corerev == 4 ||
+	    etc->corerev == 5 ||
+	    etc->corerev == 7) {
+#define DMA_CTL_TX 0
+#define DMA_CTL_RX 1
+
+#define DMA_CTL_MR 0
+#define DMA_CTL_PC 1
+#define DMA_CTL_PT 2
+#define DMA_CTL_BL 3
+		static uint16 dmactl[2][4] = {
+			/* TX */
+			{ DMA_MR_2, DMA_PC_16, DMA_PT_8, DMA_BL_1024 },
+			{ 0, DMA_PC_16, DMA_PT_8, DMA_BL_128 },
+		};
+
+		dmactl[DMA_CTL_TX][DMA_CTL_MR] = (TXMR == 2 ? DMA_MR_2 : DMA_MR_1);
+
+		if (etc->corerev == 7) {
+			/* NS B0 can only be configured to DMA_PT_1 and DMA_PC_4 */
+			dmactl[DMA_CTL_TX][DMA_CTL_PT] = DMA_PT_1;
+			dmactl[DMA_CTL_TX][DMA_CTL_PC] = DMA_PC_4;
+		} else {
+			dmactl[DMA_CTL_TX][DMA_CTL_PT] = (TXPREFTHRESH == 8 ? DMA_PT_8 :
+				TXPREFTHRESH == 4 ? DMA_PT_4 :
+				TXPREFTHRESH == 2 ? DMA_PT_2 : DMA_PT_1);
+			dmactl[DMA_CTL_TX][DMA_CTL_PC] = (TXPREFCTL == 16 ? DMA_PC_16 :
+				TXPREFCTL == 8 ? DMA_PC_8 :
+				TXPREFCTL == 4 ? DMA_PC_4 : DMA_PC_0);
+		}
+
+		dmactl[DMA_CTL_TX][DMA_CTL_BL] = (TXBURSTLEN == 1024 ? DMA_BL_1024 :
+		                                  TXBURSTLEN == 512 ? DMA_BL_512 :
+		                                  TXBURSTLEN == 256 ? DMA_BL_256 :
+		                                  TXBURSTLEN == 128 ? DMA_BL_128 :
+		                                  TXBURSTLEN == 64 ? DMA_BL_64 :
+		                                  TXBURSTLEN == 32 ? DMA_BL_32 : DMA_BL_16);
+
+		dmactl[DMA_CTL_RX][DMA_CTL_PT] =  (RXPREFTHRESH == 8 ? DMA_PT_8 :
+		                                   RXPREFTHRESH == 4 ? DMA_PT_4 :
+		                                   RXPREFTHRESH == 2 ? DMA_PT_2 : DMA_PT_1);
+		dmactl[DMA_CTL_RX][DMA_CTL_PC] = (RXPREFCTL == 16 ? DMA_PC_16 :
+		                                  RXPREFCTL == 8 ? DMA_PC_8 :
+		                                  RXPREFCTL == 4 ? DMA_PC_4 : DMA_PC_0);
+		dmactl[DMA_CTL_RX][DMA_CTL_BL] = (RXBURSTLEN == 1024 ? DMA_BL_1024 :
+		                                  RXBURSTLEN == 512 ? DMA_BL_512 :
+		                                  RXBURSTLEN == 256 ? DMA_BL_256 :
+		                                  RXBURSTLEN == 128 ? DMA_BL_128 :
+		                                  RXBURSTLEN == 64 ? DMA_BL_64 :
+		                                  RXBURSTLEN == 32 ? DMA_BL_32 : DMA_BL_16);
+
+		for (i = 0; i < NUMTXQ; i++) {
+				dma_param_set(ch->di[i], HNDDMA_PID_TX_MULTI_OUTSTD_RD,
+				              dmactl[DMA_CTL_TX][DMA_CTL_MR]);
+				dma_param_set(ch->di[i], HNDDMA_PID_TX_PREFETCH_CTL,
+				              dmactl[DMA_CTL_TX][DMA_CTL_PC]);
+				dma_param_set(ch->di[i], HNDDMA_PID_TX_PREFETCH_THRESH,
+				              dmactl[DMA_CTL_TX][DMA_CTL_PT]);
+				dma_param_set(ch->di[i], HNDDMA_PID_TX_BURSTLEN,
+				              dmactl[DMA_CTL_TX][DMA_CTL_BL]);
+				dma_param_set(ch->di[i], HNDDMA_PID_RX_PREFETCH_CTL,
+				              dmactl[DMA_CTL_RX][DMA_CTL_PC]);
+				dma_param_set(ch->di[i], HNDDMA_PID_RX_PREFETCH_THRESH,
+				              dmactl[DMA_CTL_RX][DMA_CTL_PT]);
+				dma_param_set(ch->di[i], HNDDMA_PID_RX_BURSTLEN,
+				              dmactl[DMA_CTL_RX][DMA_CTL_BL]);
+		}
+	}
+#endif /* ! _CFE_ */
+
+	/* set default sofware intmask */
+	sprintf(name, "et%d_no_txint", etc->unit);
+	if (getintvar(ch->vars, name)) {
+		/* if no_txint variable is non-zero we disable tx interrupts.
+		 * we do the tx buffer reclaim once every few frames.
+		 */
+		ch->def_intmask = (DEF_INTMASK & ~(I_XI0 | I_XI1 | I_XI2 | I_XI3));
+		etc->txrec_thresh = (((NTXD >> 2) > TXREC_THR) ? TXREC_THR - 1 : 1);
+	} else
+		ch->def_intmask = DEF_INTMASK;
+
+	ch->intmask = ch->def_intmask;
+
+	/* reset the external phy */
+	if ((reset = getgpiopin(ch->vars, "ephy_reset", GPIO_PIN_NOTDEFINED)) !=
+	    GPIO_PIN_NOTDEFINED) {
+		reset = 1 << reset;
+
+		/* Keep RESET low for 2 us */
+		si_gpioout(ch->sih, reset, 0, GPIO_DRV_PRIORITY);
+		si_gpioouten(ch->sih, reset, reset, GPIO_DRV_PRIORITY);
+		OSL_DELAY(2);
+
+		/* Keep RESET high for at least 2 us */
+		si_gpioout(ch->sih, reset, reset, GPIO_DRV_PRIORITY);
+		OSL_DELAY(2);
+
+		/* if external phy is present enable auto-negotation and
+		 * advertise full capabilities as default config.
+		 */
+		ASSERT(etc->phyaddr != EPHY_NOREG);
+		etc->needautoneg = TRUE;
+		etc->advertise = (ADV_100FULL | ADV_100HALF | ADV_10FULL | ADV_10HALF);
+		etc->advertise2 = ADV_1000FULL;
+	}
+
+	/* reset phy: reset it once now */
+	chipphyreset(ch, etc->phyaddr);
+
+#ifdef ETROBO
+	/*
+	 * Broadcom Robo ethernet switch.
+	 */
+	if (DEV_NTKIF(etc) &&
+		(boardflags & BFL_ENETROBO) && (etc->phyaddr == EPHY_NOREG)) {
+
+		ET_TRACE(("et%d: chipattach: Calling robo attach\n", etc->unit));
+
+		/* Attach to the switch */
+		if (!(etc->robo = bcm_robo_attach(ch->sih, ch, ch->vars,
+		                                  (miird_f)bcmgmac_et_chops.phyrd,
+		                                  (miiwr_f)bcmgmac_et_chops.phywr))) {
+			ET_ERROR(("et%d: chipattach: robo_attach failed\n", etc->unit));
+			goto fail;
+		}
+		/* Enable the switch and set it to a known good state */
+		if (bcm_robo_enable_device(etc->robo)) {
+			ET_ERROR(("et%d: chipattach: robo_enable_device failed\n", etc->unit));
+			goto fail;
+		}
+		/* Configure the switch to do VLAN */
+		if ((boardflags & BFL_ENETVLAN) &&
+		    bcm_robo_config_vlan(etc->robo, etc->perm_etheraddr.octet)) {
+			ET_ERROR(("et%d: chipattach: robo_config_vlan failed\n", etc->unit));
+			goto fail;
+		}
+		/* Enable switching/forwarding */
+		if (bcm_robo_enable_switch(etc->robo)) {
+			ET_ERROR(("et%d: chipattach: robo_enable_switch failed\n", etc->unit));
+			goto fail;
+		}
+#ifdef PLC
+		/* Configure the switch port connected to PLC chipset */
+		robo_plc_hw_init(etc->robo);
+#endif /* PLC */
+	}
+#endif /* ETROBO */
+
+#ifdef ETADM
+	/*
+	 * ADMtek ethernet switch.
+	 */
+	if (boardflags & BFL_ENETADM) {
+		/* Attach to the device */
+		if (!(ch->adm = adm_attach(ch->sih, ch->vars))) {
+			ET_ERROR(("et%d: chipattach: adm_attach failed\n", etc->unit));
+			goto fail;
+		}
+		/* Enable the external switch and set it to a known good state */
+		if (adm_enable_device(ch->adm)) {
+			ET_ERROR(("et%d: chipattach: adm_enable_device failed\n", etc->unit));
+			goto fail;
+		}
+		/* Configure the switch */
+		if ((boardflags & BFL_ENETVLAN) && adm_config_vlan(ch->adm)) {
+			ET_ERROR(("et%d: chipattach: adm_config_vlan failed\n", etc->unit));
+			goto fail;
+		}
+	}
+#endif /* ETADM */
+
+#ifdef ETFA
+	/*
+	 * Broadcom FA.
+	 */
+	if (BCM4707_CHIP(CHIPID(ch->sih->chip))) {
+		/* Attach to the fa */
+		if ((etc->fa = fa_attach(ch->sih, ch->et, ch->vars, etc->coreunit, etc->robo))) {
+			ET_TRACE(("et%d: chipattach: Calling fa attach\n", etc->unit));
+			/* Enable the fa */
+			if (fa_enable_device(etc->fa)) {
+				ET_ERROR(("et%d: chipattach: fa_enable_device failed\n",
+					etc->unit));
+				goto fail;
+			}
+		}
+	}
+#endif /* ETFA */
+
+	return ((void *) ch);
+
+fail:
+	chipdetach(ch);
+	return (NULL);
+}
+
+static void
+chipdetach(ch_t *ch)
+{
+	int32 i;
+
+	ET_TRACE(("et%d: chipdetach\n", ch->etc->unit));
+
+	if (ch == NULL)
+		return;
+
+#ifdef ETROBO
+	/* free robo state */
+	if (ch->etc->robo)
+		bcm_robo_detach(ch->etc->robo);
+#endif /* ETROBO */
+
+#ifdef ETADM
+	/* free ADMtek state */
+	if (ch->adm)
+		adm_detach(ch->adm);
+#endif /* ETADM */
+
+#ifdef ETFA
+	/* free FA state */
+	fa_detach(ch->etc->fa);
+#endif /* ETFA */
+
+	/* free dma state */
+	for (i = 0; i < NUMTXQ; i++)
+		if (ch->di[i] != NULL) {
+			dma_detach(ch->di[i]);
+			ch->di[i] = NULL;
+		}
+
+	/* put the core back into reset */
+	/* For Northstar, should not disable any GMAC core */
+	if (ch->sih && !BCM4707_CHIP(CHIPID(ch->sih->chip)))
+		si_core_disable(ch->sih, 0);
+
+	ch->etc->mib = NULL;
+
+	/* free si handle */
+	si_detach(ch->sih);
+	ch->sih = NULL;
+
+	/* free vars */
+	if (ch->vars)
+		MFREE(ch->osh, ch->vars, ch->vars_size);
+
+	/* free chip private state */
+	MFREE(ch->osh, ch, sizeof(ch_t));
+}
+
+static void
+chiplongname(ch_t *ch, char *buf, uint bufsize)
+{
+	char *s;
+
+	switch (ch->etc->deviceid) {
+		case BCM47XX_GMAC_ID:
+		case BCM4716_CHIP_ID:
+		case BCM4748_CHIP_ID:
+		default:
+			s = "Broadcom BCM47XX 10/100/1000 Mbps Ethernet Controller";
+			break;
+	}
+
+	strncpy(buf, s, bufsize);
+	buf[bufsize - 1] = '\0';
+}
+
+static uint
+chipmacrd(ch_t *ch, uint offset)
+{
+	ASSERT(offset < 4096); /* GMAC Register space is 4K size */
+	return R_REG(ch->osh, (uint *)((uint)(ch->regs) + offset));
+}
+
+static void
+chipmacwr(ch_t *ch, uint offset, uint val)
+{
+	ASSERT(offset < 4096); /* GMAC Register space is 4K size */
+	W_REG(ch->osh, (uint *)((uint)(ch->regs) + offset), val);
+}
+
+static void
+chipdump(ch_t *ch, struct bcmstrbuf *b)
+{
+#ifdef BCMDBG
+	int32 i;
+
+	bcm_bprintf(b, "regs 0x%lx etphy 0x%lx ch->intstatus 0x%x intmask 0x%x\n",
+		(ulong)ch->regs, (ulong)ch->etphy, ch->intstatus, ch->intmask);
+	bcm_bprintf(b, "\n");
+
+	/* dma engine state */
+	for (i = 0; i < NUMTXQ; i++) {
+		dma_dump(ch->di[i], b, TRUE);
+		bcm_bprintf(b, "\n");
+	}
+
+	/* registers */
+	chipdumpregs(ch, ch->regs, b);
+	bcm_bprintf(b, "\n");
+
+	/* switch registers */
+#ifdef ETROBO
+	if (ch->etc->robo)
+		robo_dump_regs(ch->etc->robo, b);
+#endif /* ETROBO */
+#ifdef ETADM
+	if (ch->adm)
+		adm_dump_regs(ch->adm, b->buf);
+#endif /* ETADM */
+#ifdef ETFA
+	if (ch->etc->fa) {
+		/* dump entries */
+		fa_dump(ch->etc->fa, b, FALSE);
+		/* dump regs */
+		fa_regs_show(ch->etc->fa, b);
+	}
+#endif /* ETFA */
+#endif	/* BCMDBG */
+}
+
+#ifdef BCMDBG
+
+#define	PRREG(name)	bcm_bprintf(b, #name " 0x%x ", R_REG(ch->osh, &regs->name))
+#define	PRMIBREG(name)	bcm_bprintf(b, #name " 0x%x ", R_REG(ch->osh, &regs->mib.name))
+
+static void
+chipdumpregs(ch_t *ch, gmacregs_t *regs, struct bcmstrbuf *b)
+{
+	uint phyaddr;
+
+	phyaddr = ch->etc->phyaddr;
+
+	PRREG(devcontrol); PRREG(devstatus);
+	bcm_bprintf(b, "\n");
+	PRREG(biststatus);
+	bcm_bprintf(b, "\n");
+	PRREG(intstatus); PRREG(intmask); PRREG(gptimer);
+	bcm_bprintf(b, "\n");
+	PRREG(intrecvlazy);
+	bcm_bprintf(b, "\n");
+	PRREG(flowctlthresh); PRREG(wrrthresh); PRREG(gmac_idle_cnt_thresh);
+	bcm_bprintf(b, "\n");
+	if (ch->etc->corerev != GMAC_4706B0_CORE_REV) {
+		PRREG(phyaccess); PRREG(phycontrol);
+		bcm_bprintf(b, "\n");
+	}
+	PRREG(txqctl); PRREG(rxqctl);
+	bcm_bprintf(b, "\n");
+	PRREG(gpioselect); PRREG(gpio_output_en);
+	bcm_bprintf(b, "\n");
+	PRREG(clk_ctl_st); PRREG(pwrctl);
+	bcm_bprintf(b, "\n");
+
+	/* unimac registers */
+	if (!BCM4707_CHIP(CHIPID(ch->sih->chip))) {
+		/* BCM4707 doesn't has unimacversion register */
+		PRREG(unimacversion);
+	}
+	PRREG(hdbkpctl);
+	bcm_bprintf(b, "\n");
+	PRREG(cmdcfg);
+	bcm_bprintf(b, "\n");
+	PRREG(macaddrhigh); PRREG(macaddrlow);
+	bcm_bprintf(b, "\n");
+	PRREG(rxmaxlength); PRREG(pausequanta); PRREG(macmode);
+	bcm_bprintf(b, "\n");
+	PRREG(outertag); PRREG(innertag); PRREG(txipg); PRREG(pausectl);
+	bcm_bprintf(b, "\n");
+	PRREG(txflush); PRREG(rxstatus); PRREG(txstatus);
+	bcm_bprintf(b, "\n");
+
+	/* mib registers */
+	PRMIBREG(tx_good_octets); PRMIBREG(tx_good_pkts); PRMIBREG(tx_octets); PRMIBREG(tx_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(tx_broadcast_pkts); PRMIBREG(tx_multicast_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(tx_jabber_pkts); PRMIBREG(tx_oversize_pkts); PRMIBREG(tx_fragment_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(tx_underruns); PRMIBREG(tx_total_cols); PRMIBREG(tx_single_cols);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(tx_multiple_cols); PRMIBREG(tx_excessive_cols); PRMIBREG(tx_late_cols);
+	bcm_bprintf(b, "\n");
+	if (ch->etc->corerev != GMAC_4706B0_CORE_REV) {
+		PRMIBREG(tx_defered); PRMIBREG(tx_carrier_lost); PRMIBREG(tx_pause_pkts);
+		bcm_bprintf(b, "\n");
+	}
+
+	PRMIBREG(rx_good_octets); PRMIBREG(rx_good_pkts); PRMIBREG(rx_octets); PRMIBREG(rx_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(rx_broadcast_pkts); PRMIBREG(rx_multicast_pkts);
+	bcm_bprintf(b, "\n");
+	PRMIBREG(rx_jabber_pkts);
+	if (ch->etc->corerev != GMAC_4706B0_CORE_REV) {
+		PRMIBREG(rx_oversize_pkts); PRMIBREG(rx_fragment_pkts);
+		bcm_bprintf(b, "\n");
+		PRMIBREG(rx_missed_pkts); PRMIBREG(rx_crc_align_errs); PRMIBREG(rx_undersize);
+	}
+	bcm_bprintf(b, "\n");
+	if (ch->etc->corerev != GMAC_4706B0_CORE_REV) {
+		PRMIBREG(rx_crc_errs); PRMIBREG(rx_align_errs); PRMIBREG(rx_symbol_errs);
+		bcm_bprintf(b, "\n");
+		PRMIBREG(rx_pause_pkts); PRMIBREG(rx_nonpause_pkts);
+		bcm_bprintf(b, "\n");
+	}
+	if (phyaddr != EPHY_NOREG) {
+		/* print a few interesting phy registers */
+		bcm_bprintf(b, "phy0 0x%x phy1 0x%x phy2 0x%x phy3 0x%x\n",
+		               chipphyrd(ch, phyaddr, 0),
+		               chipphyrd(ch, phyaddr, 1),
+		               chipphyrd(ch, phyaddr, 2),
+		               chipphyrd(ch, phyaddr, 3));
+		bcm_bprintf(b, "phy4 0x%x phy5 0x%x phy24 0x%x phy25 0x%x\n",
+		               chipphyrd(ch, phyaddr, 4),
+		               chipphyrd(ch, phyaddr, 5),
+		               chipphyrd(ch, phyaddr, 24),
+		               chipphyrd(ch, phyaddr, 25));
+	}
+
+}
+#endif	/* BCMDBG */
+
+static void
+gmac_clearmib(ch_t *ch)
+{
+	volatile uint32 *ptr;
+
+	if (ch->etc->corerev == GMAC_4706B0_CORE_REV)
+		return;
+
+	/* enable clear on read */
+	OR_REG(ch->osh, &ch->regs->devcontrol, DC_MROR);
+
+	for (ptr = &ch->regs->mib.tx_good_octets; ptr <= &ch->regs->mib.rx_uni_pkts; ptr++) {
+		(void)R_REG(ch->osh, ptr);
+		if (ptr == &ch->regs->mib.tx_q3_octets_high)
+			ptr++;
+	}
+
+	return;
+}
+
+static void
+gmac_init_reset(ch_t *ch)
+{
+	OR_REG(ch->osh, &ch->regs->cmdcfg, CC_SR(ch->etc->corerev));
+	OSL_DELAY(GMAC_RESET_DELAY);
+}
+
+static void
+gmac_clear_reset(ch_t *ch)
+{
+	AND_REG(ch->osh, &ch->regs->cmdcfg, ~CC_SR(ch->etc->corerev));
+	OSL_DELAY(GMAC_RESET_DELAY);
+}
+
+static void
+gmac_reset(ch_t *ch)
+{
+	uint32 ocmdcfg, cmdcfg;
+
+	/* put the mac in reset */
+	gmac_init_reset(ch);
+
+	/* initialize default config */
+	ocmdcfg = cmdcfg = R_REG(ch->osh, &ch->regs->cmdcfg);
+
+	cmdcfg &= ~(CC_TE | CC_RE | CC_RPI | CC_TAI | CC_HD | CC_ML |
+	            CC_CFE | CC_RL | CC_RED | CC_PE | CC_TPI | CC_PAD_EN | CC_PF);
+	cmdcfg |= (CC_PROM | CC_NLC | CC_CFE | CC_TPI | CC_AT);
+
+	if (cmdcfg != ocmdcfg)
+		W_REG(ch->osh, &ch->regs->cmdcfg, cmdcfg);
+
+	/* bring mac out of reset */
+	gmac_clear_reset(ch);
+}
+
+static void
+gmac_promisc(ch_t *ch, bool mode)
+{
+	uint32 cmdcfg;
+
+	cmdcfg = R_REG(ch->osh, &ch->regs->cmdcfg);
+
+	/* put the mac in reset */
+	gmac_init_reset(ch);
+
+	/* enable or disable promiscuous mode */
+	if (mode)
+		cmdcfg |= CC_PROM;
+	else
+		cmdcfg &= ~CC_PROM;
+
+	W_REG(ch->osh, &ch->regs->cmdcfg, cmdcfg);
+
+	/* bring mac out of reset */
+	gmac_clear_reset(ch);
+}
+
+static int
+gmac_speed(ch_t *ch, uint32 speed)
+{
+	uint32 cmdcfg;
+	uint32 hd_ena = 0;
+
+	switch (speed) {
+		case ET_10HALF:
+			hd_ena = CC_HD;
+			/* FALLTHRU */
+
+		case ET_10FULL:
+			speed = 0;
+			break;
+
+		case ET_100HALF:
+			hd_ena = CC_HD;
+			/* FALLTHRU */
+
+		case ET_100FULL:
+			speed = 1;
+			break;
+
+		case ET_1000FULL:
+			speed = 2;
+			break;
+
+		case ET_1000HALF:
+			ET_ERROR(("et%d: gmac_speed: supports 1000 mbps full duplex only\n",
+			          ch->etc->unit));
+			return (FAILURE);
+
+		case ET_2500FULL:
+			speed = 3;
+			break;
+
+		default:
+			ET_ERROR(("et%d: gmac_speed: speed %d not supported\n",
+			          ch->etc->unit, speed));
+			return (FAILURE);
+	}
+
+	cmdcfg = R_REG(ch->osh, &ch->regs->cmdcfg);
+
+	/* put mac in reset */
+	gmac_init_reset(ch);
+
+	/* set the speed */
+	cmdcfg &= ~(CC_ES_MASK | CC_HD);
+	cmdcfg |= ((speed << CC_ES_SHIFT) | hd_ena);
+	W_REG(ch->osh, &ch->regs->cmdcfg, cmdcfg);
+
+	/* bring mac out of reset */
+	gmac_clear_reset(ch);
+
+	return (SUCCESS);
+}
+
+static void
+gmac_macloopback(ch_t *ch, bool on)
+{
+	uint32 ocmdcfg, cmdcfg;
+
+	ocmdcfg = cmdcfg = R_REG(ch->osh, &ch->regs->cmdcfg);
+
+	/* put mac in reset */
+	gmac_init_reset(ch);
+
+	/* set/clear the mac loopback mode */
+	if (on)
+		cmdcfg |= CC_ML;
+	else
+		cmdcfg &= ~CC_ML;
+
+	if (cmdcfg != ocmdcfg)
+		W_REG(ch->osh, &ch->regs->cmdcfg, cmdcfg);
+
+	/* bring mac out of reset */
+	gmac_clear_reset(ch);
+}
+
+static int
+gmac_loopback(ch_t *ch, uint32 mode)
+{
+	switch (mode) {
+		case LOOPBACK_MODE_DMA:
+			/* to enable loopback for any channel set the loopback
+			 * enable bit in xmt0control register.
+			 */
+			dma_fifoloopbackenable(ch->di[TX_Q0]);
+			break;
+
+		case LOOPBACK_MODE_MAC:
+			gmac_macloopback(ch, TRUE);
+			break;
+
+		case LOOPBACK_MODE_NONE:
+			gmac_macloopback(ch, FALSE);
+			break;
+
+		default:
+			ET_ERROR(("et%d: gmac_loopaback: Unknown loopback mode %d\n",
+			          ch->etc->unit, mode));
+			return (FAILURE);
+	}
+
+	return (SUCCESS);
+}
+
+static void
+gmac_enable(ch_t *ch)
+{
+	uint32 cmdcfg, rxqctl, bp_clk, mdp, mode;
+	gmacregs_t *regs;
+
+	regs = ch->regs;
+
+	cmdcfg = R_REG(ch->osh, &ch->regs->cmdcfg);
+
+	/* put mac in reset */
+	gmac_init_reset(ch);
+
+	cmdcfg |= CC_SR(ch->etc->corerev);
+
+	/* first deassert rx_ena and tx_ena while in reset */
+	cmdcfg &= ~(CC_RE | CC_TE);
+	W_REG(ch->osh, &regs->cmdcfg, cmdcfg);
+
+	/* bring mac out of reset */
+	gmac_clear_reset(ch);
+
+	/* enable the mac transmit and receive paths now */
+	OSL_DELAY(2);
+	cmdcfg &= ~CC_SR(ch->etc->corerev);
+	cmdcfg |= (CC_RE | CC_TE);
+
+	/* assert rx_ena and tx_ena when out of reset to enable the mac */
+	W_REG(ch->osh, &regs->cmdcfg, cmdcfg);
+
+	/* WAR to not force ht for 47162 when gmac is in rev mii mode */
+	mode = ((R_REG(ch->osh, &regs->devstatus) & DS_MM_MASK) >> DS_MM_SHIFT);
+	if ((CHIPID(ch->sih->chip) != BCM47162_CHIP_ID) || (mode != 0))
+		/* request ht clock */
+		OR_REG(ch->osh, &regs->clk_ctl_st, CS_FH);
+
+	if (PMUCTL_ENAB(ch->sih) && (CHIPID(ch->sih->chip) == BCM47162_CHIP_ID) && (mode == 2))
+		si_pmu_chipcontrol(ch->sih, PMU_CHIPCTL1, PMU_CC1_RXC_DLL_BYPASS,
+		                   PMU_CC1_RXC_DLL_BYPASS);
+
+	/* Set the GMAC flowcontrol on and off thresholds and pause retry timer
+	 * the thresholds are tuned based on size of buffer internal to GMAC.
+	 */
+	if ((CHIPID(ch->sih->chip) == BCM5357_CHIP_ID) ||
+	    (CHIPID(ch->sih->chip) == BCM4749_CHIP_ID) ||
+	    (CHIPID(ch->sih->chip) == BCM53572_CHIP_ID) ||
+	    (CHIPID(ch->sih->chip) == BCM4716_CHIP_ID) ||
+	    (CHIPID(ch->sih->chip) == BCM47162_CHIP_ID)) {
+		uint32 flctl = 0x03cb04cb;
+
+		if ((CHIPID(ch->sih->chip) == BCM5357_CHIP_ID) ||
+		    (CHIPID(ch->sih->chip) == BCM4749_CHIP_ID) ||
+		    (CHIPID(ch->sih->chip) == BCM53572_CHIP_ID))
+			flctl = 0x2300e1;
+
+		W_REG(ch->osh, &regs->flowctlthresh, flctl);
+		W_REG(ch->osh, &regs->pausectl, 0x27fff);
+	}
+
+	/* To prevent any risk of the BCM4707 ROM mdp issue we saw in the QT,
+	 * we use the mdp register default value
+	 */
+	if (!BCM4707_CHIP(CHIPID(ch->sih->chip))) {
+		/* init the mac data period. the value is set according to expr
+		 * ((128ns / bp_clk) - 3).
+		 */
+		rxqctl = R_REG(ch->osh, &regs->rxqctl);
+		rxqctl &= ~RC_MDP_MASK;
+
+		bp_clk = si_clock(ch->sih) / 1000000;
+		mdp = ((bp_clk * 128) / 1000) - 3;
+		W_REG(ch->osh, &regs->rxqctl, rxqctl | (mdp << RC_MDP_SHIFT));
+	}
+
+	return;
+}
+
+static void
+gmac_txflowcontrol(ch_t *ch, bool on)
+{
+	uint32 cmdcfg;
+
+	cmdcfg = R_REG(ch->osh, &ch->regs->cmdcfg);
+
+	/* put the mac in reset */
+	gmac_init_reset(ch);
+
+	/* to enable tx flow control clear the rx pause ignore bit */
+	if (on)
+		cmdcfg &= ~CC_RPI;
+	else
+		cmdcfg |= CC_RPI;
+
+	W_REG(ch->osh, &ch->regs->cmdcfg, cmdcfg);
+
+	/* bring mac out of reset */
+	gmac_clear_reset(ch);
+}
+
+static void
+gmac_miiconfig(ch_t *ch)
+{
+	/* BCM4707 GMAC DevStatus register has different definition of "Interface Mode"
+	 * Bit 12:8  "interface_mode"  This field is programmed through IDM control bits [6:2]
+	 *
+	 * Bit 0 : SOURCE_SYNC_MODE_EN - If set, Rx line clock input will be used by Unimac for
+	 *          sampling data.If this is reset, PLL reference clock (Clock 250 or Clk 125 based
+	 *          on CLK_250_SEL) will be used as receive side line clock.
+	 * Bit 1 : DEST_SYNC_MODE_EN - If this is reset, PLL reference clock input (Clock 250 or
+	 *          Clk 125 based on CLK_250_SEL) will be used as transmit line clock.
+	 *          If this is set, TX line clock input (from external switch/PHY) is used as
+	 *          transmit line clock.
+	 * Bit 2 : TX_CLK_OUT_INVERT_EN - If set, this will invert the TX clock out of AMAC.
+	 * Bit 3 : DIRECT_GMII_MODE - If direct gmii is set to 0, then only 25 MHz clock needs to
+	 *          be fed at 25MHz reference clock input, for both 10/100 Mbps speeds.
+	 *          Unimac will internally divide the clock to 2.5 MHz for 10 Mbps speed
+	 * Bit 4 : CLK_250_SEL - When set, this selects 250Mhz reference clock input and hence
+	 *          Unimac line rate will be 2G.
+	 *          If reset, this selects 125MHz reference clock input.
+	 */
+	if (BCM4707_CHIP(CHIPID(ch->sih->chip))) {
+		if (ch->etc->phyaddr == EPHY_NOREG) {
+			si_core_cflags(ch->sih, 0x44, 0x44);
+			gmac_speed(ch, ET_2500FULL);
+			ch->etc->speed = 2500;
+			ch->etc->duplex = 1;
+		}
+	} else {
+		uint32 devstatus, mode;
+		gmacregs_t *regs;
+
+		regs = ch->regs;
+
+		/* Read the devstatus to figure out the configuration
+		 * mode of the interface.
+		 */
+		devstatus = R_REG(ch->osh, &regs->devstatus);
+		mode = ((devstatus & DS_MM_MASK) >> DS_MM_SHIFT);
+
+		/* Set the speed to 100 if the switch interface is
+		 * using mii/rev mii.
+		 */
+		if ((mode == 0) || (mode == 1)) {
+			if (ch->etc->forcespeed == ET_AUTO) {
+				gmac_speed(ch, ET_100FULL);
+				ch->etc->speed = 100;
+				ch->etc->duplex = 1;
+			} else
+				gmac_speed(ch, ch->etc->forcespeed);
+		} else {
+			if (ch->etc->phyaddr == EPHY_NOREG) {
+				ch->etc->speed = 1000;
+				ch->etc->duplex = 1;
+			}
+		}
+	}
+}
+
+static void
+chipreset(ch_t *ch)
+{
+	gmacregs_t *regs;
+	uint32 i, sflags, flagbits = 0;
+
+	ET_TRACE(("et%d: chipreset\n", ch->etc->unit));
+
+	regs = ch->regs;
+
+	if (!si_iscoreup(ch->sih)) {
+		if (!ch->etc->nicmode)
+			si_pci_setup(ch->sih, (1 << si_coreidx(ch->sih)));
+		/* power on reset: reset the enet core */
+		goto chipinreset;
+	}
+
+	/* update software counters before resetting the chip */
+	if (ch->mibgood)
+		chipstatsupd(ch);
+
+	/* reset the tx dma engines */
+	for (i = 0; i < NUMTXQ; i++) {
+		if (ch->di[i]) {
+			ET_TRACE(("et%d: resetting tx dma%d\n", ch->etc->unit, i));
+			dma_txreset(ch->di[i]);
+		}
+	}
+
+	/* set gmac into loopback mode to ensure no rx traffic */
+	gmac_loopback(ch, LOOPBACK_MODE_MAC);
+	OSL_DELAY(1);
+
+	/* reset the rx dma engine */
+	if (ch->di[RX_Q0]) {
+		ET_TRACE(("et%d: resetting rx dma\n", ch->etc->unit));
+		dma_rxreset(ch->di[RX_Q0]);
+	}
+
+	/* clear the multicast filter table */
+	gmac_mf_cleanup(ch);
+
+chipinreset:
+	sflags = si_core_sflags(ch->sih, 0, 0);
+	/* Do not enable internal switch for 47186/47188 */
+	if ((((CHIPID(ch->sih->chip) == BCM5357_CHIP_ID) ||
+	      (CHIPID(ch->sih->chip) == BCM4749_CHIP_ID)) &&
+	     (ch->sih->chippkg == BCM47186_PKG_ID)) ||
+	    ((CHIPID(ch->sih->chip) == BCM53572_CHIP_ID) && (ch->sih->chippkg == BCM47188_PKG_ID)))
+		sflags &= ~SISF_SW_ATTACHED;
+
+	if (sflags & SISF_SW_ATTACHED) {
+		ET_TRACE(("et%d: internal switch attached\n", ch->etc->unit));
+		flagbits = SICF_SWCLKE;
+		if (!ch->etc->robo) {
+			ET_TRACE(("et%d: reseting switch\n", ch->etc->unit));
+			flagbits |= SICF_SWRST;
+		}
+	}
+
+	/* 3GMAC: for BCM4707 and BCM47094, only do core reset at chipattach */
+	if ((CHIPID(ch->sih->chip) != BCM4707_CHIP_ID) &&
+	    (CHIPID(ch->sih->chip) != BCM47094_CHIP_ID)) {
+		/* reset core */
+		si_core_reset(ch->sih, flagbits, 0);
+	}
+
+	/* Request Misc PLL for corerev > 2 */
+	if (ch->etc->corerev > 2 && !BCM4707_CHIP(CHIPID(ch->sih->chip))) {
+		OR_REG(ch->osh, &regs->clk_ctl_st, CS_ER);
+		SPINWAIT((R_REG(ch->osh, &regs->clk_ctl_st) & CS_ES) != CS_ES, 1000);
+	}
+
+	if ((CHIPID(ch->sih->chip) == BCM5357_CHIP_ID) ||
+	    (CHIPID(ch->sih->chip) == BCM4749_CHIP_ID) ||
+	    (CHIPID(ch->sih->chip) == BCM53572_CHIP_ID)) {
+		char *var;
+		uint32 sw_type = PMU_CC1_SW_TYPE_EPHY | PMU_CC1_IF_TYPE_MII;
+
+		if ((var = getvar(ch->vars, "et_swtype")) != NULL)
+			sw_type = (bcm_atoi(var) & 0x0f) << 4;
+		else if ((CHIPID(ch->sih->chip) == BCM5357_CHIP_ID) &&
+		         (ch->sih->chippkg == BCM5358_PKG_ID))
+			sw_type = PMU_CC1_SW_TYPE_EPHYRMII;
+		else if (((CHIPID(ch->sih->chip) != BCM53572_CHIP_ID) &&
+		          (ch->sih->chippkg == BCM47186_PKG_ID)) ||
+		         ((CHIPID(ch->sih->chip) == BCM53572_CHIP_ID) &&
+		          (ch->sih->chippkg == BCM47188_PKG_ID)) ||
+		         (ch->sih->chippkg == HWSIM_PKG_ID))
+			sw_type = PMU_CC1_IF_TYPE_RGMII|PMU_CC1_SW_TYPE_RGMII;
+
+		ET_TRACE(("%s: sw_type %04x\n", __FUNCTION__, sw_type));
+		if (PMUCTL_ENAB(ch->sih)) {
+			si_pmu_chipcontrol(ch->sih, PMU_CHIPCTL1,
+				(PMU_CC1_IF_TYPE_MASK|PMU_CC1_SW_TYPE_MASK),
+				sw_type);
+		}
+	}
+
+	if ((sflags & SISF_SW_ATTACHED) && (!ch->etc->robo)) {
+		ET_TRACE(("et%d: taking switch out of reset\n", ch->etc->unit));
+		si_core_cflags(ch->sih, SICF_SWRST, 0);
+	}
+
+	/* reset gmac */
+	gmac_reset(ch);
+
+	/* clear mib */
+	gmac_clearmib(ch);
+	ch->mibgood = TRUE;
+
+	if (ch->etc->corerev == GMAC_4706B0_CORE_REV)
+		OR_REG(ch->osh, &ch->regscomm->phycontrol, PC_MTE);
+	else
+		OR_REG(ch->osh, &regs->phycontrol, PC_MTE);
+
+	/* Read the devstatus to figure out the configuration mode of
+	 * the interface. Set the speed to 100 if the switch interface
+	 * is mii/rmii.
+	 */
+	gmac_miiconfig(ch);
+
+#if !defined(_CFE_) && defined(BCM47XX_CA9)
+	if (OSL_ACP_WAR_ENAB() || OSL_ARCH_IS_COHERENT()) {
+		uint32 mask = (0xf << 16) | (0xf << 7) | (0x1f << 25) | (0x1f << 20);
+		uint32 val = (0xb << 16) | (0x7 << 7) | (0x1 << 25) | (0x1 << 20);
+		/* si_core_cflags to change ARCACHE[19:16] to 0xb, and AWCACHE[10:7] to 0x7,
+		 * ARUSER[29:25] to 0x1, and AWUSER [24:20] to 0x1
+		 */
+		si_core_cflags(ch->sih, mask, val);
+	}
+#endif /* !_CFE_ && BCM47XX_CA9 */
+
+	/* gmac doesn't have internal phy */
+	chipphyinit(ch, ch->etc->phyaddr);
+
+	/* clear persistent sw intstatus */
+	ch->intstatus = 0;
+}
+
+/*
+ * Lookup a multicast address in the filter hash table.
+ */
+static int
+gmac_mf_lkup(ch_t *ch, struct ether_addr *mcaddr)
+{
+	mflist_t *ptr;
+
+	/* find the multicast address */
+	for (ptr = ch->mf.bucket[GMAC_MCADDR_HASH(mcaddr)]; ptr != NULL; ptr = ptr->next) {
+		if (!ETHER_MCADDR_CMP(&ptr->mc_addr, mcaddr))
+			return (SUCCESS);
+	}
+
+	return (FAILURE);
+}
+
+/*
+ * Add a multicast address to the filter hash table.
+ */
+static int
+gmac_mf_add(ch_t *ch, struct ether_addr *mcaddr)
+{
+	uint32 hash;
+	mflist_t *entry;
+#ifdef BCMDBG
+	char mac[ETHER_ADDR_STR_LEN];
+#endif /* BCMDBG */
+
+	/* add multicast addresses only */
+	if (!ETHER_ISMULTI(mcaddr)) {
+		ET_ERROR(("et%d: adding invalid multicast address %s\n",
+		          ch->etc->unit, bcm_ether_ntoa(mcaddr, mac)));
+		return (FAILURE);
+	}
+
+	/* discard duplicate add requests */
+	if (gmac_mf_lkup(ch, mcaddr) == SUCCESS) {
+		ET_ERROR(("et%d: adding duplicate mcast filter entry\n", ch->etc->unit));
+		return (FAILURE);
+	}
+
+	/* allocate memory for list entry */
+	entry = MALLOC(ch->osh, sizeof(mflist_t));
+	if (entry == NULL) {
+		ET_ERROR(("et%d: out of memory allocating mcast filter entry\n", ch->etc->unit));
+		return (FAILURE);
+	}
+
+	/* add the entry to the hash bucket */
+	ether_copy(mcaddr, &entry->mc_addr);
+	hash = GMAC_MCADDR_HASH(mcaddr);
+	entry->next = ch->mf.bucket[hash];
+	ch->mf.bucket[hash] = entry;
+
+	return (SUCCESS);
+}
+
+/*
+ * Cleanup the multicast filter hash table.
+ */
+static void
+gmac_mf_cleanup(ch_t *ch)
+{
+	mflist_t *ptr, *tmp;
+	int32 i;
+
+	for (i = 0; i < GMAC_HASHT_SIZE; i++) {
+		ptr = ch->mf.bucket[i];
+		while (ptr) {
+			tmp = ptr;
+			ptr = ptr->next;
+			MFREE(ch->osh, tmp, sizeof(mflist_t));
+		}
+		ch->mf.bucket[i] = NULL;
+	}
+}
+
+/*
+ * Initialize all the chip registers.  If dma mode, init tx and rx dma engines
+ * but leave the devcontrol tx and rx (fifos) disabled.
+ */
+static void
+chipinit(ch_t *ch, uint options)
+{
+	etc_info_t *etc;
+	gmacregs_t *regs;
+	uint idx;
+	uint i;
+
+	regs = ch->regs;
+	etc = ch->etc;
+	idx = 0;
+
+	ET_TRACE(("et%d: chipinit\n", etc->unit));
+
+	/* enable one rx interrupt per received frame */
+	W_REG(ch->osh, &regs->intrecvlazy, (1 << IRL_FC_SHIFT));
+
+	/* enable 802.3x tx flow control (honor received PAUSE frames) */
+	gmac_txflowcontrol(ch, TRUE);
+
+	/* enable/disable promiscuous mode */
+	gmac_promisc(ch, etc->promisc);
+
+	/* set our local address */
+	W_REG(ch->osh, &regs->macaddrhigh,
+	      hton32(*(uint32 *)&etc->cur_etheraddr.octet[0]));
+	W_REG(ch->osh, &regs->macaddrlow,
+	      hton16(*(uint16 *)&etc->cur_etheraddr.octet[4]));
+
+	if (!etc->promisc) {
+		/* gmac doesn't have a cam, hence do the multicast address filtering
+		 * in the software
+		 */
+		/* allmulti or a list of discrete multicast addresses */
+		if (!etc->allmulti && etc->nmulticast)
+			for (i = 0; i < etc->nmulticast; i++)
+				(void)gmac_mf_add(ch, &etc->multicast[i]);
+	}
+
+	/* optionally enable mac-level loopback */
+	if (etc->loopbk)
+		gmac_loopback(ch, LOOPBACK_MODE_MAC);
+	else
+		gmac_loopback(ch, LOOPBACK_MODE_NONE);
+
+	/* set max frame lengths - account for possible vlan tag */
+	W_REG(ch->osh, &regs->rxmaxlength, ETHER_MAX_LEN + 32);
+
+	/*
+	 * Optionally, disable phy autonegotiation and force our speed/duplex
+	 * or constrain our advertised capabilities.
+	 */
+	if (etc->forcespeed != ET_AUTO) {
+		gmac_speed(ch, etc->forcespeed);
+		chipphyforce(ch, etc->phyaddr);
+	} else if (etc->advertise && etc->needautoneg)
+		chipphyadvertise(ch, etc->phyaddr);
+
+	/* NS B0 only enables 4 entries x 4 channels */
+	if (etc->corerev == 7)
+		OR_REG(ch->osh, &regs->pwrctl, 0x1);
+
+	/* enable the overflow continue feature and disable parity */
+	dma_ctrlflags(ch->di[0], DMA_CTRL_ROC | DMA_CTRL_PEN | DMA_CTRL_RXSINGLE /* mask */,
+	              DMA_CTRL_ROC | DMA_CTRL_RXSINGLE /* value */);
+
+	if (options & ET_INIT_FULL) {
+		/* initialize the tx and rx dma channels */
+		for (i = 0; i < NUMTXQ; i++)
+			dma_txinit(ch->di[i]);
+		dma_rxinit(ch->di[RX_Q0]);
+
+		/* post dma receive buffers */
+		dma_rxfill(ch->di[RX_Q0]);
+
+		/* lastly, enable interrupts */
+		if (options & ET_INIT_INTRON)
+			et_intrson(etc->et);
+	}
+	else
+		dma_rxenable(ch->di[RX_Q0]);
+
+	/* turn on the emac */
+	gmac_enable(ch);
+}
+
+/* dma transmit */
+static bool BCMFASTPATH
+chiptx(ch_t *ch, void *p0)
+{
+	int error, len;
+	uint32 q = TX_Q0;
+
+	ET_TRACE(("et%d: chiptx\n", ch->etc->unit));
+	ET_LOG("et%d: chiptx", ch->etc->unit, 0);
+
+#ifdef ETROBO
+	if ((ch->etc->robo != NULL) &&
+	    (((robo_info_t *)ch->etc->robo)->devid == DEVID53115)) {
+		void *p = p0;
+
+		if ((p0 = etc_bcm53115_war(ch->etc, p)) == NULL) {
+			PKTFREE(ch->osh, p, TRUE);
+			return FALSE;
+		}
+	}
+#endif /* ETROBO */
+
+	len = PKTLEN(ch->osh, p0);
+
+	/* check tx max length */
+	if (len > (ETHER_MAX_LEN + 32)) {
+		ET_ERROR(("et%d: chiptx: max frame length exceeded\n",
+		          ch->etc->unit));
+		PKTFREE(ch->osh, p0, TRUE);
+		return FALSE;
+	}
+
+	if ((len < GMAC_MIN_FRAMESIZE) && (ch->etc->corerev == 0))
+		PKTSETLEN(ch->osh, p0, GMAC_MIN_FRAMESIZE);
+
+	/* queue the packet based on its priority */
+	if (ch->etc->qos) {
+		if (ch->etc->corerev != 4 && ch->etc->corerev != 5) {
+			q = etc_up2tc(PKTPRIO(p0));
+		}
+		else {
+			q = TC_BE;
+		}
+	}
+
+	ASSERT(q < NUMTXQ);
+
+	/* if tx completion intr is disabled then do the reclaim
+	 * once every few frames transmitted.
+	 */
+	if ((ch->etc->txframes[q] & ch->etc->txrec_thresh) == 1)
+		dma_txreclaim(ch->di[q], HNDDMA_RANGE_TRANSMITTED);
+
+#if defined(_CFE_) || defined(__NetBSD__)
+	error = dma_txfast(ch->di[q], p0, TRUE);
+#else
+#ifdef PKTC
+#define DMA_COMMIT	((PKTCFLAGS(p0) & 1) != 0)
+#else
+#define DMA_COMMIT	(TRUE)
+#endif
+	error = dma_txfast(ch->di[q], p0, DMA_COMMIT);
+#endif /* defined(_CFE_) || defined(__NetBSD__) */
+
+	if (error) {
+		ET_ERROR(("et%d: chiptx: out of txds\n", ch->etc->unit));
+		ch->etc->txnobuf++;
+		return FALSE;
+	}
+
+	ch->etc->txframes[q]++;
+
+	/* set back the orig length */
+	if (len < GMAC_MIN_FRAMESIZE)
+		PKTSETLEN(ch->osh, p0, len);
+
+	return TRUE;
+}
+
+/* reclaim completed transmit descriptors and packets */
+static void BCMFASTPATH
+chiptxreclaim(ch_t *ch, bool forceall)
+{
+	int32 i;
+
+	ET_TRACE(("et%d: chiptxreclaim\n", ch->etc->unit));
+
+	for (i = 0; i < NUMTXQ; i++) {
+		if (*(uint *)(ch->etc->txavail[i]) < NTXD)
+			dma_txreclaim(ch->di[i], forceall ? HNDDMA_RANGE_ALL :
+			                                    HNDDMA_RANGE_TRANSMITTED);
+		ch->intstatus &= ~(I_XI0 << i);
+	}
+}
+
+/* dma receive: returns a pointer to the next frame received, or NULL if there are no more */
+static void * BCMFASTPATH
+chiprx(ch_t *ch)
+{
+	void *p;
+	struct ether_addr *da;
+
+	ET_TRACE(("et%d: chiprx\n", ch->etc->unit));
+	ET_LOG("et%d: chiprx", ch->etc->unit, 0);
+
+	/* gmac doesn't have a cam to do address filtering. so we implement
+	 * the multicast address filtering here.
+	 */
+	while ((p = dma_rx(ch->di[RX_Q0])) != NULL) {
+		/* check for overflow error packet */
+		if (RXH_FLAGS(ch->etc, PKTDATA(ch->osh, p)) & htol16(GRXF_OVF)) {
+			ET_ERROR(("et%d: chiprx, dma overflow\n", ch->etc->unit));
+			PKTFREE(ch->osh, p, FALSE);
+			ch->etc->rxoflodiscards++;
+			continue;
+		}
+
+		if (ch->etc->allmulti) {
+			return (p);
+		}
+		else {
+			/* skip the rx header */
+			PKTPULL(ch->osh, p, HWRXOFF);
+
+			/* do filtering only for multicast packets when allmulti is false */
+			da = (struct ether_addr *)PKTDATA(ch->osh, p);
+			if (!ETHER_ISMULTI(da) ||
+			    (gmac_mf_lkup(ch, da) == SUCCESS) || ETHER_ISBCAST(da)) {
+				PKTPUSH(ch->osh, p, HWRXOFF);
+				return (p);
+			}
+			PKTFREE(ch->osh, p, FALSE);
+		}
+	}
+
+	ch->intstatus &= ~I_RI;
+
+	/* post more rx buffers since we consumed a few */
+	dma_rxfill(ch->di[RX_Q0]);
+
+	return (NULL);
+}
+
+static int BCMFASTPATH /* dma receive quota number of pkts */
+chiprxquota(ch_t *ch, int quota, void **rxpkts)
+{
+	int rxcnt;
+	void * pkt;
+	uint8 * rxh;
+	hnddma_t * di_rx_q0;
+
+	ET_TRACE(("et%d: chiprxquota %d\n", ch->etc->unit, quota));
+	ET_LOG("et%d: chiprxquota", ch->etc->unit, 0);
+
+	rxcnt = 0;
+	di_rx_q0 = ch->di[RX_Q0];
+
+	/* Fetch quota number of pkts (or ring empty) */
+	while ((rxcnt < quota) && ((pkt = dma_rx(di_rx_q0)) != NULL)) {
+		rxh = PKTDATA(ch->osh, pkt); /* start of pkt data */
+
+#if !defined(_CFE_)
+		bcm_prefetch_32B(rxh + 32, 1); /* skip 30B of HWRXOFF */
+#endif /* _CFE_ */
+
+#if defined(BCM_GMAC3)
+		if (GMAC_RXH_FLAGS(rxh)) { /* rx error reported in rxheader */
+			et_discard(ch->etc->et, pkt); /* handoff to port layer */
+			continue; /* do not increment rxcnt */
+		}
+#endif /* BCM_GMAC3 */
+
+		rxpkts[rxcnt] = pkt;
+		rxcnt++;
+	}
+
+	/* This pass is not on the tput performance path! */
+	if (!ch->etc->allmulti) { /* SW Filter all configured mf EthDA(s) */
+		struct ether_addr *da;
+		int nrx;
+		int mfpass = 0; /* pkts that passed mf lkup */
+
+		for (nrx = 0; nrx < rxcnt; nrx++) {
+			pkt = rxpkts[nrx];
+			da = (struct ether_addr *)(PKTDATA(ch->osh, pkt) + HWRXOFF);
+			if (!ETHER_ISMULTI(da) || ETHER_ISBCAST(da) ||
+				(gmac_mf_lkup(ch, da) == SUCCESS)) {
+				rxpkts[mfpass++] = pkt; /* repack rxpkts array */
+			} else {
+				PKTFREE(ch->osh, pkt, FALSE);
+			}
+		}
+
+		rxcnt = mfpass;
+	}
+
+	/* post more rx buffers since we consumed a few */
+	dma_rxfill(di_rx_q0);
+
+	if (rxcnt < quota) { /* ring is "possibly" empty, enable et interrupts */
+		ch->intstatus &= ~I_RI;
+	}
+
+	return rxcnt; /* rxpkts[] has rxcnt number of pkts to be processed */
+}
+
+static void BCMFASTPATH
+chiprxlazy(ch_t *ch)
+{
+	uint reg_val = ((ch->etc->rxlazy_timeout & IRL_TO_MASK) |
+	                (ch->etc->rxlazy_framecnt << IRL_FC_SHIFT));
+	W_REG(ch->osh, &ch->regs->intrecvlazy, reg_val);
+}
+
+
+/* reclaim completed dma receive descriptors and packets */
+static void
+chiprxreclaim(ch_t *ch)
+{
+	ET_TRACE(("et%d: chiprxreclaim\n", ch->etc->unit));
+	dma_rxreclaim(ch->di[RX_Q0]);
+	ch->intstatus &= ~I_RI;
+}
+
+/* calculate the number of free dma receive descriptors */
+static uint BCMFASTPATH
+chipactiverxbuf(ch_t *ch)
+{
+	ET_TRACE(("et%d: chipactiverxbuf\n", ch->etc->unit));
+	ET_LOG("et%d: chipactiverxbuf", ch->etc->unit, 0);
+	return dma_activerxbuf(ch->di[RX_Q0]);
+}
+
+/* allocate and post dma receive buffers */
+static void BCMFASTPATH
+chiprxfill(ch_t *ch)
+{
+	ET_TRACE(("et%d: chiprxfill\n", ch->etc->unit));
+	ET_LOG("et%d: chiprx", ch->etc->unit, 0);
+	dma_rxfill(ch->di[RX_Q0]);
+}
+
+/* get current and pending interrupt events */
+static int BCMFASTPATH
+chipgetintrevents(ch_t *ch, bool in_isr)
+{
+	uint32 intstatus;
+	int events;
+
+	events = 0;
+
+	/* read the interrupt status register */
+	intstatus = R_REG(ch->osh, &ch->regs->intstatus);
+
+	/* defer unsolicited interrupts */
+	intstatus &= (in_isr ? ch->intmask : ch->def_intmask);
+
+	if (intstatus != 0)
+		events = INTR_NEW;
+
+	/* or new bits into persistent intstatus */
+	intstatus = (ch->intstatus |= intstatus);
+
+	/* return if no events */
+	if (intstatus == 0)
+		return (0);
+
+	/* convert chip-specific intstatus bits into generic intr event bits */
+#if defined(BCM_GMAC3)
+	if (intstatus & I_TO) {
+		events |= INTR_TO;                          /* post to et_dpc */
+
+		W_REG(ch->osh, &ch->regs->intstatus, I_TO); /* explicitly ack I_TO */
+		ch->intstatus &= ~(I_TO);                   /* handled in et_linux */
+	}
+#endif /* BCM_GMAC3 */
+
+	if (intstatus & I_RI)
+		events |= INTR_RX;
+	if (intstatus & (I_XI0 | I_XI1 | I_XI2 | I_XI3))
+		events |= INTR_TX;
+#if defined(_CFE_)
+	if (intstatus & ~(I_RDU | I_RFO) & I_ERRORS)
+#else
+	if (intstatus & I_ERRORS)
+#endif
+		events |= INTR_ERROR;
+
+	return (events);
+}
+
+/* enable chip interrupts */
+static void BCMFASTPATH
+chipintrson(ch_t *ch)
+{
+	ch->intmask = ch->def_intmask;
+	W_REG(ch->osh, &ch->regs->intmask, ch->intmask);
+}
+
+/* disable chip interrupts */
+static void BCMFASTPATH
+chipintrsoff(ch_t *ch)
+{
+	/* disable further interrupts from gmac */
+#if defined(BCM_GMAC3)
+	ch->intmask = I_TO;	/* Do not disable GPtimer Interrupt */
+#else  /* ! BCM_GMAC3 */
+	ch->intmask = 0;
+#endif /* ! BCM_GMAC3 */
+
+	W_REG(ch->osh, &ch->regs->intmask, ch->intmask);
+	(void) R_REG(ch->osh, &ch->regs->intmask);	/* sync readback */
+
+	/* clear the interrupt conditions */
+	W_REG(ch->osh, &ch->regs->intstatus, ch->intstatus);
+}
+
+/* return true of caller should re-initialize, otherwise false */
+static bool BCMFASTPATH
+chiperrors(ch_t *ch)
+{
+	uint32 intstatus;
+	etc_info_t *etc;
+
+	etc = ch->etc;
+
+	intstatus = ch->intstatus;
+	ch->intstatus &= ~(I_ERRORS);
+
+	ET_TRACE(("et%d: chiperrors: intstatus 0x%x\n", etc->unit, intstatus));
+
+	if (intstatus & I_PDEE) {
+		ET_ERROR(("et%d: descriptor error\n", etc->unit));
+		etc->dmade++;
+	}
+
+	if (intstatus & I_PDE) {
+		ET_ERROR(("et%d: data error\n", etc->unit));
+		etc->dmada++;
+	}
+
+	if (intstatus & I_DE) {
+		ET_ERROR(("et%d: descriptor protocol error\n", etc->unit));
+		etc->dmape++;
+	}
+
+	if (intstatus & I_RDU) {
+		ET_ERROR(("et%d: receive descriptor underflow\n", etc->unit));
+		etc->rxdmauflo++;
+	}
+
+	if (intstatus & I_RFO) {
+		ET_TRACE(("et%d: receive fifo overflow\n", etc->unit));
+		etc->rxoflo++;
+	}
+
+	if (intstatus & I_XFU) {
+		ET_ERROR(("et%d: transmit fifo underflow\n", etc->unit));
+		etc->txuflo++;
+	}
+
+	/* if overflows or decriptors underflow, don't report it
+	 * as an error and provoque a reset
+	 */
+	if (intstatus & ~(I_RDU | I_RFO) & I_ERRORS) {
+		return (TRUE);
+	}
+
+	return (FALSE);
+}
+
+static bool
+chipdmaerrors(ch_t *ch)
+{
+	return dma_rxtxerror(ch->di[TX_Q1], TRUE);
+}
+
+static void
+chipstatsupd(ch_t *ch)
+{
+	etc_info_t *etc;
+	gmacregs_t *regs;
+	volatile uint32 *s;
+	uint32 *d;
+
+	etc = ch->etc;
+	regs = ch->regs;
+
+	/* read the mib counters and update the driver maintained software
+	 * counters.
+	 */
+	if (etc->corerev != GMAC_4706B0_CORE_REV) {
+		OR_REG(ch->osh, &regs->devcontrol, DC_MROR);
+		for (s = &regs->mib.tx_good_octets, d = &ch->mib.tx_good_octets;
+		     s <= &regs->mib.rx_uni_pkts; s++, d++) {
+			*d += R_REG(ch->osh, s);
+			if (s == &ch->regs->mib.tx_q3_octets_high) {
+				s++;
+				d++;
+			}
+		}
+	}
+
+
+	/*
+	 * Aggregate transmit and receive errors that probably resulted
+	 * in the loss of a frame are computed on the fly.
+	 *
+	 * We seem to get lots of tx_carrier_lost errors when flipping
+	 * speed modes so don't count these as tx errors.
+	 *
+	 * Arbitrarily lump the non-specific dma errors as tx errors.
+	 */
+	etc->rxgiants = (ch->di[RX_Q0])->rxgiants;
+	etc->txerror = ch->mib.tx_jabber_pkts + ch->mib.tx_oversize_pkts
+		+ ch->mib.tx_underruns + ch->mib.tx_excessive_cols
+		+ ch->mib.tx_late_cols + etc->txnobuf + etc->dmade
+		+ etc->dmada + etc->dmape + etc->txuflo;
+	etc->rxerror = ch->mib.rx_jabber_pkts + ch->mib.rx_oversize_pkts
+		+ ch->mib.rx_missed_pkts + ch->mib.rx_crc_align_errs
+		+ ch->mib.rx_undersize + ch->mib.rx_crc_errs
+		+ ch->mib.rx_align_errs + ch->mib.rx_symbol_errs
+		+ etc->rxnobuf + etc->rxdmauflo + etc->rxoflo + etc->rxbadlen + etc->rxgiants;
+}
+
+static void
+chipdumpmib(ch_t *ch, struct bcmstrbuf *b, bool clear)
+{
+	gmacmib_t *m;
+
+	m = &ch->mib;
+
+	if (clear) {
+		bzero((char *)m, sizeof(gmacmib_t));
+		return;
+	}
+
+	bcm_bprintf(b, "tx_broadcast_pkts %d tx_multicast_pkts %d tx_jabber_pkts %d "
+	               "tx_oversize_pkts %d\n",
+	               m->tx_broadcast_pkts, m->tx_multicast_pkts,
+	               m->tx_jabber_pkts,
+	               m->tx_oversize_pkts);
+	bcm_bprintf(b, "tx_fragment_pkts %d tx_underruns %d\n",
+	               m->tx_fragment_pkts, m->tx_underruns);
+	bcm_bprintf(b, "tx_total_cols %d tx_single_cols %d tx_multiple_cols %d "
+	               "tx_excessive_cols %d\n",
+	               m->tx_total_cols, m->tx_single_cols, m->tx_multiple_cols,
+	               m->tx_excessive_cols);
+	bcm_bprintf(b, "tx_late_cols %d tx_defered %d tx_carrier_lost %d tx_pause_pkts %d\n",
+	               m->tx_late_cols, m->tx_defered, m->tx_carrier_lost,
+	               m->tx_pause_pkts);
+
+	/* receive stat counters */
+	/* hardware mib pkt and octet counters wrap too quickly to be useful */
+	bcm_bprintf(b, "rx_broadcast_pkts %d rx_multicast_pkts %d rx_jabber_pkts %d "
+	               "rx_oversize_pkts %d\n",
+	               m->rx_broadcast_pkts, m->rx_multicast_pkts,
+	               m->rx_jabber_pkts, m->rx_oversize_pkts);
+	bcm_bprintf(b, "rx_fragment_pkts %d rx_missed_pkts %d rx_crc_align_errs %d "
+	               "rx_undersize %d\n",
+	               m->rx_fragment_pkts, m->rx_missed_pkts,
+	               m->rx_crc_align_errs, m->rx_undersize);
+	bcm_bprintf(b, "rx_crc_errs %d rx_align_errs %d rx_symbol_errs %d\n",
+	               m->rx_crc_errs, m->rx_align_errs, m->rx_symbol_errs);
+	bcm_bprintf(b, "rx_pause_pkts %d rx_nonpause_pkts %d\n",
+	               m->rx_pause_pkts, m->rx_nonpause_pkts);
+}
+
+static void
+chipenablepme(ch_t *ch)
+{
+	return;
+}
+
+static void
+chipdisablepme(ch_t *ch)
+{
+	return;
+}
+
+static void
+chipduplexupd(ch_t *ch)
+{
+	uint32 cmdcfg;
+	int32 duplex, speed;
+
+	cmdcfg = R_REG(ch->osh, &ch->regs->cmdcfg);
+
+	/* check if duplex mode changed */
+	if (ch->etc->duplex && (cmdcfg & CC_HD))
+		duplex = 0;
+	else if (!ch->etc->duplex && ((cmdcfg & CC_HD) == 0))
+		duplex = CC_HD;
+	else
+		duplex = -1;
+
+	/* check if the speed changed */
+	speed = ((cmdcfg & CC_ES_MASK) >> CC_ES_SHIFT);
+	if ((ch->etc->speed == 1000) && (speed != 2))
+		speed = 2;
+	else if ((ch->etc->speed == 100) && (speed != 1))
+		speed = 1;
+	else if ((ch->etc->speed == 10) && (speed != 0))
+		speed = 0;
+	else
+		speed = -1;
+
+	/* no duplex or speed change required */
+	if ((speed == -1) && (duplex == -1))
+		return;
+
+	/* update the speed */
+	if (speed != -1) {
+		cmdcfg &= ~CC_ES_MASK;
+		cmdcfg |= (speed << CC_ES_SHIFT);
+	}
+
+	/* update the duplex mode */
+	if (duplex != -1) {
+		cmdcfg &= ~CC_HD;
+		cmdcfg |= duplex;
+	}
+
+	ET_TRACE(("chipduplexupd: updating speed & duplex %x\n", cmdcfg));
+
+	/* put mac in reset */
+	gmac_init_reset(ch);
+
+	W_REG(ch->osh, &ch->regs->cmdcfg, cmdcfg);
+
+	/* bring mac out of reset */
+	gmac_clear_reset(ch);
+}
+
+static uint16
+chipphyrd(ch_t *ch, uint phyaddr, uint reg)
+{
+	uint32 tmp;
+	gmacregs_t *regs;
+	uint32 *phycontrol_addr, *phyaccess_addr;
+
+	if (GMAC_NS_COREREV(ch->etc->corerev)) {
+		ET_ERROR(("et%d: chipphyrd: not supported\n", ch->etc->unit));
+		return 0;
+	}
+
+	ASSERT(phyaddr < MAXEPHY);
+	ASSERT(reg < MAXPHYREG);
+
+	regs = ch->regs;
+
+	if (ch->etc->corerev == GMAC_4706B0_CORE_REV) {
+		phycontrol_addr = (uint32 *)&ch->regscomm->phycontrol;
+		phyaccess_addr = (uint32 *)&ch->regscomm->phyaccess;
+	} else {
+		phycontrol_addr = (uint32 *)&regs->phycontrol;
+		phyaccess_addr = (uint32 *)&regs->phyaccess;
+	}
+
+	/* issue the read */
+	tmp = R_REG(ch->osh, phycontrol_addr);
+	tmp &= ~0x1f;
+	tmp |= phyaddr;
+	W_REG(ch->osh, phycontrol_addr, tmp);
+	W_REG(ch->osh, phyaccess_addr,
+	      (PA_START | (phyaddr << PA_ADDR_SHIFT) | (reg << PA_REG_SHIFT)));
+
+	/* wait for it to complete */
+	SPINWAIT((R_REG(ch->osh, phyaccess_addr) & PA_START), 1000);
+	tmp = R_REG(ch->osh, phyaccess_addr);
+	if (tmp & PA_START) {
+		ET_ERROR(("et%d: chipphyrd: did not complete\n", ch->etc->unit));
+		tmp = 0xffff;
+	}
+
+	return (tmp & PA_DATA_MASK);
+}
+
+static void
+chipphywr(ch_t *ch, uint phyaddr, uint reg, uint16 v)
+{
+	uint32 tmp;
+	gmacregs_t *regs;
+	uint32 *phycontrol_addr, *phyaccess_addr;
+
+	if (GMAC_NS_COREREV(ch->etc->corerev)) {
+		ET_ERROR(("et%d: chipphywr: not supported\n", ch->etc->unit));
+		return;
+	}
+
+	ASSERT(phyaddr < MAXEPHY);
+	ASSERT(reg < MAXPHYREG);
+
+	regs = ch->regs;
+
+	if (ch->etc->corerev == GMAC_4706B0_CORE_REV) {
+		phycontrol_addr = (uint32 *)&ch->regscomm->phycontrol;
+		phyaccess_addr = (uint32 *)&ch->regscomm->phyaccess;
+	} else {
+		phycontrol_addr = (uint32 *)&regs->phycontrol;
+		phyaccess_addr = (uint32 *)&regs->phyaccess;
+	}
+
+	/* clear mdioint bit of intstatus first  */
+	tmp = R_REG(ch->osh, phycontrol_addr);
+	tmp &= ~0x1f;
+	tmp |= phyaddr;
+	W_REG(ch->osh, phycontrol_addr, tmp);
+	W_REG(ch->osh, &regs->intstatus, I_MDIO);
+	ASSERT((R_REG(ch->osh, &regs->intstatus) & I_MDIO) == 0);
+
+	/* issue the write */
+	W_REG(ch->osh, phyaccess_addr,
+	      (PA_START | PA_WRITE | (phyaddr << PA_ADDR_SHIFT) | (reg << PA_REG_SHIFT) | v));
+
+	/* wait for it to complete */
+	SPINWAIT((R_REG(ch->osh, phyaccess_addr) & PA_START), 1000);
+	if (R_REG(ch->osh, phyaccess_addr) & PA_START) {
+		ET_ERROR(("et%d: chipphywr: did not complete\n", ch->etc->unit));
+	}
+}
+
+static void
+chipphyor(ch_t *ch, uint phyaddr, uint reg, uint16 v)
+{
+	uint16 tmp;
+
+	tmp = chipphyrd(ch, phyaddr, reg);
+	tmp |= v;
+	chipphywr(ch, phyaddr, reg, tmp);
+}
+
+static void
+chipconfigtimer(ch_t *ch, uint microsecs)
+{
+	ASSERT(ch->etc->bp_ticks_usec != 0);
+
+	/* Enable general purpose timer in periodic mode */
+	W_REG(ch->osh, &ch->regs->gptimer, microsecs * ch->etc->bp_ticks_usec);
+}
+
+static void
+chipphyreset(ch_t *ch, uint phyaddr)
+{
+	ASSERT(phyaddr < MAXEPHY);
+
+	if (phyaddr == EPHY_NOREG)
+		return;
+
+	ET_TRACE(("et%d: chipphyreset: phyaddr %d\n", ch->etc->unit, phyaddr));
+
+	chipphywr(ch, phyaddr, 0, CTL_RESET);
+	OSL_DELAY(100);
+	if (chipphyrd(ch, phyaddr, 0) & CTL_RESET) {
+		ET_ERROR(("et%d: chipphyreset: reset not complete\n", ch->etc->unit));
+	}
+
+	chipphyinit(ch, phyaddr);
+}
+
+static void
+chipphyinit(ch_t *ch, uint phyaddr)
+{
+	if (CHIPID(ch->sih->chip) == BCM5356_CHIP_ID) {
+		int i;
+
+		for (i = 0; i < 5; i++) {
+			chipphywr(ch, i, 0x1f, 0x008b);
+			chipphywr(ch, i, 0x15, 0x0100);
+			chipphywr(ch, i, 0x1f, 0x000f);
+			chipphywr(ch, i, 0x12, 0x2aaa);
+			chipphywr(ch, i, 0x1f, 0x000b);
+		}
+	}
+
+	if ((((CHIPID(ch->sih->chip) == BCM5357_CHIP_ID) ||
+	      (CHIPID(ch->sih->chip) == BCM4749_CHIP_ID)) &&
+	     (ch->sih->chippkg != BCM47186_PKG_ID)) ||
+	    ((CHIPID(ch->sih->chip) == BCM53572_CHIP_ID) &&
+	     (ch->sih->chippkg != BCM47188_PKG_ID))) {
+		int i;
+
+		/* Clear ephy power down bits in case it was set for coma mode */
+		if (PMUCTL_ENAB(ch->sih)) {
+			si_pmu_chipcontrol(ch->sih, 2, 0xc0000000, 0);
+			si_pmu_chipcontrol(ch->sih, 4, 0x80000000, 0);
+		}
+
+		for (i = 0; i < 5; i++) {
+			chipphywr(ch, i, 0x1f, 0x000f);
+			chipphywr(ch, i, 0x16, 0x5284);
+			chipphywr(ch, i, 0x1f, 0x000b);
+			chipphywr(ch, i, 0x17, 0x0010);
+			chipphywr(ch, i, 0x1f, 0x000f);
+			chipphywr(ch, i, 0x16, 0x5296);
+			chipphywr(ch, i, 0x17, 0x1073);
+			chipphywr(ch, i, 0x17, 0x9073);
+			chipphywr(ch, i, 0x16, 0x52b6);
+			chipphywr(ch, i, 0x17, 0x9273);
+			chipphywr(ch, i, 0x1f, 0x000b);
+		}
+	}
+
+	if (phyaddr == EPHY_NOREG)
+		return;
+
+	ET_TRACE(("et%d: chipphyinit: phyaddr %d\n", ch->etc->unit, phyaddr));
+}
+
+static void
+chipphyforce(ch_t *ch, uint phyaddr)
+{
+	etc_info_t *etc;
+	uint16 ctl;
+
+	ASSERT(phyaddr < MAXEPHY);
+
+	if (phyaddr == EPHY_NOREG)
+		return;
+
+	etc = ch->etc;
+
+	if (etc->forcespeed == ET_AUTO)
+		return;
+
+	ET_TRACE(("et%d: chipphyforce: phyaddr %d speed %d\n",
+	          ch->etc->unit, phyaddr, etc->forcespeed));
+
+	ctl = chipphyrd(ch, phyaddr, 0);
+	ctl &= ~(CTL_SPEED | CTL_SPEED_MSB | CTL_ANENAB | CTL_DUPLEX);
+
+	switch (etc->forcespeed) {
+		case ET_10HALF:
+			break;
+
+		case ET_10FULL:
+			ctl |= CTL_DUPLEX;
+			break;
+
+		case ET_100HALF:
+			ctl |= CTL_SPEED_100;
+			break;
+
+		case ET_100FULL:
+			ctl |= (CTL_SPEED_100 | CTL_DUPLEX);
+			break;
+
+		case ET_1000FULL:
+			ctl |= (CTL_SPEED_1000 | CTL_DUPLEX);
+			break;
+	}
+
+	chipphywr(ch, phyaddr, 0, ctl);
+}
+
+/* set selected capability bits in autonegotiation advertisement */
+static void
+chipphyadvertise(ch_t *ch, uint phyaddr)
+{
+	etc_info_t *etc;
+	uint16 adv, adv2;
+
+	ASSERT(phyaddr < MAXEPHY);
+
+	if (phyaddr == EPHY_NOREG)
+		return;
+
+	etc = ch->etc;
+
+	if ((etc->forcespeed != ET_AUTO) || !etc->needautoneg)
+		return;
+
+	ASSERT(etc->advertise);
+
+	ET_TRACE(("et%d: chipphyadvertise: phyaddr %d advertise %x\n",
+	          ch->etc->unit, phyaddr, etc->advertise));
+
+	/* reset our advertised capabilitity bits */
+	adv = chipphyrd(ch, phyaddr, 4);
+	adv &= ~(ADV_100FULL | ADV_100HALF | ADV_10FULL | ADV_10HALF);
+	adv |= etc->advertise;
+	chipphywr(ch, phyaddr, 4, adv);
+
+	adv2 = chipphyrd(ch, phyaddr, 9);
+	adv2 &= ~(ADV_1000FULL | ADV_1000HALF);
+	adv2 |= etc->advertise2;
+	chipphywr(ch, phyaddr, 9, adv2);
+
+	ET_TRACE(("et%d: chipphyadvertise: phyaddr %d adv %x adv2 %x phyad0 %x\n",
+	          ch->etc->unit, phyaddr, adv, adv2, chipphyrd(ch, phyaddr, 0)));
+
+	/* restart autonegotiation */
+	chipphyor(ch, phyaddr, 0, CTL_RESTART);
+
+	etc->needautoneg = FALSE;
+}
+
+void
+chipunitmap(uint coreunit, uint *unit)
+{
+#ifdef ETFA
+	*unit = fa_core2unit(si_kattach(SI_OSH), coreunit);
+#endif
+}
diff --git a/release/src-rt-7.14.114.x/src/et/cfe/sys/etcgmac.h b/release/src-rt-7.14.114.x/src/et/cfe/sys/etcgmac.h
new file mode 100644
index 0000000000..646ce98532
--- /dev/null
+++ b/release/src-rt-7.14.114.x/src/et/cfe/sys/etcgmac.h
@@ -0,0 +1,72 @@
+/*
+ * Broadcom Gigabit Ethernet MAC defines.
+ *
+ * Copyright (C) 2014, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ * $Id: etcgmac.h 458392 2014-02-26 21:19:35Z $
+ */
+#ifndef _etcgmac_h_
+#define _etcgmac_h_
+
+/* chip interrupt bit error summary */
+#define	I_ERRORS		(I_PDEE | I_PDE | I_DE | I_RDU | I_RFO | I_XFU)
+
+#if defined(BCM_GMAC3)
+#define	DEF_INTMASK		(I_XI0 | I_XI1 | I_XI2 | I_XI3 | I_RI | I_ERRORS | I_TO)
+#else  /* ! BCM_GMAC3 */
+#define DEF_INTMASK     (I_XI0 | I_XI1 | I_XI2 | I_XI3 | I_RI | I_ERRORS)
+#endif /* ! BCM_GMAC3 */
+
+#define GMAC_RESET_DELAY 	2
+
+#define GMAC_MIN_FRAMESIZE	17	/* gmac can only send frames of
+	                                 * size above 17 octetes.
+	                                 */
+
+#define LOOPBACK_MODE_DMA	0	/* loopback the packet at the DMA engine */
+#define LOOPBACK_MODE_MAC	1	/* loopback the packet at MAC */
+#define LOOPBACK_MODE_NONE	2	/* no Loopback */
+
+#define DMAREG(ch, dir, qnum)	((dir == DMA_TX) ? \
+	                         (void *)(uintptr)&(ch->regs->dmaregs[qnum].dmaxmt) : \
+	                         (void *)(uintptr)&(ch->regs->dmaregs[qnum].dmarcv))
+
+/*
+ * Add multicast address to the list. Multicast address are maintained as
+ * hash table with chaining.
+ */
+typedef struct mclist {
+	struct ether_addr mc_addr;	/* multicast address to allow */
+	struct mclist *next;		/* next entry */
+} mflist_t;
+
+#define GMAC_HASHT_SIZE		16	/* hash table size */
+#define GMAC_MCADDR_HASH(m)	((((uint8 *)(m))[3] + ((uint8 *)(m))[4] + \
+	                         ((uint8 *)(m))[5]) & (GMAC_HASHT_SIZE - 1))
+
+#define ETHER_MCADDR_CMP(x, y) ((((uint16 *)(x))[0] ^ ((uint16 *)(y))[0]) | \
+				(((uint16 *)(x))[1] ^ ((uint16 *)(y))[1]) | \
+				(((uint16 *)(x))[2] ^ ((uint16 *)(y))[2]))
+
+#define SUCCESS			0
+#define FAILURE			-1
+
+typedef struct mcfilter {
+					/* hash table for multicast filtering */
+	mflist_t *bucket[GMAC_HASHT_SIZE];
+} mcfilter_t;
+
+extern uint32 find_priq(uint32 pri_map);
+
+#endif /* _etcgmac_h_ */
-- 
2.25.1

